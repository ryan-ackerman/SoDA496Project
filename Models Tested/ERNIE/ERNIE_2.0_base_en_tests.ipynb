{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339e3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c953798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (3.12.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87367d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4108488",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a12100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan Ackerman\\anaconda3\\envs\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def get_word_embeddings(words, max_length=10):\n",
    "    # Load the ERNIE model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"nghuyong/ernie-2.0-base-en\")\n",
    "    model = AutoModel.from_pretrained(\"nghuyong/ernie-2.0-base-en\")\n",
    "\n",
    "    # Tokenize and pad/truncate all words to the same length\n",
    "    input_ids = tokenizer(words, add_special_tokens=True, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "\n",
    "    # Get word embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "\n",
    "    # The embeddings are already of consistent length (max_length)\n",
    "    word_embeddings = embeddings.numpy()\n",
    "\n",
    "    return word_embeddings\n",
    "\n",
    "\n",
    "# Word Sets and Embeddings\n",
    "AF_Names = [\"Reginald\", \"Kameron\", \"Kendrick\", \"Javon\", \"Tyrell\", \"Jamar\", \"Camron\", \"Tyree\", \"Jamari\", \"Reggie\", \"Jada\", \n",
    "            \"Latoya\", \"Jayla\", \"Tamika\", \"Latoyna\", \"Journey\", \"Tameka\", \"Journee\", \"Lawanda\", \"Janiya\"]\n",
    "AF_Embeddings = get_word_embeddings(AF_Names, max_length=10)\n",
    "\n",
    "EU_Names = [\"James\", \"John\", \"Robert\", \"Michael\", \"William\", \"David\", \"Joseph\", \"Richard\", \"Charles\", \"Thomas\", \"Mary\", \n",
    "            \"Elizabeth\", \"Patricia\", \"Jennifer\", \"Linda\", \"Barbara\", \"Margaret\", \"Susan\", \"Sarah\", \"Jessica\"]\n",
    "EU_Embeddings = get_word_embeddings(EU_Names, max_length=10)\n",
    "\n",
    "LX_Names = [\"Paul\", \"Vincent\", \"Victor\", \"Adrian\", \"Marcus\", \"Leo\", \"Miles\", \"Roman\", \"Sergio\", \"Felix\", \"Patricia\", \"Laura\", \n",
    "            \"Amanda\", \"Victoria\", \"Julia\", \"Gloria\", \"Diana\", \"Clara\", \"Paula\", \"Norma\"]\n",
    "LX_Embeddings = get_word_embeddings(LX_Names, max_length=10)\n",
    "\n",
    "CH_Names = [\"Lian\", \"Shan\", \"Lew\", \"Long\", \"Quan\", \"Jun\", \"Tou\", \"Jin\", \"Cai\", \"Chan\", \"Lue\", \"China\", \"Lu\", \"Maylee\", \n",
    "            \"Tennie\", \"Maylin\", \"Chynna\", \"Jia\", \"Mei\", \"Tylee\"]\n",
    "CH_Embeddings = get_word_embeddings(CH_Names, max_length=10)\n",
    "\n",
    "Male_Names = [\"James\", \"John\", \"Robert\", \"Michael\", \"William\", \"David\", \"Joseph\", \"Richard\", \"Charles\", \"Thomas\", \n",
    "              \"Christopher\", \"Daniel\", \"Matthew\",\"George\", \"Anthony\", \"Donald\", \"Paul\", \"Mark\", \"Andrew\", \"Edward\"]\n",
    "Male_Embeddings = get_word_embeddings(Male_Names, max_length=10)\n",
    "\n",
    "Female_Names = [\"Mary\", \"Elizabeth\", \"Patricia\", \"Jennifer\", \"Linda\", \"Barbara\", \"Margaret\", \"Susan\", \"Dorothy\", \"Sarah\", \n",
    "                \"Jessica\", \"Helen\", \"Nancy\", \"Betty\", \"Karen\", \"Lisa\", \"Anna\", \"Sandra\", \"Emily\", \"Ashley\"]\n",
    "Female_Embeddings = get_word_embeddings(Female_Names, max_length=10)\n",
    "\n",
    "Pleasant_Words = [\"happy\", \"agreeable\", \"polite\", \"civil\", \"charming\", \"gracious\", \"gentle\", \"approachable\", \"love\", \"cool\"]\n",
    "Pleasant_Embeddings = get_word_embeddings(Pleasant_Words, max_length=10)\n",
    "\n",
    "Unpleasant_Words = [\"rude\", \"lazy\", \"disagreeable\", \"lousy\", \"sad\", \"hate\", \"violent\", \"bitter\", \"harsh\", \"angry\"]\n",
    "Unpleasant_Embeddings = get_word_embeddings(Unpleasant_Words, max_length=10)\n",
    "\n",
    "STEM_Careers = [\"Software Developer\", \"Nurse Practitioner\", \"Health Services Manager\", \"Physicians Assistant\", \n",
    "                \"Security Analyst\", \"IT Manager\", \"Web Developer\", \"Dentist\", \"Orthodontist\", \"Computer Systems Analyst\"]\n",
    "STEM_Embeddings = get_word_embeddings(STEM_Careers, max_length=10)\n",
    "\n",
    "Non_STEM_Careers = [\"Artist\", \"Marketing Manager\", \"Social Worker\", \"Attorney\", \"Journalist\", \"Musician\", \"Teacher\", \n",
    "                    \"Media Manager\", \"Graphic Designer\", \"Judge\"]\n",
    "Non_STEM_Embeddings = get_word_embeddings(Non_STEM_Careers, max_length=10)\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55cc7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Reshape Embeddings to 2-D\n",
    "AF_Embeddings = AF_Embeddings.reshape(len(AF_Names), -1)\n",
    "EU_Embeddings = EU_Embeddings.reshape(len(EU_Names), -1)\n",
    "CH_Embeddings = CH_Embeddings.reshape(len(CH_Names), -1)\n",
    "LX_Embeddings = LX_Embeddings.reshape(len(LX_Names), -1)\n",
    "Male_Embeddings = Male_Embeddings.reshape(len(Male_Names), -1)\n",
    "Female_Embeddings = Female_Embeddings.reshape(len(Female_Names), -1)\n",
    "Pleasant_Embeddings = Pleasant_Embeddings.reshape(len(Pleasant_Words), -1)\n",
    "Unpleasant_Embeddings = Unpleasant_Embeddings.reshape(len(Unpleasant_Words), -1)\n",
    "STEM_Embeddings = STEM_Embeddings.reshape(len(STEM_Careers), -1)\n",
    "Non_STEM_Embeddings = Non_STEM_Embeddings.reshape(len(Non_STEM_Careers), -1)\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0792c",
   "metadata": {},
   "source": [
    "# TEST 1: Racial Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50bd0cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: African American Names vs Pleasant Words\n",
      "             happy  agreeable    polite     civil  charming  gracious  \\\n",
      "Reginald  0.862779   0.575859  0.874527  0.865938  0.870398  0.597532   \n",
      "Kameron   0.556468   0.817310  0.585469  0.569918  0.586751  0.847795   \n",
      "Kendrick  0.825454   0.567996  0.869058  0.841198  0.869142  0.589422   \n",
      "Javon     0.572913   0.822744  0.605281  0.589936  0.597723  0.861082   \n",
      "Tyrell    0.565778   0.837136  0.592204  0.577709  0.596634  0.842748   \n",
      "Jamar     0.578199   0.843808  0.601422  0.585305  0.589111  0.867939   \n",
      "Camron    0.554819   0.822537  0.598071  0.576814  0.593494  0.847213   \n",
      "Tyree     0.571021   0.853653  0.592602  0.581109  0.600811  0.858956   \n",
      "Jamari    0.554582   0.789336  0.586625  0.569591  0.571286  0.848497   \n",
      "Reggie    0.869656   0.589019  0.874318  0.863331  0.871234  0.593479   \n",
      "Jada      0.572441   0.849988  0.572802  0.550647  0.576591  0.848937   \n",
      "Latoya    0.567987   0.589145  0.592971  0.585142  0.585375  0.604113   \n",
      "Jayla     0.583757   0.839746  0.602386  0.587167  0.600716  0.862345   \n",
      "Tamika    0.568092   0.815378  0.589903  0.570305  0.591716  0.863222   \n",
      "Latoyna   0.572602   0.593081  0.594284  0.587938  0.590049  0.600658   \n",
      "Journey   0.837501   0.550710  0.876003  0.847983  0.863900  0.582215   \n",
      "Tameka    0.587997   0.849668  0.608224  0.594430  0.604527  0.870194   \n",
      "Journee   0.523161   0.541159  0.515181  0.496211  0.511877  0.577599   \n",
      "Lawanda   0.580176   0.852211  0.611258  0.604739  0.600797  0.868982   \n",
      "Janiya    0.578585   0.836290  0.610797  0.598190  0.600154  0.870990   \n",
      "\n",
      "            gentle  approachable      love      cool  \n",
      "Reginald  0.879132      0.585047  0.847284  0.846504  \n",
      "Kameron   0.567888      0.847961  0.583093  0.571710  \n",
      "Kendrick  0.842916      0.593464  0.843171  0.855366  \n",
      "Javon     0.587163      0.846825  0.583945  0.587420  \n",
      "Tyrell    0.589701      0.844460  0.587290  0.581170  \n",
      "Jamar     0.590667      0.864283  0.595918  0.591512  \n",
      "Camron    0.581726      0.860193  0.579347  0.575661  \n",
      "Tyree     0.596630      0.849861  0.598993  0.595535  \n",
      "Jamari    0.574434      0.817658  0.569825  0.559738  \n",
      "Reggie    0.878638      0.593014  0.856912  0.869470  \n",
      "Jada      0.575349      0.832107  0.581035  0.613467  \n",
      "Latoya    0.589449      0.598866  0.584318  0.577540  \n",
      "Jayla     0.597608      0.856546  0.597254  0.608294  \n",
      "Tamika    0.581706      0.833091  0.594371  0.582672  \n",
      "Latoyna   0.594435      0.602671  0.585988  0.583547  \n",
      "Journey   0.855252      0.591821  0.862289  0.835732  \n",
      "Tameka    0.604162      0.869407  0.601868  0.599615  \n",
      "Journee   0.521475      0.517950  0.551997  0.525116  \n",
      "Lawanda   0.601698      0.868278  0.594220  0.586833  \n",
      "Janiya    0.600120      0.863081  0.589137  0.588154  \n",
      "Cosine Similarity Matrix: African American Names vs Unpleasant Words\n",
      "              rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Reginald  0.849273  0.876603      0.604985  0.611335  0.877626  0.884260   \n",
      "Kameron   0.582668  0.583132      0.860010  0.874856  0.582140  0.590661   \n",
      "Kendrick  0.862598  0.865657      0.605389  0.616202  0.853266  0.866228   \n",
      "Javon     0.592062  0.589295      0.862194  0.879646  0.592561  0.588433   \n",
      "Tyrell    0.587884  0.598073      0.871662  0.880636  0.604020  0.606998   \n",
      "Jamar     0.585627  0.584162      0.876910  0.889794  0.595464  0.604778   \n",
      "Camron    0.578700  0.578968      0.865549  0.889816  0.584540  0.580722   \n",
      "Tyree     0.604724  0.606524      0.888315  0.893844  0.610069  0.615262   \n",
      "Jamari    0.566080  0.559108      0.824778  0.849546  0.548785  0.562716   \n",
      "Reggie    0.859917  0.890564      0.620011  0.623562  0.884582  0.901188   \n",
      "Jada      0.574045  0.567446      0.873680  0.868067  0.603141  0.588684   \n",
      "Latoya    0.574026  0.579962      0.609487  0.618516  0.582997  0.593898   \n",
      "Jayla     0.593444  0.592839      0.877833  0.887350  0.601041  0.595603   \n",
      "Tamika    0.588072  0.571477      0.861234  0.883649  0.583896  0.595205   \n",
      "Latoyna   0.579046  0.584227      0.614588  0.623720  0.595399  0.599193   \n",
      "Journey   0.857642  0.857166      0.588999  0.609288  0.862651  0.879457   \n",
      "Tameka    0.597842  0.595032      0.886082  0.898573  0.609444  0.610196   \n",
      "Journee   0.513082  0.497928      0.535381  0.548073  0.525761  0.523215   \n",
      "Lawanda   0.590408  0.597286      0.882878  0.891041  0.600870  0.609797   \n",
      "Janiya    0.594916  0.592795      0.878207  0.898373  0.598041  0.596447   \n",
      "\n",
      "           violent    bitter     harsh     angry  \n",
      "Reginald  0.860637  0.889859  0.876433  0.901598  \n",
      "Kameron   0.571157  0.597558  0.580166  0.599177  \n",
      "Kendrick  0.839517  0.876755  0.861933  0.879454  \n",
      "Javon     0.585788  0.606099  0.587768  0.613618  \n",
      "Tyrell    0.579180  0.616115  0.598666  0.612883  \n",
      "Jamar     0.583776  0.605666  0.587493  0.614824  \n",
      "Camron    0.570798  0.604526  0.578652  0.600189  \n",
      "Tyree     0.578934  0.619871  0.603529  0.616568  \n",
      "Jamari    0.556693  0.572896  0.559813  0.588304  \n",
      "Reggie    0.860057  0.901666  0.884949  0.902845  \n",
      "Jada      0.552718  0.592978  0.573469  0.594635  \n",
      "Latoya    0.577795  0.594466  0.581068  0.601718  \n",
      "Jayla     0.584222  0.611180  0.589614  0.617685  \n",
      "Tamika    0.564961  0.599880  0.579839  0.600879  \n",
      "Latoyna   0.577198  0.602089  0.588162  0.604625  \n",
      "Journey   0.839424  0.878720  0.860978  0.882242  \n",
      "Tameka    0.588322  0.612993  0.601275  0.621143  \n",
      "Journee   0.483268  0.513515  0.503666  0.522031  \n",
      "Lawanda   0.595212  0.611519  0.597099  0.618693  \n",
      "Janiya    0.594656  0.610166  0.593372  0.619270  \n"
     ]
    }
   ],
   "source": [
    "# African American Names\n",
    "\n",
    "# Pleasant Words\n",
    "similarities_AFvP = cosine_similarity(AF_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_AFvU = cosine_similarity(AF_Embeddings, Unpleasant_Embeddings)\n",
    "\n",
    "similarities_AFvP = pd.DataFrame(similarities_AFvP, index = AF_Names, columns = Pleasant_Words)\n",
    "similarities_AFvU = pd.DataFrame(similarities_AFvU, index = AF_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: African American Names vs Pleasant Words\")\n",
    "print(similarities_AFvP)\n",
    "print(\"Cosine Similarity Matrix: African American Names vs Unpleasant Words\")\n",
    "print(similarities_AFvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7b5b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: European American Names vs Pleasant Words\n",
      "              happy  agreeable    polite     civil  charming  gracious  \\\n",
      "James      0.839291   0.561623  0.871579  0.843575  0.869548  0.606165   \n",
      "John       0.822366   0.548379  0.856590  0.831155  0.848763  0.604932   \n",
      "Robert     0.844342   0.568632  0.862237  0.847957  0.854357  0.600715   \n",
      "Michael    0.865710   0.577950  0.878767  0.845145  0.879428  0.615161   \n",
      "William    0.812780   0.546086  0.850668  0.835874  0.844924  0.595084   \n",
      "David      0.833994   0.565746  0.872317  0.840326  0.868136  0.611388   \n",
      "Joseph     0.820162   0.546120  0.866331  0.839942  0.855906  0.593948   \n",
      "Richard    0.829862   0.559645  0.865707  0.845907  0.861719  0.600102   \n",
      "Charles    0.818068   0.536243  0.856967  0.846400  0.847210  0.593938   \n",
      "Thomas     0.809597   0.550813  0.859183  0.842183  0.852827  0.586855   \n",
      "Mary       0.831344   0.533130  0.860944  0.828436  0.855758  0.609249   \n",
      "Elizabeth  0.835502   0.549565  0.868753  0.840155  0.868358  0.609205   \n",
      "Patricia   0.842468   0.560184  0.878590  0.853818  0.868066  0.605610   \n",
      "Jennifer   0.845892   0.558137  0.873930  0.841344  0.872012  0.603520   \n",
      "Linda      0.844327   0.558399  0.868749  0.828784  0.865368  0.604087   \n",
      "Barbara    0.837721   0.550121  0.869769  0.837628  0.866505  0.601550   \n",
      "Margaret   0.836962   0.551728  0.869892  0.839440  0.868173  0.598177   \n",
      "Susan      0.843902   0.560833  0.880211  0.837523  0.875372  0.611847   \n",
      "Sarah      0.844455   0.548466  0.871563  0.833564  0.871690  0.616597   \n",
      "Jessica    0.844254   0.565749  0.871111  0.836023  0.876053  0.598358   \n",
      "\n",
      "             gentle  approachable      love      cool  \n",
      "James      0.861846      0.581649  0.851705  0.841908  \n",
      "John       0.847458      0.561987  0.838079  0.829932  \n",
      "Robert     0.870803      0.573968  0.848064  0.842394  \n",
      "Michael    0.874857      0.590215  0.878217  0.864975  \n",
      "William    0.848525      0.561540  0.828339  0.816434  \n",
      "David      0.859958      0.586051  0.853860  0.846145  \n",
      "Joseph     0.851286      0.576583  0.829768  0.824652  \n",
      "Richard    0.854409      0.577959  0.839267  0.835782  \n",
      "Charles    0.850856      0.565588  0.827585  0.813907  \n",
      "Thomas     0.842729      0.575405  0.819867  0.814647  \n",
      "Mary       0.863106      0.563451  0.852430  0.818237  \n",
      "Elizabeth  0.861008      0.572370  0.850230  0.832544  \n",
      "Patricia   0.868050      0.585028  0.844526  0.847329  \n",
      "Jennifer   0.866193      0.580601  0.850879  0.852066  \n",
      "Linda      0.859121      0.574943  0.852282  0.852313  \n",
      "Barbara    0.862790      0.578602  0.845594  0.839388  \n",
      "Margaret   0.861983      0.575837  0.848738  0.826322  \n",
      "Susan      0.870597      0.585045  0.858535  0.849264  \n",
      "Sarah      0.870801      0.573110  0.856497  0.849480  \n",
      "Jessica    0.864832      0.588993  0.857387  0.854542  \n",
      "Cosine Similarity Matrix: European American Names vs Unpleasant Words\n",
      "               rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "James      0.858773  0.863205      0.596403  0.615289  0.849641  0.863421   \n",
      "John       0.844895  0.842641      0.576376  0.607215  0.831431  0.837283   \n",
      "Robert     0.849391  0.860524      0.598415  0.607449  0.858586  0.866509   \n",
      "Michael    0.875733  0.870184      0.614785  0.630782  0.882249  0.890865   \n",
      "William    0.836936  0.843116      0.579788  0.596826  0.828205  0.839485   \n",
      "David      0.861776  0.856967      0.598812  0.620417  0.848395  0.859831   \n",
      "Joseph     0.847582  0.853077      0.585522  0.604364  0.832477  0.845111   \n",
      "Richard    0.854236  0.858375      0.596552  0.609009  0.843879  0.855273   \n",
      "Charles    0.832811  0.848118      0.570761  0.599993  0.820702  0.839288   \n",
      "Thomas     0.835826  0.846934      0.587165  0.601063  0.831469  0.835912   \n",
      "Mary       0.840488  0.842038      0.569220  0.601719  0.826156  0.854196   \n",
      "Elizabeth  0.853587  0.848558      0.581975  0.605353  0.843344  0.854169   \n",
      "Patricia   0.858891  0.860092      0.595379  0.611608  0.847915  0.858541   \n",
      "Jennifer   0.856680  0.860912      0.595557  0.611809  0.858537  0.864834   \n",
      "Linda      0.854590  0.854133      0.589696  0.608465  0.851023  0.857384   \n",
      "Barbara    0.849992  0.850055      0.590162  0.612293  0.846760  0.854780   \n",
      "Margaret   0.854921  0.848195      0.586763  0.610929  0.849384  0.859809   \n",
      "Susan      0.863758  0.858999      0.595688  0.615167  0.852640  0.868243   \n",
      "Sarah      0.867376  0.853007      0.585184  0.617776  0.851541  0.861799   \n",
      "Jessica    0.864114  0.861727      0.604026  0.617533  0.861622  0.874186   \n",
      "\n",
      "            violent    bitter     harsh     angry  \n",
      "James      0.842767  0.877559  0.862623  0.893139  \n",
      "John       0.827745  0.852633  0.839121  0.869863  \n",
      "Robert     0.844802  0.875580  0.857979  0.890896  \n",
      "Michael    0.845186  0.896606  0.881928  0.908466  \n",
      "William    0.832198  0.859120  0.838169  0.871226  \n",
      "David      0.837931  0.873031  0.854178  0.889075  \n",
      "Joseph     0.841668  0.862971  0.849063  0.879780  \n",
      "Richard    0.846280  0.877367  0.853951  0.887286  \n",
      "Charles    0.837560  0.854933  0.834947  0.871453  \n",
      "Thomas     0.842316  0.863141  0.844355  0.867729  \n",
      "Mary       0.829586  0.858384  0.839903  0.876209  \n",
      "Elizabeth  0.833186  0.865362  0.850001  0.881526  \n",
      "Patricia   0.841736  0.875126  0.858046  0.890940  \n",
      "Jennifer   0.838076  0.877563  0.857113  0.893924  \n",
      "Linda      0.832153  0.866592  0.849461  0.886151  \n",
      "Barbara    0.833222  0.869404  0.850766  0.883989  \n",
      "Margaret   0.836610  0.869055  0.854548  0.884749  \n",
      "Susan      0.835016  0.880365  0.858732  0.894550  \n",
      "Sarah      0.824684  0.873371  0.859975  0.891938  \n",
      "Jessica    0.835982  0.880249  0.868601  0.893906  \n"
     ]
    }
   ],
   "source": [
    "# European American Names\n",
    "# Pleasant Words\n",
    "similarities_EUvP = cosine_similarity(EU_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_EUvU = cosine_similarity(EU_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_EUvP = pd.DataFrame(similarities_EUvP, index = EU_Names, columns = Pleasant_Words)\n",
    "similarities_EUvU = pd.DataFrame(similarities_EUvU, index = EU_Names, columns = Unpleasant_Words)\n",
    "print(\"Cosine Similarity Matrix: European American Names vs Pleasant Words\")\n",
    "print(similarities_EUvP)\n",
    "print(\"Cosine Similarity Matrix: European American Names vs Unpleasant Words\")\n",
    "print(similarities_EUvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c98f3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Latin American Names vs Pleasant Words\n",
      "             happy  agreeable    polite     civil  charming  gracious  \\\n",
      "Paul      0.831715   0.565870  0.879394  0.849718  0.869142  0.612527   \n",
      "Vincent   0.824270   0.567349  0.860845  0.844706  0.852991  0.595623   \n",
      "Victor    0.845330   0.573005  0.879341  0.850739  0.873202  0.610989   \n",
      "Adrian    0.858370   0.584623  0.876244  0.862023  0.872284  0.599398   \n",
      "Marcus    0.857560   0.578297  0.872775  0.854731  0.874407  0.605967   \n",
      "Leo       0.851047   0.570504  0.873556  0.853188  0.868754  0.607221   \n",
      "Miles     0.776315   0.511476  0.825813  0.786785  0.808274  0.537763   \n",
      "Roman     0.874623   0.554875  0.904437  0.914347  0.878694  0.599544   \n",
      "Sergio    0.839067   0.582765  0.869527  0.839215  0.862867  0.599807   \n",
      "Felix     0.832385   0.553825  0.856947  0.828006  0.861266  0.596911   \n",
      "Patricia  0.842468   0.560184  0.878590  0.853818  0.868066  0.605610   \n",
      "Laura     0.835729   0.552560  0.864153  0.828843  0.865153  0.601515   \n",
      "Amanda    0.847560   0.573527  0.880720  0.838438  0.883868  0.598479   \n",
      "Victoria  0.830101   0.568556  0.845336  0.831362  0.837940  0.569844   \n",
      "Julia     0.846377   0.551031  0.872431  0.836528  0.874457  0.610806   \n",
      "Gloria    0.826888   0.541053  0.865375  0.833280  0.855961  0.603252   \n",
      "Diana     0.842132   0.560379  0.872921  0.833810  0.874663  0.598224   \n",
      "Clara     0.845559   0.551048  0.880302  0.841258  0.873186  0.606133   \n",
      "Paula     0.846443   0.573602  0.867522  0.842264  0.864544  0.607160   \n",
      "Norma     0.851218   0.564871  0.876100  0.854966  0.867931  0.595809   \n",
      "\n",
      "            gentle  approachable      love      cool  \n",
      "Paul      0.865185      0.589147  0.856653  0.848968  \n",
      "Vincent   0.849500      0.587592  0.831052  0.821392  \n",
      "Victor    0.866661      0.593065  0.852119  0.846342  \n",
      "Adrian    0.867958      0.599093  0.854468  0.856076  \n",
      "Marcus    0.875141      0.595509  0.857051  0.853972  \n",
      "Leo       0.866771      0.589222  0.858904  0.854832  \n",
      "Miles     0.812825      0.536945  0.792387  0.790048  \n",
      "Roman     0.910779      0.596243  0.827675  0.849176  \n",
      "Sergio    0.858515      0.589458  0.846510  0.852149  \n",
      "Felix     0.851111      0.574623  0.840247  0.844472  \n",
      "Patricia  0.868050      0.585028  0.844526  0.847329  \n",
      "Laura     0.855083      0.575148  0.855126  0.842656  \n",
      "Amanda    0.869663      0.593886  0.863164  0.862670  \n",
      "Victoria  0.844037      0.583305  0.825205  0.812825  \n",
      "Julia     0.866068      0.578505  0.860353  0.845079  \n",
      "Gloria    0.859045      0.568438  0.858788  0.825836  \n",
      "Diana     0.861135      0.584213  0.859185  0.856668  \n",
      "Clara     0.872282      0.588417  0.848911  0.829590  \n",
      "Paula     0.865508      0.586216  0.857847  0.850820  \n",
      "Norma     0.870525      0.581350  0.853070  0.848298  \n",
      "Cosine Similarity Matrix: Latin American Names vs Unpleasant Words\n",
      "              rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Paul      0.868741  0.866901      0.601256  0.623668  0.849147  0.870015   \n",
      "Vincent   0.838466  0.853349      0.599643  0.611331  0.838100  0.844789   \n",
      "Victor    0.861548  0.859810      0.612308  0.618271  0.864359  0.866436   \n",
      "Adrian    0.856018  0.872864      0.616051  0.622806  0.873067  0.880974   \n",
      "Marcus    0.860574  0.880111      0.609261  0.617078  0.872914  0.885120   \n",
      "Leo       0.859163  0.860067      0.606574  0.618164  0.856181  0.873184   \n",
      "Miles     0.805764  0.808531      0.544906  0.559757  0.802057  0.815993   \n",
      "Roman     0.862870  0.907029      0.597284  0.618549  0.876368  0.875813   \n",
      "Sergio    0.856928  0.863127      0.611674  0.614040  0.862504  0.863475   \n",
      "Felix     0.857233  0.849645      0.592561  0.615576  0.851842  0.856946   \n",
      "Patricia  0.858891  0.860092      0.595379  0.611608  0.847915  0.858541   \n",
      "Laura     0.853141  0.844877      0.587292  0.607664  0.841930  0.857739   \n",
      "Amanda    0.870617  0.860322      0.612184  0.622303  0.873767  0.882078   \n",
      "Victoria  0.818830  0.836049      0.596159  0.605490  0.850778  0.854799   \n",
      "Julia     0.864044  0.851448      0.589338  0.614974  0.852478  0.863121   \n",
      "Gloria    0.845348  0.839881      0.579457  0.601274  0.831554  0.858693   \n",
      "Diana     0.861188  0.851154      0.597348  0.610450  0.851793  0.865347   \n",
      "Clara     0.854236  0.852583      0.591627  0.615178  0.850460  0.861086   \n",
      "Paula     0.852463  0.853254      0.607119  0.616686  0.852559  0.863961   \n",
      "Norma     0.854560  0.848677      0.601523  0.606061  0.858452  0.874003   \n",
      "\n",
      "           violent    bitter     harsh     angry  \n",
      "Paul      0.845150  0.874560  0.863109  0.889016  \n",
      "Vincent   0.844585  0.867537  0.852945  0.874852  \n",
      "Victor    0.843214  0.888395  0.867063  0.901831  \n",
      "Adrian    0.855714  0.889514  0.873993  0.903969  \n",
      "Marcus    0.858778  0.895158  0.876169  0.903464  \n",
      "Leo       0.838859  0.878570  0.863008  0.893768  \n",
      "Miles     0.787174  0.819609  0.813612  0.833842  \n",
      "Roman     0.906516  0.911785  0.895552  0.920929  \n",
      "Sergio    0.841623  0.878143  0.860115  0.892737  \n",
      "Felix     0.820964  0.867180  0.851461  0.875172  \n",
      "Patricia  0.841736  0.875126  0.858046  0.890940  \n",
      "Laura     0.823099  0.870233  0.846715  0.883004  \n",
      "Amanda    0.839637  0.889634  0.870966  0.902678  \n",
      "Victoria  0.828447  0.868687  0.850676  0.869540  \n",
      "Julia     0.828475  0.876388  0.851941  0.890008  \n",
      "Gloria    0.825629  0.860884  0.844717  0.875083  \n",
      "Diana     0.829434  0.874081  0.857232  0.889052  \n",
      "Clara     0.837179  0.877088  0.857838  0.888868  \n",
      "Paula     0.832110  0.871804  0.853135  0.883712  \n",
      "Norma     0.839057  0.879259  0.860849  0.889612  \n"
     ]
    }
   ],
   "source": [
    "# Latin American Names\n",
    "# Pleasant Words\n",
    "similarities_LXvP = cosine_similarity(LX_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_LXvU = cosine_similarity(LX_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_LXvP = pd.DataFrame(similarities_LXvP, index = LX_Names, columns = Pleasant_Words)\n",
    "similarities_LXvU = pd.DataFrame(similarities_LXvU, index = LX_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Latin American Names vs Pleasant Words\")\n",
    "print(similarities_LXvP)\n",
    "print(\"Cosine Similarity Matrix: Latin American Names vs Unpleasant Words\")\n",
    "print(similarities_LXvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b0bab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Chinese American Names vs Pleasant Words\n",
      "           happy  agreeable    polite     civil  charming  gracious    gentle  \\\n",
      "Lian    0.541939   0.789623  0.567064  0.550110  0.557749  0.824398  0.561564   \n",
      "Shan    0.828168   0.538410  0.841123  0.851897  0.834140  0.575677  0.844150   \n",
      "Lew     0.834627   0.542533  0.826621  0.860604  0.829148  0.571385  0.845294   \n",
      "Long    0.846692   0.515624  0.861468  0.821316  0.851338  0.573735  0.862647   \n",
      "Quan    0.844516   0.555790  0.830141  0.842796  0.830926  0.571752  0.841673   \n",
      "Jun     0.814285   0.530646  0.846112  0.838243  0.834038  0.575362  0.831565   \n",
      "Tou     0.563563   0.814289  0.565874  0.542393  0.556290  0.854753  0.569326   \n",
      "Jin     0.819222   0.538862  0.839704  0.830373  0.835958  0.580935  0.832973   \n",
      "Cai     0.847770   0.547852  0.853774  0.864593  0.847259  0.582341  0.858793   \n",
      "Chan    0.812663   0.525993  0.841424  0.823533  0.836337  0.588200  0.836026   \n",
      "Lue     0.550463   0.804698  0.582884  0.567874  0.575487  0.838771  0.578423   \n",
      "China   0.820228   0.562019  0.858923  0.832021  0.847469  0.568047  0.840511   \n",
      "Lu      0.831387   0.532990  0.833037  0.851251  0.829444  0.573719  0.843961   \n",
      "Maylee  0.577440   0.809057  0.590050  0.579198  0.583068  0.857816  0.586447   \n",
      "Tennie  0.579840   0.839187  0.606268  0.583795  0.599285  0.884840  0.597700   \n",
      "Maylin  0.562886   0.826494  0.586183  0.579245  0.576338  0.830732  0.578719   \n",
      "Chynna  0.560367   0.573480  0.585504  0.573801  0.585911  0.584913  0.584661   \n",
      "Jia     0.822162   0.536320  0.837567  0.827592  0.827980  0.581097  0.831508   \n",
      "Mei     0.836502   0.547970  0.859801  0.847789  0.853805  0.592165  0.852677   \n",
      "Tylee   0.586260   0.848161  0.581891  0.544909  0.594453  0.877032  0.577575   \n",
      "\n",
      "        approachable      love      cool  \n",
      "Lian        0.814051  0.562436  0.555498  \n",
      "Shan        0.552056  0.831436  0.823418  \n",
      "Lew         0.547059  0.810077  0.823027  \n",
      "Long        0.559662  0.776901  0.826208  \n",
      "Quan        0.554765  0.829124  0.845577  \n",
      "Jun         0.556106  0.817912  0.815310  \n",
      "Tou         0.817884  0.575114  0.580704  \n",
      "Jin         0.553295  0.825256  0.846596  \n",
      "Cai         0.564195  0.836104  0.833934  \n",
      "Chan        0.557215  0.823305  0.822597  \n",
      "Lue         0.826899  0.576980  0.565195  \n",
      "China       0.583758  0.835327  0.831163  \n",
      "Lu          0.548266  0.823954  0.825789  \n",
      "Maylee      0.829938  0.579653  0.567571  \n",
      "Tennie      0.855489  0.593282  0.601508  \n",
      "Maylin      0.838745  0.565634  0.561187  \n",
      "Chynna      0.588938  0.577048  0.577576  \n",
      "Jia         0.555021  0.816038  0.827066  \n",
      "Mei         0.568249  0.840732  0.841232  \n",
      "Tylee       0.822555  0.602447  0.620457  \n",
      "Cosine Similarity Matrix: Chinese American Names vs Unpleasant Words\n",
      "            rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Lian    0.547395  0.546441      0.816259  0.847259  0.549700  0.560343   \n",
      "Shan    0.820032  0.837760      0.564452  0.592728  0.843133  0.858054   \n",
      "Lew     0.819568  0.843102      0.568194  0.585239  0.849703  0.853387   \n",
      "Long    0.837503  0.864565      0.545782  0.594340  0.846071  0.809927   \n",
      "Quan    0.814317  0.832174      0.579672  0.581055  0.860172  0.859991   \n",
      "Jun     0.820061  0.830547      0.563078  0.586502  0.831597  0.839217   \n",
      "Tou     0.550600  0.549574      0.835906  0.850240  0.569183  0.575533   \n",
      "Jin     0.833444  0.836686      0.564751  0.590672  0.834480  0.841382   \n",
      "Cai     0.831110  0.852374      0.578531  0.595865  0.856947  0.865971   \n",
      "Chan    0.820117  0.827727      0.558103  0.597202  0.823478  0.835394   \n",
      "Lue     0.565360  0.567235      0.841300  0.867995  0.564016  0.580930   \n",
      "China   0.842945  0.848753      0.593758  0.602148  0.860011  0.864052   \n",
      "Lu      0.816344  0.834774      0.563732  0.586561  0.840148  0.848246   \n",
      "Maylee  0.569597  0.577850      0.841162  0.867662  0.583629  0.580918   \n",
      "Tennie  0.594577  0.590674      0.873114  0.905704  0.589143  0.593523   \n",
      "Maylin  0.562213  0.570181      0.853078  0.862428  0.586468  0.581294   \n",
      "Chynna  0.570948  0.569846      0.603946  0.612227  0.582645  0.584177   \n",
      "Jia     0.812306  0.826190      0.562108  0.582997  0.830180  0.835361   \n",
      "Mei     0.840489  0.850240      0.579240  0.605076  0.848069  0.859878   \n",
      "Tylee   0.597595  0.569644      0.854730  0.859747  0.596117  0.573208   \n",
      "\n",
      "         violent    bitter     harsh     angry  \n",
      "Lian    0.545095  0.567215  0.547553  0.579362  \n",
      "Shan    0.833772  0.857089  0.841183  0.860579  \n",
      "Lew     0.828952  0.855661  0.841652  0.850095  \n",
      "Long    0.851462  0.866863  0.876222  0.869032  \n",
      "Quan    0.818905  0.851264  0.843446  0.851814  \n",
      "Jun     0.825217  0.847421  0.830236  0.856014  \n",
      "Tou     0.539372  0.564746  0.555423  0.579581  \n",
      "Jin     0.818390  0.846053  0.830404  0.856761  \n",
      "Cai     0.840504  0.870827  0.853429  0.874005  \n",
      "Chan    0.819134  0.840267  0.823618  0.855188  \n",
      "Lue     0.561481  0.583712  0.564208  0.591885  \n",
      "China   0.838555  0.869562  0.853109  0.877531  \n",
      "Lu      0.824741  0.850230  0.828811  0.855914  \n",
      "Maylee  0.573286  0.594155  0.581289  0.604117  \n",
      "Tennie  0.574552  0.609056  0.589636  0.616829  \n",
      "Maylin  0.568035  0.597088  0.580364  0.597466  \n",
      "Chynna  0.572466  0.598995  0.572044  0.600665  \n",
      "Jia     0.815843  0.839034  0.827937  0.850570  \n",
      "Mei     0.831115  0.864725  0.843500  0.871335  \n",
      "Tylee   0.541286  0.581972  0.578689  0.590713  \n"
     ]
    }
   ],
   "source": [
    "# Chinese American Names\n",
    "# Pleasant Words\n",
    "similarities_CHvP = cosine_similarity(CH_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_CHvU = cosine_similarity(CH_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_CHvP = pd.DataFrame(similarities_CHvP, index = CH_Names, columns = Pleasant_Words)\n",
    "similarities_CHvU = pd.DataFrame(similarities_CHvU, index = CH_Names, columns = Unpleasant_Words)\n",
    "print(\"Cosine Similarity Matrix: Chinese American Names vs Pleasant Words\")\n",
    "print(similarities_CHvP)\n",
    "print(\"Cosine Similarity Matrix: Chinese American Names vs Unpleasant Words\")\n",
    "print(similarities_CHvU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967ba9b",
   "metadata": {},
   "source": [
    "# TEST 2: Gender Biases for Favorability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984fa641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Male Names vs Pleasant Words\n",
      "                happy  agreeable    polite     civil  charming  gracious  \\\n",
      "James        0.839291   0.561623  0.871579  0.843575  0.869548  0.606165   \n",
      "John         0.822366   0.548379  0.856590  0.831155  0.848763  0.604932   \n",
      "Robert       0.844342   0.568632  0.862237  0.847957  0.854357  0.600715   \n",
      "Michael      0.865710   0.577950  0.878767  0.845145  0.879428  0.615161   \n",
      "William      0.812780   0.546086  0.850668  0.835874  0.844924  0.595084   \n",
      "David        0.833994   0.565746  0.872317  0.840326  0.868136  0.611388   \n",
      "Joseph       0.820162   0.546120  0.866331  0.839942  0.855906  0.593948   \n",
      "Richard      0.829862   0.559645  0.865707  0.845907  0.861719  0.600102   \n",
      "Charles      0.818068   0.536243  0.856967  0.846400  0.847210  0.593938   \n",
      "Thomas       0.809597   0.550813  0.859183  0.842183  0.852827  0.586855   \n",
      "Christopher  0.846641   0.564032  0.872883  0.856009  0.873055  0.607434   \n",
      "Daniel       0.846879   0.573185  0.874655  0.847521  0.872344  0.614316   \n",
      "Matthew      0.746211   0.501534  0.750990  0.752427  0.749976  0.524996   \n",
      "George       0.843823   0.556799  0.870214  0.854631  0.863311  0.607889   \n",
      "Anthony      0.822141   0.567603  0.856514  0.832937  0.859387  0.586104   \n",
      "Donald       0.844705   0.557260  0.859016  0.861794  0.857925  0.589738   \n",
      "Paul         0.831715   0.565870  0.879394  0.849718  0.869142  0.612527   \n",
      "Mark         0.858392   0.584652  0.872303  0.841541  0.879426  0.611335   \n",
      "Andrew       0.849494   0.587634  0.873802  0.850948  0.873547  0.613461   \n",
      "Edward       0.850923   0.584649  0.877122  0.866145  0.876874  0.604994   \n",
      "\n",
      "               gentle  approachable      love      cool  \n",
      "James        0.861846      0.581649  0.851705  0.841908  \n",
      "John         0.847458      0.561987  0.838079  0.829932  \n",
      "Robert       0.870803      0.573968  0.848064  0.842394  \n",
      "Michael      0.874857      0.590215  0.878217  0.864975  \n",
      "William      0.848525      0.561540  0.828339  0.816434  \n",
      "David        0.859958      0.586051  0.853860  0.846145  \n",
      "Joseph       0.851286      0.576583  0.829768  0.824652  \n",
      "Richard      0.854409      0.577959  0.839267  0.835782  \n",
      "Charles      0.850856      0.565588  0.827585  0.813907  \n",
      "Thomas       0.842729      0.575405  0.819867  0.814647  \n",
      "Christopher  0.863113      0.589844  0.856313  0.847205  \n",
      "Daniel       0.869375      0.587365  0.857332  0.850613  \n",
      "Matthew      0.753437      0.492565  0.744253  0.723128  \n",
      "George       0.866793      0.576686  0.848005  0.835819  \n",
      "Anthony      0.840906      0.592310  0.830817  0.828211  \n",
      "Donald       0.852388      0.572719  0.845629  0.831155  \n",
      "Paul         0.865185      0.589147  0.856653  0.848968  \n",
      "Mark         0.865001      0.593935  0.866969  0.880122  \n",
      "Andrew       0.867355      0.597125  0.859277  0.855807  \n",
      "Edward       0.873051      0.598766  0.847634  0.848457  \n",
      "Cosine Similarity Matrix: Male Names vs Unpleasant Words\n",
      "                 rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "James        0.858773  0.863205      0.596403  0.615289  0.849641  0.863421   \n",
      "John         0.844895  0.842641      0.576376  0.607215  0.831431  0.837283   \n",
      "Robert       0.849391  0.860524      0.598415  0.607449  0.858586  0.866509   \n",
      "Michael      0.875733  0.870184      0.614785  0.630782  0.882249  0.890865   \n",
      "William      0.836936  0.843116      0.579788  0.596826  0.828205  0.839485   \n",
      "David        0.861776  0.856967      0.598812  0.620417  0.848395  0.859831   \n",
      "Joseph       0.847582  0.853077      0.585522  0.604364  0.832477  0.845111   \n",
      "Richard      0.854236  0.858375      0.596552  0.609009  0.843879  0.855273   \n",
      "Charles      0.832811  0.848118      0.570761  0.599993  0.820702  0.839288   \n",
      "Thomas       0.835826  0.846934      0.587165  0.601063  0.831469  0.835912   \n",
      "Christopher  0.862121  0.863522      0.600211  0.613590  0.856270  0.863873   \n",
      "Daniel       0.864889  0.862942      0.606728  0.621870  0.864989  0.871330   \n",
      "Matthew      0.731067  0.742898      0.513237  0.514666  0.743971  0.750301   \n",
      "George       0.853916  0.869712      0.592907  0.615246  0.850001  0.865659   \n",
      "Anthony      0.849268  0.855985      0.605491  0.614462  0.849851  0.852500   \n",
      "Donald       0.846739  0.872991      0.592061  0.609987  0.862405  0.878949   \n",
      "Paul         0.868741  0.866901      0.601256  0.623668  0.849147  0.870015   \n",
      "Mark         0.874385  0.873160      0.612785  0.628559  0.876360  0.880632   \n",
      "Andrew       0.865774  0.869411      0.616028  0.625610  0.867542  0.870558   \n",
      "Edward       0.859929  0.874644      0.614482  0.628915  0.873489  0.873421   \n",
      "\n",
      "              violent    bitter     harsh     angry  \n",
      "James        0.842767  0.877559  0.862623  0.893139  \n",
      "John         0.827745  0.852633  0.839121  0.869863  \n",
      "Robert       0.844802  0.875580  0.857979  0.890896  \n",
      "Michael      0.845186  0.896606  0.881928  0.908466  \n",
      "William      0.832198  0.859120  0.838169  0.871226  \n",
      "David        0.837931  0.873031  0.854178  0.889075  \n",
      "Joseph       0.841668  0.862971  0.849063  0.879780  \n",
      "Richard      0.846280  0.877367  0.853951  0.887286  \n",
      "Charles      0.837560  0.854933  0.834947  0.871453  \n",
      "Thomas       0.842316  0.863141  0.844355  0.867729  \n",
      "Christopher  0.848727  0.875165  0.863433  0.890628  \n",
      "Daniel       0.842128  0.885349  0.866956  0.900174  \n",
      "Matthew      0.733883  0.761637  0.756918  0.765377  \n",
      "George       0.851770  0.879468  0.860837  0.890651  \n",
      "Anthony      0.840903  0.871914  0.855226  0.878663  \n",
      "Donald       0.854985  0.878228  0.857862  0.884516  \n",
      "Paul         0.845150  0.874560  0.863109  0.889016  \n",
      "Mark         0.839095  0.890407  0.877096  0.898142  \n",
      "Andrew       0.848988  0.885484  0.872120  0.901050  \n",
      "Edward       0.860825  0.889430  0.875231  0.899710  \n"
     ]
    }
   ],
   "source": [
    "# Male Names\n",
    "# Pleasant Words\n",
    "similarities_MvP = cosine_similarity(Male_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_MvU = cosine_similarity(Male_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_MvP = pd.DataFrame(similarities_MvP, index = Male_Names, columns = Pleasant_Words)\n",
    "similarities_MvU = pd.DataFrame(similarities_MvU, index = Male_Names, columns = Unpleasant_Words)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs Pleasant Words\")\n",
    "print(similarities_MvP)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs Unpleasant Words\")\n",
    "print(similarities_MvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fcfe221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Female Names vs Pleasant Words\n",
      "              happy  agreeable    polite     civil  charming  gracious  \\\n",
      "Mary       0.831344   0.533130  0.860944  0.828436  0.855758  0.609249   \n",
      "Elizabeth  0.835502   0.549565  0.868753  0.840155  0.868358  0.609205   \n",
      "Patricia   0.842468   0.560184  0.878590  0.853818  0.868066  0.605610   \n",
      "Jennifer   0.845892   0.558137  0.873930  0.841344  0.872012  0.603520   \n",
      "Linda      0.844327   0.558399  0.868749  0.828784  0.865368  0.604087   \n",
      "Barbara    0.837721   0.550121  0.869769  0.837628  0.866505  0.601550   \n",
      "Margaret   0.836962   0.551728  0.869892  0.839440  0.868173  0.598177   \n",
      "Susan      0.843902   0.560833  0.880211  0.837523  0.875372  0.611847   \n",
      "Dorothy    0.842959   0.552118  0.878722  0.842275  0.874444  0.606638   \n",
      "Sarah      0.844455   0.548466  0.871563  0.833564  0.871690  0.616597   \n",
      "Jessica    0.844254   0.565749  0.871111  0.836023  0.876053  0.598358   \n",
      "Helen      0.842541   0.553517  0.874190  0.835428  0.871650  0.604454   \n",
      "Nancy      0.847953   0.553826  0.870721  0.846286  0.869023  0.606616   \n",
      "Betty      0.839845   0.544559  0.877716  0.838743  0.873735  0.596167   \n",
      "Karen      0.852018   0.566820  0.882842  0.845883  0.888077  0.609376   \n",
      "Lisa       0.841198   0.553185  0.868024  0.823380  0.871592  0.595905   \n",
      "Anna       0.832852   0.553358  0.866204  0.833087  0.866960  0.598135   \n",
      "Sandra     0.842237   0.556212  0.872123  0.835917  0.867833  0.604371   \n",
      "Emily      0.850967   0.565246  0.881910  0.849034  0.885315  0.605588   \n",
      "Ashley     0.859437   0.600132  0.863447  0.850314  0.875308  0.591208   \n",
      "\n",
      "             gentle  approachable      love      cool  \n",
      "Mary       0.863106      0.563451  0.852430  0.818237  \n",
      "Elizabeth  0.861008      0.572370  0.850230  0.832544  \n",
      "Patricia   0.868050      0.585028  0.844526  0.847329  \n",
      "Jennifer   0.866193      0.580601  0.850879  0.852066  \n",
      "Linda      0.859121      0.574943  0.852282  0.852313  \n",
      "Barbara    0.862790      0.578602  0.845594  0.839388  \n",
      "Margaret   0.861983      0.575837  0.848738  0.826322  \n",
      "Susan      0.870597      0.585045  0.858535  0.849264  \n",
      "Dorothy    0.869979      0.579152  0.847217  0.836672  \n",
      "Sarah      0.870801      0.573110  0.856497  0.849480  \n",
      "Jessica    0.864832      0.588993  0.857387  0.854542  \n",
      "Helen      0.864931      0.582576  0.854990  0.841388  \n",
      "Nancy      0.869063      0.573790  0.855017  0.854550  \n",
      "Betty      0.869883      0.576328  0.849667  0.835117  \n",
      "Karen      0.873152      0.591163  0.870187  0.866177  \n",
      "Lisa       0.862889      0.578305  0.859572  0.855284  \n",
      "Anna       0.857576      0.577637  0.848205  0.840872  \n",
      "Sandra     0.866384      0.572069  0.848271  0.841271  \n",
      "Emily      0.869915      0.589889  0.862785  0.861457  \n",
      "Ashley     0.867057      0.599566  0.864007  0.868646  \n",
      "Cosine Similarity Matrix: Female Names vs Unpleasant Words\n",
      "               rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Mary       0.840488  0.842038      0.569220  0.601719  0.826156  0.854196   \n",
      "Elizabeth  0.853587  0.848558      0.581975  0.605353  0.843344  0.854169   \n",
      "Patricia   0.858891  0.860092      0.595379  0.611608  0.847915  0.858541   \n",
      "Jennifer   0.856680  0.860912      0.595557  0.611809  0.858537  0.864834   \n",
      "Linda      0.854590  0.854133      0.589696  0.608465  0.851023  0.857384   \n",
      "Barbara    0.849992  0.850055      0.590162  0.612293  0.846760  0.854780   \n",
      "Margaret   0.854921  0.848195      0.586763  0.610929  0.849384  0.859809   \n",
      "Susan      0.863758  0.858999      0.595688  0.615167  0.852640  0.868243   \n",
      "Dorothy    0.854210  0.858271      0.590065  0.616859  0.846388  0.857760   \n",
      "Sarah      0.867376  0.853007      0.585184  0.617776  0.851541  0.861799   \n",
      "Jessica    0.864114  0.861727      0.604026  0.617533  0.861622  0.874186   \n",
      "Helen      0.859780  0.854051      0.589579  0.613435  0.850479  0.864916   \n",
      "Nancy      0.861056  0.865517      0.589835  0.620604  0.856697  0.870514   \n",
      "Betty      0.856489  0.857517      0.585142  0.619124  0.850555  0.872115   \n",
      "Karen      0.881634  0.873537      0.605365  0.632277  0.875987  0.885319   \n",
      "Lisa       0.868165  0.859475      0.591703  0.622363  0.861735  0.876812   \n",
      "Anna       0.853722  0.844685      0.591571  0.611893  0.843961  0.854078   \n",
      "Sandra     0.854438  0.847555      0.591603  0.608705  0.852820  0.861304   \n",
      "Emily      0.871232  0.864158      0.603525  0.622031  0.866092  0.873598   \n",
      "Ashley     0.864387  0.871402      0.625514  0.624959  0.892821  0.898790   \n",
      "\n",
      "            violent    bitter     harsh     angry  \n",
      "Mary       0.829586  0.858384  0.839903  0.876209  \n",
      "Elizabeth  0.833186  0.865362  0.850001  0.881526  \n",
      "Patricia   0.841736  0.875126  0.858046  0.890940  \n",
      "Jennifer   0.838076  0.877563  0.857113  0.893924  \n",
      "Linda      0.832153  0.866592  0.849461  0.886151  \n",
      "Barbara    0.833222  0.869404  0.850766  0.883989  \n",
      "Margaret   0.836610  0.869055  0.854548  0.884749  \n",
      "Susan      0.835016  0.880365  0.858732  0.894550  \n",
      "Dorothy    0.837762  0.874424  0.858358  0.890676  \n",
      "Sarah      0.824684  0.873371  0.859975  0.891938  \n",
      "Jessica    0.835982  0.880249  0.868601  0.893906  \n",
      "Helen      0.834110  0.873730  0.855142  0.893140  \n",
      "Nancy      0.836732  0.879366  0.861884  0.892845  \n",
      "Betty      0.837950  0.880422  0.859117  0.893242  \n",
      "Karen      0.841522  0.889730  0.874131  0.899727  \n",
      "Lisa       0.823772  0.878469  0.853625  0.891269  \n",
      "Anna       0.828589  0.869558  0.847843  0.887261  \n",
      "Sandra     0.831310  0.872115  0.852973  0.889279  \n",
      "Emily      0.842591  0.888129  0.869027  0.897776  \n",
      "Ashley     0.850679  0.894833  0.879033  0.902522  \n"
     ]
    }
   ],
   "source": [
    "# Female Names\n",
    "# Pleasant Words\n",
    "similarities_FvP = cosine_similarity(Female_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_FvU = cosine_similarity(Female_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_FvP = pd.DataFrame(similarities_FvP, index = Female_Names, columns = Pleasant_Words)\n",
    "similarities_FvU = pd.DataFrame(similarities_FvU, index = Female_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Female Names vs Pleasant Words\")\n",
    "print(similarities_FvP)\n",
    "print(\"Cosine Similarity Matrix: Female Names vs Unpleasant Words\")\n",
    "print(similarities_FvU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4844ca",
   "metadata": {},
   "source": [
    "# TEST 3: Gender Biases in Careers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4dc4744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Male Names vs STEM Careers\n",
      "             Software Developer  Nurse Practitioner  Health Services Manager  \\\n",
      "James                  0.589579            0.562634                 0.572918   \n",
      "John                   0.573784            0.543518                 0.554346   \n",
      "Robert                 0.570804            0.545791                 0.558728   \n",
      "Michael                0.590285            0.560835                 0.572731   \n",
      "William                0.572450            0.549632                 0.559678   \n",
      "David                  0.600034            0.567963                 0.579572   \n",
      "Joseph                 0.576083            0.547407                 0.554489   \n",
      "Richard                0.585791            0.556313                 0.571098   \n",
      "Charles                0.575990            0.550422                 0.558122   \n",
      "Thomas                 0.594539            0.567068                 0.572679   \n",
      "Christopher            0.598090            0.567168                 0.575208   \n",
      "Daniel                 0.593160            0.567353                 0.576714   \n",
      "Matthew                0.499117            0.471154                 0.484662   \n",
      "George                 0.580207            0.551597                 0.566984   \n",
      "Anthony                0.599989            0.575143                 0.585148   \n",
      "Donald                 0.572792            0.541730                 0.559380   \n",
      "Paul                   0.599175            0.564564                 0.573187   \n",
      "Mark                   0.595204            0.563354                 0.576037   \n",
      "Andrew                 0.601055            0.571175                 0.584151   \n",
      "Edward                 0.604900            0.577983                 0.591616   \n",
      "\n",
      "             Physicians Assistant  Security Analyst  IT Manager  \\\n",
      "James                    0.577254          0.579659    0.598339   \n",
      "John                     0.554706          0.557919    0.587496   \n",
      "Robert                   0.568717          0.562640    0.577636   \n",
      "Michael                  0.575146          0.582836    0.610623   \n",
      "William                  0.563645          0.562639    0.576171   \n",
      "David                    0.579067          0.586797    0.615692   \n",
      "Joseph                   0.563389          0.566443    0.588405   \n",
      "Richard                  0.576309          0.572518    0.592081   \n",
      "Charles                  0.566620          0.565247    0.579182   \n",
      "Thomas                   0.584463          0.580757    0.588777   \n",
      "Christopher              0.586665          0.581280    0.601965   \n",
      "Daniel                   0.579602          0.579721    0.606808   \n",
      "Matthew                  0.488650          0.489198    0.497140   \n",
      "George                   0.568343          0.570524    0.591716   \n",
      "Anthony                  0.595140          0.592029    0.603092   \n",
      "Donald                   0.561877          0.567201    0.587527   \n",
      "Paul                     0.578804          0.583951    0.614420   \n",
      "Mark                     0.575075          0.584837    0.608530   \n",
      "Andrew                   0.589960          0.587913    0.611275   \n",
      "Edward                   0.596693          0.598498    0.607074   \n",
      "\n",
      "             Web Developer   Dentist  Orthodontist  Computer Systems Analyst  \n",
      "James             0.593392  0.879045      0.559293                  0.553995  \n",
      "John              0.576897  0.853943      0.540588                  0.535926  \n",
      "Robert            0.574104  0.856102      0.543260                  0.541578  \n",
      "Michael           0.596576  0.896559      0.562255                  0.553182  \n",
      "William           0.573260  0.848357      0.545628                  0.540504  \n",
      "David             0.603102  0.885392      0.567501                  0.558834  \n",
      "Joseph            0.577152  0.870581      0.551935                  0.540728  \n",
      "Richard           0.589109  0.870402      0.555250                  0.548892  \n",
      "Charles           0.573422  0.855428      0.548837                  0.543664  \n",
      "Thomas            0.595738  0.872121      0.558197                  0.558500  \n",
      "Christopher       0.602769  0.881275      0.565414                  0.555478  \n",
      "Daniel            0.596830  0.887559      0.567307                  0.552348  \n",
      "Matthew           0.501599  0.754351      0.470561                  0.474704  \n",
      "George            0.577994  0.874567      0.550909                  0.542845  \n",
      "Anthony           0.604552  0.888585      0.568906                  0.560902  \n",
      "Donald            0.576352  0.872114      0.546712                  0.542947  \n",
      "Paul              0.601525  0.889052      0.562060                  0.558420  \n",
      "Mark              0.602022  0.897258      0.567170                  0.556903  \n",
      "Andrew            0.606854  0.890854      0.570428                  0.559098  \n",
      "Edward            0.605540  0.894969      0.578519                  0.567683  \n",
      "Cosine Similarity Matrix: Male Names vs Non-STEM Careers\n",
      "               Artist  Marketing Manager  Social Worker  Attorney  Journalist  \\\n",
      "James        0.840529           0.571940       0.597125  0.889874    0.873915   \n",
      "John         0.813862           0.551107       0.579258  0.855068    0.840434   \n",
      "Robert       0.810184           0.549693       0.578096  0.866146    0.843790   \n",
      "Michael      0.838693           0.575090       0.598803  0.887650    0.865598   \n",
      "William      0.804117           0.551904       0.585486  0.857572    0.842263   \n",
      "David        0.843413           0.578895       0.599858  0.888310    0.875409   \n",
      "Joseph       0.824480           0.551605       0.584453  0.880174    0.862927   \n",
      "Richard      0.832513           0.563269       0.588724  0.878799    0.867601   \n",
      "Charles      0.817563           0.549615       0.577919  0.872267    0.855533   \n",
      "Thomas       0.826890           0.569309       0.596687  0.886004    0.870472   \n",
      "Christopher  0.847359           0.574209       0.603349  0.893117    0.879942   \n",
      "Daniel       0.838798           0.577168       0.600778  0.894028    0.875241   \n",
      "Matthew      0.710288           0.483283       0.495382  0.757226    0.733619   \n",
      "George       0.817152           0.563763       0.585448  0.878131    0.852591   \n",
      "Anthony      0.854046           0.581464       0.608954  0.903704    0.873743   \n",
      "Donald       0.807851           0.554261       0.575073  0.873563    0.841044   \n",
      "Paul         0.844985           0.576564       0.603391  0.892273    0.872559   \n",
      "Mark         0.858943           0.582124       0.596017  0.893030    0.876733   \n",
      "Andrew       0.846305           0.585096       0.606935  0.898641    0.875555   \n",
      "Edward       0.836856           0.579980       0.609988  0.898973    0.873950   \n",
      "\n",
      "             Musician   Teacher  Media Manager  Graphic Designer     Judge  \n",
      "James        0.820038  0.849269       0.588695          0.575931  0.916201  \n",
      "John         0.791380  0.818780       0.565158          0.558507  0.888956  \n",
      "Robert       0.783775  0.820647       0.572712          0.547949  0.900105  \n",
      "Michael      0.810405  0.853926       0.588141          0.571844  0.913420  \n",
      "William      0.780216  0.815633       0.567775          0.549147  0.891022  \n",
      "David        0.814408  0.848050       0.595264          0.584973  0.916848  \n",
      "Joseph       0.801194  0.841711       0.569138          0.561875  0.901419  \n",
      "Richard      0.810295  0.835128       0.585345          0.571524  0.908447  \n",
      "Charles      0.800477  0.825170       0.571234          0.558065  0.898223  \n",
      "Thomas       0.820368  0.846183       0.585206          0.570930  0.903670  \n",
      "Christopher  0.825995  0.850061       0.594412          0.584166  0.923300  \n",
      "Daniel       0.812398  0.855327       0.594204          0.575044  0.924726  \n",
      "Matthew      0.693257  0.723332       0.498658          0.481404  0.775294  \n",
      "George       0.796460  0.831254       0.580221          0.561336  0.900475  \n",
      "Anthony      0.836595  0.856548       0.603197          0.584131  0.907184  \n",
      "Donald       0.786104  0.822334       0.572916          0.551466  0.884246  \n",
      "Paul         0.821504  0.856728       0.587623          0.579857  0.916585  \n",
      "Mark         0.826012  0.861640       0.596993          0.580580  0.931109  \n",
      "Andrew       0.826352  0.854173       0.605965          0.579296  0.919189  \n",
      "Edward       0.820399  0.848358       0.603896          0.574689  0.910637  \n"
     ]
    }
   ],
   "source": [
    "# Male Names\n",
    "# STEM Careers\n",
    "similarities_MvS = cosine_similarity(Male_Embeddings, STEM_Embeddings)\n",
    "# Non-STEM Careers\n",
    "similarities_MvN = cosine_similarity(Male_Embeddings, Non_STEM_Embeddings)\n",
    "similarities_MvS = pd.DataFrame(similarities_MvS, index = Male_Names, columns = STEM_Careers)\n",
    "similarities_MvN = pd.DataFrame(similarities_MvN, index = Male_Names, columns = Non_STEM_Careers)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs STEM Careers\")\n",
    "print(similarities_MvS)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs Non-STEM Careers\")\n",
    "print(similarities_MvN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b00b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Female Names vs STEM Careers\n",
      "           Software Developer  Nurse Practitioner  Health Services Manager  \\\n",
      "Mary                 0.563337            0.550620                 0.551723   \n",
      "Elizabeth            0.568699            0.557077                 0.558597   \n",
      "Patricia             0.586332            0.567841                 0.574657   \n",
      "Jennifer             0.589088            0.568630                 0.577538   \n",
      "Linda                0.590680            0.571281                 0.577778   \n",
      "Barbara              0.588550            0.568595                 0.576739   \n",
      "Margaret             0.586419            0.567839                 0.570089   \n",
      "Susan                0.582947            0.566564                 0.572588   \n",
      "Dorothy              0.583174            0.566267                 0.571291   \n",
      "Sarah                0.574966            0.557214                 0.560213   \n",
      "Jessica              0.597947            0.571494                 0.578518   \n",
      "Helen                0.582819            0.564461                 0.570038   \n",
      "Nancy                0.575568            0.551494                 0.560501   \n",
      "Betty                0.577275            0.561409                 0.565649   \n",
      "Karen                0.597875            0.572842                 0.578351   \n",
      "Lisa                 0.585555            0.556483                 0.564001   \n",
      "Anna                 0.591005            0.570566                 0.573815   \n",
      "Sandra               0.579227            0.558982                 0.568964   \n",
      "Emily                0.595448            0.572121                 0.577806   \n",
      "Ashley               0.603661            0.578056                 0.593186   \n",
      "\n",
      "           Physicians Assistant  Security Analyst  IT Manager  Web Developer  \\\n",
      "Mary                   0.556526          0.552035    0.584486       0.569787   \n",
      "Elizabeth              0.568473          0.560317    0.582673       0.575249   \n",
      "Patricia               0.578657          0.576682    0.596130       0.588067   \n",
      "Jennifer               0.578000          0.579471    0.603960       0.594316   \n",
      "Linda                  0.576657          0.576564    0.605055       0.592598   \n",
      "Barbara                0.578448          0.575490    0.599309       0.589241   \n",
      "Margaret               0.571491          0.573146    0.600316       0.587833   \n",
      "Susan                  0.578437          0.572963    0.606612       0.592139   \n",
      "Dorothy                0.576129          0.574636    0.602257       0.587195   \n",
      "Sarah                  0.564077          0.563357    0.599450       0.582374   \n",
      "Jessica                0.578998          0.585843    0.614623       0.601706   \n",
      "Helen                  0.574252          0.574701    0.605526       0.588629   \n",
      "Nancy                  0.558200          0.567252    0.592265       0.579858   \n",
      "Betty                  0.569752          0.565529    0.602284       0.584156   \n",
      "Karen                  0.574677          0.585269    0.621251       0.602158   \n",
      "Lisa                   0.564428          0.571530    0.607568       0.590315   \n",
      "Anna                   0.576014          0.579636    0.602921       0.589357   \n",
      "Sandra                 0.572332          0.571213    0.597638       0.582851   \n",
      "Emily                  0.584394          0.581782    0.611929       0.600602   \n",
      "Ashley                 0.592615          0.595724    0.614122       0.606011   \n",
      "\n",
      "            Dentist  Orthodontist  Computer Systems Analyst  \n",
      "Mary       0.856566      0.538451                  0.528443  \n",
      "Elizabeth  0.861329      0.549157                  0.537424  \n",
      "Patricia   0.878873      0.564103                  0.550317  \n",
      "Jennifer   0.882908      0.562118                  0.550167  \n",
      "Linda      0.882496      0.556543                  0.551646  \n",
      "Barbara    0.881067      0.560888                  0.550549  \n",
      "Margaret   0.880881      0.555817                  0.545881  \n",
      "Susan      0.884583      0.561423                  0.549753  \n",
      "Dorothy    0.878583      0.556757                  0.546277  \n",
      "Sarah      0.871897      0.550713                  0.533668  \n",
      "Jessica    0.891649      0.570202                  0.554044  \n",
      "Helen      0.881344      0.563785                  0.547580  \n",
      "Nancy      0.871913      0.551235                  0.538750  \n",
      "Betty      0.879609      0.550321                  0.539483  \n",
      "Karen      0.904765      0.565758                  0.557675  \n",
      "Lisa       0.890873      0.559109                  0.547550  \n",
      "Anna       0.883272      0.563235                  0.553298  \n",
      "Sandra     0.875404      0.549731                  0.544522  \n",
      "Emily      0.896091      0.568092                  0.553589  \n",
      "Ashley     0.903592      0.571624                  0.567131  \n",
      "Cosine Similarity Matrix: Female Names vs Non-STEM Careers\n",
      "             Artist  Marketing Manager  Social Worker  Attorney  Journalist  \\\n",
      "Mary       0.823471           0.550530       0.580434  0.860482    0.846182   \n",
      "Elizabeth  0.831950           0.552770       0.586763  0.874107    0.862070   \n",
      "Patricia   0.840987           0.567357       0.599521  0.888676    0.877059   \n",
      "Jennifer   0.851859           0.577035       0.604012  0.893543    0.879962   \n",
      "Linda      0.848329           0.580238       0.605211  0.884922    0.876765   \n",
      "Barbara    0.846289           0.573128       0.605791  0.890705    0.874295   \n",
      "Margaret   0.837006           0.568934       0.606266  0.877308    0.866384   \n",
      "Susan      0.846114           0.576496       0.605512  0.891749    0.876144   \n",
      "Dorothy    0.842771           0.572354       0.604960  0.885994    0.872862   \n",
      "Sarah      0.840484           0.568116       0.593737  0.878218    0.866373   \n",
      "Jessica    0.851093           0.583521       0.612200  0.895874    0.878644   \n",
      "Helen      0.847716           0.572690       0.603544  0.885096    0.876848   \n",
      "Nancy      0.829907           0.560578       0.587640  0.879301    0.862281   \n",
      "Betty      0.839614           0.567823       0.602785  0.879651    0.867687   \n",
      "Karen      0.849343           0.584325       0.610580  0.893075    0.875703   \n",
      "Lisa       0.850284           0.572017       0.590251  0.876493    0.865382   \n",
      "Anna       0.850437           0.571667       0.599529  0.884406    0.874557   \n",
      "Sandra     0.837987           0.571488       0.596430  0.880598    0.866822   \n",
      "Emily      0.860056           0.580352       0.610624  0.899786    0.882276   \n",
      "Ashley     0.851540           0.589939       0.615305  0.896830    0.868971   \n",
      "\n",
      "           Musician   Teacher  Media Manager  Graphic Designer     Judge  \n",
      "Mary       0.790362  0.837702       0.563714          0.557066  0.902367  \n",
      "Elizabeth  0.798845  0.839379       0.572681          0.561593  0.913716  \n",
      "Patricia   0.810516  0.851983       0.589554          0.574634  0.922780  \n",
      "Jennifer   0.817694  0.858983       0.595429          0.584461  0.924398  \n",
      "Linda      0.819477  0.857958       0.596357          0.582448  0.918951  \n",
      "Barbara    0.812460  0.849943       0.591675          0.577490  0.916519  \n",
      "Margaret   0.814596  0.848420       0.582774          0.572000  0.905115  \n",
      "Susan      0.812155  0.858939       0.590830          0.575746  0.924512  \n",
      "Dorothy    0.811196  0.853167       0.588670          0.573405  0.919264  \n",
      "Sarah      0.803890  0.856054       0.579010          0.568463  0.925022  \n",
      "Jessica    0.821472  0.866159       0.598295          0.587220  0.925901  \n",
      "Helen      0.812399  0.858164       0.589122          0.574311  0.921643  \n",
      "Nancy      0.795524  0.844980       0.575596          0.561955  0.920614  \n",
      "Betty      0.805457  0.853801       0.580100          0.572992  0.911037  \n",
      "Karen      0.821319  0.871788       0.592000          0.587100  0.918491  \n",
      "Lisa       0.811611  0.861264       0.581000          0.577503  0.911208  \n",
      "Anna       0.823057  0.853939       0.585336          0.580847  0.909244  \n",
      "Sandra     0.804004  0.850461       0.586901          0.568487  0.922146  \n",
      "Emily      0.827280  0.870187       0.593985          0.585161  0.922922  \n",
      "Ashley     0.825288  0.860826       0.607747          0.577032  0.906039  \n"
     ]
    }
   ],
   "source": [
    "# Female Names\n",
    "# STEM Careers\n",
    "similarities_FvS = cosine_similarity(Female_Embeddings, STEM_Embeddings)\n",
    "# Non-STEM Careers\n",
    "similarities_FvN = cosine_similarity(Female_Embeddings, Non_STEM_Embeddings)\n",
    "similarities_FvS = pd.DataFrame(similarities_FvS, index = Female_Names, columns = STEM_Careers)\n",
    "similarities_FvN = pd.DataFrame(similarities_FvN, index = Female_Names, columns = Non_STEM_Careers)\n",
    "print(\"Cosine Similarity Matrix: Female Names vs STEM Careers\")\n",
    "print(similarities_FvS)\n",
    "print(\"Cosine Similarity Matrix: Female Names vs Non-STEM Careers\")\n",
    "print(similarities_FvN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42b01746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DataFrame  avgCS_ERNIE_2_base_en\n",
      "0       AFvP               0.672820\n",
      "1       AFvU               0.671384\n",
      "2       EUvP               0.768552\n",
      "3       EUvU               0.805604\n",
      "4       LXvP               0.771444\n",
      "5       LXvU               0.809464\n",
      "6       CHvP               0.708923\n",
      "7       CHvU               0.724417\n",
      "8        MvP               0.765842\n",
      "9        MvU               0.804958\n",
      "10       FvP               0.773231\n",
      "11       FvU               0.810454\n",
      "12       MvS               0.600026\n",
      "13       MvN               0.740034\n",
      "14       FvS               0.604837\n",
      "15       FvN               0.751895\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Mean cosine similarity of each test\n",
    "\n",
    "dataframes_dict = {\n",
    "    'AFvP': similarities_AFvP,\n",
    "    'AFvU': similarities_AFvU,\n",
    "    'EUvP': similarities_EUvP,\n",
    "    'EUvU': similarities_EUvU,\n",
    "    'LXvP': similarities_LXvP,\n",
    "    'LXvU': similarities_LXvU,\n",
    "    'CHvP': similarities_CHvP,\n",
    "    'CHvU': similarities_CHvU,\n",
    "    'MvP': similarities_MvP,\n",
    "    'MvU': similarities_MvU,\n",
    "    'FvP': similarities_FvP,\n",
    "    'FvU': similarities_FvU,\n",
    "    'MvS': similarities_MvS,\n",
    "    'MvN': similarities_MvN,\n",
    "    'FvS': similarities_FvS,\n",
    "    'FvN': similarities_FvN\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the means\n",
    "mean_dict = {}\n",
    "\n",
    "# Calculate the mean for each DataFrame and store it in the mean_dict\n",
    "for df_name, df in dataframes_dict.items():\n",
    "    df = pd.DataFrame(df)\n",
    "    mean_value = df.values.mean()\n",
    "    mean_dict[df_name] = mean_value\n",
    "\n",
    "# Create a new DataFrame from the mean_dict\n",
    "mean_df = pd.DataFrame(list(mean_dict.items()), columns=['DataFrame', 'avgCS_ERNIE_2_base_en'])\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(mean_df)\n",
    "\n",
    "#Save to .csv\n",
    "mean_df.to_csv('ERNIE_2_base_en_meanCosSim.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ba12f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFvP.csv was created\n",
      "AFvU.csv was created\n",
      "EUvP.csv was created\n",
      "EUvU.csv was created\n",
      "LXvP.csv was created\n",
      "LXvU.csv was created\n",
      "CHvP.csv was created\n",
      "CHvU.csv was created\n",
      "MvP.csv was created\n",
      "MvU.csv was created\n",
      "FvP.csv was created\n",
      "FvU.csv was created\n",
      "MvS.csv was created\n",
      "MvN.csv was created\n",
      "FvS.csv was created\n",
      "FvN.csv was created\n"
     ]
    }
   ],
   "source": [
    "for key, df in dataframes_dict.items():\n",
    "    # Construct the file path using the key\n",
    "    file_path = f\"{key}.csv\"\n",
    "    \n",
    "    # Write the DataFrame to the CSV file\n",
    "    df.to_csv(file_path, index=True)\n",
    "    print(f\"{key}.csv was created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
