{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339e3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (4.32.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (3.12.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac58803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (4.32.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: nltk in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sentence-transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\n",
      "Requirement already satisfied: click in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c953798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (2.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (3.12.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87367d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4108488",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34a405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan Ackerman\\anaconda3\\envs\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Function to generate word embeddings for a list of words\n",
    "def get_word_embeddings(word_list):\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/stsb-xlm-r-multilingual')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/stsb-xlm-r-multilingual')\n",
    "\n",
    "    # Tokenize words\n",
    "    encoded_input = tokenizer(word_list, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, mean pooling.\n",
    "    word_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    return word_embeddings\n",
    "\n",
    "# Word Sets and Embeddings\n",
    "AF_Names = [\"Reginald\", \"Kameron\", \"Kendrick\", \"Javon\", \"Tyrell\", \"Jamar\", \"Camron\", \"Tyree\", \"Jamari\", \"Reggie\", \"Jada\", \n",
    "            \"Latoya\", \"Jayla\", \"Tamika\", \"Latoyna\", \"Journey\", \"Tameka\", \"Journee\", \"Lawanda\", \"Janiya\"]\n",
    "AF_Embeddings = get_word_embeddings(AF_Names)\n",
    "\n",
    "EU_Names = [\"James\", \"John\", \"Robert\", \"Michael\", \"William\", \"David\", \"Joseph\", \"Richard\", \"Charles\", \"Thomas\", \"Mary\", \n",
    "            \"Elizabeth\", \"Patricia\", \"Jennifer\", \"Linda\", \"Barbara\", \"Margaret\", \"Susan\", \"Sarah\", \"Jessica\"]\n",
    "EU_Embeddings = get_word_embeddings(EU_Names)\n",
    "\n",
    "LX_Names = [\"Paul\", \"Vincent\", \"Victor\", \"Adrian\", \"Marcus\", \"Leo\", \"Miles\", \"Roman\", \"Sergio\", \"Felix\", \"Patricia\", \"Laura\", \n",
    "            \"Amanda\", \"Victoria\", \"Julia\", \"Gloria\", \"Diana\", \"Clara\", \"Paula\", \"Norma\"]\n",
    "LX_Embeddings = get_word_embeddings(LX_Names)\n",
    "\n",
    "CH_Names = [\"Lian\", \"Shan\", \"Lew\", \"Long\", \"Quan\", \"Jun\", \"Tou\", \"Jin\", \"Cai\", \"Chan\", \"Lue\", \"China\", \"Lu\", \"Maylee\", \n",
    "            \"Tennie\", \"Maylin\", \"Chynna\", \"Jia\", \"Mei\", \"Tylee\"]\n",
    "CH_Embeddings = get_word_embeddings(CH_Names)\n",
    "\n",
    "Male_Names = [\"James\", \"John\", \"Robert\", \"Michael\", \"William\", \"David\", \"Joseph\", \"Richard\", \"Charles\", \"Thomas\", \n",
    "              \"Christopher\", \"Daniel\", \"Matthew\",\"George\", \"Anthony\", \"Donald\", \"Paul\", \"Mark\", \"Andrew\", \"Edward\"]\n",
    "Male_Embeddings = get_word_embeddings(Male_Names)\n",
    "\n",
    "Female_Names = [\"Mary\", \"Elizabeth\", \"Patricia\", \"Jennifer\", \"Linda\", \"Barbara\", \"Margaret\", \"Susan\", \"Dorothy\", \"Sarah\", \n",
    "                \"Jessica\", \"Helen\", \"Nancy\", \"Betty\", \"Karen\", \"Lisa\", \"Anna\", \"Sandra\", \"Emily\", \"Ashley\"]\n",
    "Female_Embeddings = get_word_embeddings(Female_Names)\n",
    "\n",
    "Pleasant_Words = [\"happy\", \"agreeable\", \"polite\", \"civil\", \"charming\", \"gracious\", \"gentle\", \"approachable\", \"love\", \"cool\"]\n",
    "Pleasant_Embeddings = get_word_embeddings(Pleasant_Words)\n",
    "\n",
    "Unpleasant_Words = [\"rude\", \"lazy\", \"disagreeable\", \"lousy\", \"sad\", \"hate\", \"violent\", \"bitter\", \"harsh\", \"angry\"]\n",
    "Unpleasant_Embeddings = get_word_embeddings(Unpleasant_Words)\n",
    "\n",
    "STEM_Careers = [\"Software Developer\", \"Nurse Practitioner\", \"Health Services Manager\", \"Physicians Assistant\", \n",
    "                \"Security Analyst\", \"IT Manager\", \"Web Developer\", \"Dentist\", \"Orthodontist\", \"Computer Systems Analyst\"]\n",
    "STEM_Embeddings = get_word_embeddings(STEM_Careers)\n",
    "\n",
    "Non_STEM_Careers = [\"Artist\", \"Marketing Manager\", \"Social Worker\", \"Attorney\", \"Journalist\", \"Musician\", \"Teacher\", \n",
    "                    \"Media Manager\", \"Graphic Designer\", \"Judge\"]\n",
    "Non_STEM_Embeddings = get_word_embeddings(Non_STEM_Careers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c8cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f0792c",
   "metadata": {},
   "source": [
    "# TEST 1: Racial Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50bd0cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: African American Names vs Pleasant Words\n",
      "             happy  agreeable    polite     civil  charming  gracious  \\\n",
      "Reginald  0.251451   0.336781  0.270186  0.455528  0.255503  0.395091   \n",
      "Kameron   0.345501   0.432027  0.346713  0.535653  0.380548  0.466049   \n",
      "Kendrick  0.286963   0.304898  0.265309  0.428886  0.284983  0.333557   \n",
      "Javon     0.581219   0.720114  0.567750  0.665883  0.569917  0.678357   \n",
      "Tyrell    0.167682   0.215830  0.132785  0.306261  0.125179  0.275866   \n",
      "Jamar     0.333945   0.423138  0.361205  0.528163  0.389374  0.444588   \n",
      "Camron    0.187255   0.257835  0.199191  0.372229  0.235140  0.271400   \n",
      "Tyree     0.167132   0.235636  0.173084  0.356342  0.135066  0.270053   \n",
      "Jamari    0.361961   0.453313  0.388979  0.567708  0.381640  0.498078   \n",
      "Reggie    0.262960   0.344005  0.283137  0.444531  0.266000  0.394189   \n",
      "Jada      0.558019   0.695319  0.562276  0.704156  0.589314  0.669501   \n",
      "Latoya    0.226073   0.312497  0.274876  0.470642  0.300484  0.349875   \n",
      "Jayla     0.271571   0.350215  0.268121  0.420210  0.261848  0.339501   \n",
      "Tamika    0.336136   0.443454  0.362558  0.558043  0.364574  0.469228   \n",
      "Latoyna   0.208764   0.302854  0.283690  0.465787  0.290932  0.334232   \n",
      "Journey   0.215318   0.262492  0.231158  0.358417  0.251202  0.280183   \n",
      "Tameka    0.453858   0.587374  0.492947  0.701462  0.493603  0.602828   \n",
      "Journee   0.424775   0.506055  0.406500  0.631484  0.430968  0.559216   \n",
      "Lawanda   0.203190   0.335875  0.219400  0.416707  0.242220  0.350184   \n",
      "Janiya    0.307460   0.365516  0.350779  0.499001  0.341582  0.392365   \n",
      "\n",
      "            gentle  approachable      love      cool  \n",
      "Reginald  0.254646      0.322885  0.362187  0.305940  \n",
      "Kameron   0.311353      0.532099  0.413708  0.438198  \n",
      "Kendrick  0.300714      0.431924  0.270858  0.381585  \n",
      "Javon     0.421198      0.715100  0.550322  0.643211  \n",
      "Tyrell    0.175760      0.271326  0.238476  0.171100  \n",
      "Jamar     0.354240      0.538358  0.374517  0.382548  \n",
      "Camron    0.251790      0.390400  0.287132  0.326125  \n",
      "Tyree     0.215956      0.294509  0.232579  0.208448  \n",
      "Jamari    0.349423      0.558296  0.410216  0.406758  \n",
      "Reggie    0.282601      0.336435  0.325975  0.356275  \n",
      "Jada      0.475221      0.702399  0.561048  0.636229  \n",
      "Latoya    0.357235      0.409909  0.363998  0.245870  \n",
      "Jayla     0.291451      0.433936  0.328352  0.283282  \n",
      "Tamika    0.386231      0.531118  0.399974  0.401854  \n",
      "Latoyna   0.332832      0.379249  0.355817  0.240231  \n",
      "Journey   0.247401      0.428287  0.279014  0.268914  \n",
      "Tameka    0.488754      0.651615  0.522595  0.552283  \n",
      "Journee   0.379732      0.597784  0.459778  0.461525  \n",
      "Lawanda   0.252920      0.394428  0.288957  0.290652  \n",
      "Janiya    0.345806      0.434311  0.367589  0.338256  \n",
      "Cosine Similarity Matrix: African American Names vs Unpleasant Words\n",
      "              rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Reginald  0.142754  0.144687      0.222586  0.351125  0.415403  0.141322   \n",
      "Kameron   0.223685  0.126531      0.281062  0.312382  0.691784  0.148069   \n",
      "Kendrick  0.269613  0.211569      0.286180  0.269960  0.441437  0.024427   \n",
      "Javon     0.295571  0.186654      0.383879  0.424852  0.780870  0.250999   \n",
      "Tyrell    0.169271  0.100743      0.197246  0.340917  0.422963  0.084399   \n",
      "Jamar     0.297543  0.196823      0.353823  0.366356  0.658982  0.184823   \n",
      "Camron    0.141189  0.090020      0.184883  0.234048  0.602451  0.094327   \n",
      "Tyree     0.208607  0.179456      0.230988  0.345384  0.406807  0.137170   \n",
      "Jamari    0.331672  0.202442      0.366417  0.396405  0.700468  0.210923   \n",
      "Reggie    0.168606  0.208756      0.221646  0.301348  0.404042  0.168198   \n",
      "Jada      0.318124  0.250500      0.398224  0.455675  0.793474  0.287849   \n",
      "Latoya    0.121640  0.117210      0.154761  0.293630  0.549466  0.167058   \n",
      "Jayla     0.151045  0.105634      0.207478  0.232700  0.569373  0.094910   \n",
      "Tamika    0.256396  0.227203      0.332420  0.352332  0.636846  0.221655   \n",
      "Latoyna   0.163696  0.103751      0.186681  0.305822  0.590057  0.184238   \n",
      "Journey   0.133109  0.092770      0.161634  0.195087  0.480820  0.045951   \n",
      "Tameka    0.343271  0.306398      0.411263  0.463621  0.755093  0.275958   \n",
      "Journee   0.296544  0.211474      0.369959  0.460910  0.753427  0.224545   \n",
      "Lawanda   0.173316  0.110717      0.238682  0.281787  0.521890  0.108743   \n",
      "Janiya    0.189176  0.183588      0.255283  0.221004  0.521112  0.136253   \n",
      "\n",
      "           violent    bitter     harsh     angry  \n",
      "Reginald  0.068796  0.269433  0.244903  0.158244  \n",
      "Kameron   0.223168  0.277776  0.346433  0.221725  \n",
      "Kendrick  0.123455  0.110705  0.245997  0.145182  \n",
      "Javon     0.269643  0.320615  0.487176  0.344547  \n",
      "Tyrell    0.124608  0.326428  0.268320  0.197439  \n",
      "Jamar     0.270770  0.329305  0.431816  0.283847  \n",
      "Camron    0.198963  0.180148  0.227682  0.153013  \n",
      "Tyree     0.089023  0.354582  0.281420  0.220836  \n",
      "Jamari    0.281373  0.360884  0.462715  0.334487  \n",
      "Reggie    0.054993  0.238353  0.245790  0.196936  \n",
      "Jada      0.269919  0.380373  0.505676  0.350370  \n",
      "Latoya    0.133315  0.340207  0.288652  0.173323  \n",
      "Jayla     0.210387  0.261374  0.295488  0.164446  \n",
      "Tamika    0.213308  0.351671  0.431819  0.308341  \n",
      "Latoyna   0.152452  0.342406  0.315046  0.187590  \n",
      "Journey   0.153814  0.190472  0.224525  0.126127  \n",
      "Tameka    0.262733  0.409123  0.501772  0.331347  \n",
      "Journee   0.269483  0.351593  0.471580  0.311310  \n",
      "Lawanda   0.263394  0.246407  0.307732  0.168610  \n",
      "Janiya    0.046795  0.215580  0.270900  0.140946  \n"
     ]
    }
   ],
   "source": [
    "# African American Names\n",
    "\n",
    "# Pleasant Words\n",
    "similarities_AFvP = cosine_similarity(AF_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_AFvU = cosine_similarity(AF_Embeddings, Unpleasant_Embeddings)\n",
    "\n",
    "similarities_AFvP = pd.DataFrame(similarities_AFvP, index = AF_Names, columns = Pleasant_Words)\n",
    "similarities_AFvU = pd.DataFrame(similarities_AFvU, index = AF_Names, columns = Unpleasant_Words)\n",
    "print(\"Cosine Similarity Matrix: African American Names vs Pleasant Words\")\n",
    "print(similarities_AFvP)\n",
    "print(\"Cosine Similarity Matrix: African American Names vs Unpleasant Words\")\n",
    "print(similarities_AFvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7b5b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: European American Names vs Pleasant Words\n",
      "              happy  agreeable    polite     civil  charming  gracious  \\\n",
      "James      0.264323   0.285021  0.238533  0.404505  0.249507  0.331670   \n",
      "John       0.263917   0.308286  0.218405  0.432454  0.219760  0.340813   \n",
      "Robert     0.159164   0.210734  0.215705  0.274650  0.127228  0.272302   \n",
      "Michael    0.336251   0.339140  0.316363  0.522873  0.347805  0.487477   \n",
      "William    0.188221   0.220080  0.115727  0.361746  0.207075  0.296012   \n",
      "David      0.238337   0.336345  0.309008  0.459027  0.248808  0.342114   \n",
      "Joseph     0.231378   0.288734  0.223294  0.325019  0.185305  0.334610   \n",
      "Richard    0.108802   0.170773  0.132427  0.247831  0.103367  0.247996   \n",
      "Charles    0.241694   0.307960  0.267634  0.391822  0.310617  0.403683   \n",
      "Thomas     0.194565   0.289645  0.272875  0.430608  0.179531  0.344031   \n",
      "Mary       0.253565   0.311784  0.283632  0.440337  0.262250  0.444240   \n",
      "Elizabeth  0.066126   0.236392  0.268022  0.386090  0.158411  0.244093   \n",
      "Patricia   0.249780   0.354225  0.431576  0.575551  0.286422  0.390637   \n",
      "Jennifer   0.284704   0.350759  0.373091  0.557006  0.363007  0.396441   \n",
      "Linda      0.277526   0.413909  0.416520  0.552094  0.331191  0.421016   \n",
      "Barbara    0.232492   0.293390  0.309994  0.458465  0.247796  0.391909   \n",
      "Margaret   0.205589   0.381567  0.421427  0.527692  0.297811  0.415891   \n",
      "Susan      0.273926   0.390113  0.430124  0.501582  0.356873  0.388446   \n",
      "Sarah      0.299965   0.346046  0.343780  0.527762  0.352815  0.425353   \n",
      "Jessica    0.189922   0.306729  0.265833  0.426969  0.202560  0.324024   \n",
      "\n",
      "             gentle  approachable      love      cool  \n",
      "James      0.260473      0.328372  0.346978  0.269803  \n",
      "John       0.248217      0.329753  0.342643  0.360968  \n",
      "Robert     0.227116      0.285967  0.252335  0.202325  \n",
      "Michael    0.284588      0.440195  0.327771  0.352296  \n",
      "William    0.161824      0.268722  0.293122  0.238665  \n",
      "David      0.307513      0.346330  0.351192  0.309119  \n",
      "Joseph     0.154034      0.305739  0.250992  0.217384  \n",
      "Richard    0.097599      0.197527  0.212759  0.133443  \n",
      "Charles    0.287647      0.396299  0.348598  0.264970  \n",
      "Thomas     0.197521      0.371155  0.253560  0.265240  \n",
      "Mary       0.337240      0.357126  0.367520  0.261206  \n",
      "Elizabeth  0.301474      0.289477  0.257811  0.200230  \n",
      "Patricia   0.385007      0.383524  0.261107  0.366656  \n",
      "Jennifer   0.396407      0.327549  0.308419  0.362524  \n",
      "Linda      0.510286      0.399634  0.396038  0.488276  \n",
      "Barbara    0.371614      0.308863  0.349188  0.360444  \n",
      "Margaret   0.420342      0.389277  0.394712  0.313597  \n",
      "Susan      0.362311      0.392647  0.355874  0.356178  \n",
      "Sarah      0.325859      0.459589  0.331870  0.325689  \n",
      "Jessica    0.253869      0.275105  0.274772  0.306744  \n",
      "Cosine Similarity Matrix: European American Names vs Unpleasant Words\n",
      "               rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "James      0.154240  0.139182      0.194497  0.190973  0.534508  0.081550   \n",
      "John       0.254573  0.208656      0.298217  0.313978  0.467413  0.148536   \n",
      "Robert     0.114121  0.105991      0.102789  0.174731  0.358823  0.022597   \n",
      "Michael    0.237259  0.139858      0.262967  0.256301  0.393899  0.110104   \n",
      "William    0.243397  0.094860      0.225378  0.270836  0.465081  0.164201   \n",
      "David      0.194300  0.131624      0.193256  0.320163  0.538393  0.131398   \n",
      "Joseph     0.095039  0.066160      0.127523  0.168309  0.379585  0.109691   \n",
      "Richard    0.170977  0.068652      0.128163  0.227864  0.258728  0.062510   \n",
      "Charles    0.106306  0.050642      0.193223  0.213339  0.368055  0.089122   \n",
      "Thomas     0.260848  0.101349      0.292655  0.244624  0.433699  0.129225   \n",
      "Mary       0.151794  0.134157      0.229747  0.345103  0.539706  0.223171   \n",
      "Elizabeth  0.081075  0.072516      0.142023  0.181180  0.390102  0.104354   \n",
      "Patricia   0.232201  0.264726      0.222431  0.227975  0.333146  0.259720   \n",
      "Jennifer   0.265566  0.318727      0.303981  0.307366  0.391505  0.252648   \n",
      "Linda      0.180105  0.279321      0.237766  0.296847  0.327389  0.145007   \n",
      "Barbara    0.224890  0.177227      0.226039  0.298381  0.343548  0.167036   \n",
      "Margaret   0.199349  0.179784      0.271070  0.286026  0.482134  0.263741   \n",
      "Susan      0.296002  0.209164      0.285018  0.278931  0.434420  0.220348   \n",
      "Sarah      0.218997  0.111856      0.271920  0.290603  0.508160  0.182492   \n",
      "Jessica    0.222629  0.235987      0.296210  0.249875  0.421599  0.238470   \n",
      "\n",
      "            violent    bitter     harsh     angry  \n",
      "James      0.143152  0.099260  0.203021  0.100106  \n",
      "John       0.180258  0.145437  0.284681  0.164928  \n",
      "Robert     0.116097  0.101235  0.169015  0.111701  \n",
      "Michael    0.120140  0.214238  0.300042  0.170971  \n",
      "William    0.261669  0.174365  0.325153  0.226022  \n",
      "David      0.141492  0.238353  0.283640  0.190714  \n",
      "Joseph     0.055649  0.104723  0.182014  0.107966  \n",
      "Richard    0.117397  0.137188  0.218662  0.108017  \n",
      "Charles    0.117206  0.154270  0.251083  0.112532  \n",
      "Thomas     0.117198  0.193824  0.276866  0.180691  \n",
      "Mary       0.158879  0.219381  0.312540  0.228649  \n",
      "Elizabeth  0.051066  0.110688  0.178405  0.063700  \n",
      "Patricia   0.085566  0.245421  0.273586  0.229582  \n",
      "Jennifer   0.178102  0.282819  0.309998  0.277051  \n",
      "Linda      0.068561  0.238386  0.216590  0.143579  \n",
      "Barbara    0.101499  0.175475  0.264450  0.204738  \n",
      "Margaret   0.103347  0.293468  0.300715  0.197692  \n",
      "Susan      0.124662  0.292561  0.331097  0.202763  \n",
      "Sarah      0.120120  0.227403  0.330081  0.204316  \n",
      "Jessica    0.127782  0.249912  0.335235  0.244793  \n"
     ]
    }
   ],
   "source": [
    "# European American Names\n",
    "# Pleasant Words\n",
    "similarities_EUvP = cosine_similarity(EU_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_EUvU = cosine_similarity(EU_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_EUvP = pd.DataFrame(similarities_EUvP, index = EU_Names, columns = Pleasant_Words)\n",
    "similarities_EUvU = pd.DataFrame(similarities_EUvU, index = EU_Names, columns = Unpleasant_Words)\n",
    "print(\"Cosine Similarity Matrix: European American Names vs Pleasant Words\")\n",
    "print(similarities_EUvP)\n",
    "print(\"Cosine Similarity Matrix: European American Names vs Unpleasant Words\")\n",
    "print(similarities_EUvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c98f3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Latin American Names vs Pleasant Words\n",
      "             happy  agreeable    polite     civil  charming  gracious  \\\n",
      "Paul      0.203060   0.277410  0.284907  0.381434  0.294371  0.333334   \n",
      "Vincent   0.245870   0.277563  0.247463  0.380615  0.187049  0.299309   \n",
      "Victor    0.286919   0.384572  0.307498  0.387690  0.352518  0.397439   \n",
      "Adrian    0.352480   0.439669  0.421379  0.529434  0.416576  0.434915   \n",
      "Marcus    0.211287   0.299989  0.312950  0.367389  0.220484  0.367903   \n",
      "Leo       0.464654   0.472990  0.321641  0.514876  0.429025  0.495930   \n",
      "Miles     0.318251   0.374962  0.233910  0.388278  0.305655  0.394539   \n",
      "Roman     0.221927   0.256549  0.265483  0.408709  0.212757  0.333936   \n",
      "Sergio    0.228390   0.269258  0.234949  0.302938  0.189429  0.251563   \n",
      "Felix     0.281112   0.343361  0.341017  0.374925  0.410786  0.343169   \n",
      "Patricia  0.249780   0.354225  0.431576  0.575551  0.286422  0.390637   \n",
      "Laura     0.196903   0.301458  0.362462  0.369008  0.270543  0.298943   \n",
      "Amanda    0.265801   0.362943  0.346522  0.512765  0.298716  0.411347   \n",
      "Victoria  0.062480   0.195091  0.190331  0.289775  0.193582  0.275756   \n",
      "Julia     0.257980   0.360039  0.409064  0.497802  0.355342  0.442024   \n",
      "Gloria    0.375883   0.410744  0.359560  0.521085  0.383584  0.506841   \n",
      "Diana     0.279162   0.328990  0.311071  0.437389  0.355724  0.377033   \n",
      "Clara     0.182820   0.235910  0.306083  0.354480  0.292163  0.284408   \n",
      "Paula     0.351403   0.364805  0.346412  0.427072  0.302976  0.387607   \n",
      "Norma     0.326474   0.480344  0.446121  0.658122  0.379086  0.437135   \n",
      "\n",
      "            gentle  approachable      love      cool  \n",
      "Paul      0.270955      0.319939  0.299477  0.322658  \n",
      "Vincent   0.287378      0.297797  0.317321  0.296348  \n",
      "Victor    0.265372      0.342173  0.272488  0.386908  \n",
      "Adrian    0.340771      0.538932  0.330587  0.444429  \n",
      "Marcus    0.166771      0.324982  0.307545  0.261160  \n",
      "Leo       0.285972      0.471318  0.458135  0.474155  \n",
      "Miles     0.179624      0.380370  0.405810  0.346696  \n",
      "Roman     0.218704      0.251580  0.250798  0.294154  \n",
      "Sergio    0.180699      0.234819  0.184208  0.307907  \n",
      "Felix     0.243552      0.314968  0.294182  0.304272  \n",
      "Patricia  0.385007      0.383524  0.261107  0.366656  \n",
      "Laura     0.313661      0.389328  0.301240  0.306153  \n",
      "Amanda    0.289169      0.350106  0.306769  0.372320  \n",
      "Victoria  0.225572      0.292141  0.230739  0.217437  \n",
      "Julia     0.357165      0.411945  0.352455  0.301540  \n",
      "Gloria    0.409107      0.410098  0.508626  0.471822  \n",
      "Diana     0.428285      0.372815  0.346263  0.398760  \n",
      "Clara     0.315470      0.284193  0.222665  0.288684  \n",
      "Paula     0.300831      0.414651  0.414272  0.405427  \n",
      "Norma     0.470542      0.508695  0.339548  0.498363  \n",
      "Cosine Similarity Matrix: Latin American Names vs Unpleasant Words\n",
      "              rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Paul      0.213955  0.186296      0.184739  0.227751  0.376211  0.121249   \n",
      "Vincent   0.047649  0.259761      0.138479  0.250511  0.345577  0.095802   \n",
      "Victor    0.175560  0.105839      0.220180  0.267386  0.289877  0.088086   \n",
      "Adrian    0.300122  0.199262      0.263543  0.242205  0.401869  0.130517   \n",
      "Marcus    0.168368  0.039811      0.186335  0.133215  0.239625  0.140472   \n",
      "Leo       0.245856  0.194244      0.269527  0.380796  0.508613  0.190313   \n",
      "Miles     0.120395  0.103728      0.251053  0.323256  0.483628  0.163973   \n",
      "Roman     0.073413  0.077377      0.093050  0.186469  0.239214  0.094740   \n",
      "Sergio    0.144295  0.189066      0.116545  0.235390  0.235737  0.075423   \n",
      "Felix     0.186174  0.133244      0.165294  0.187442  0.354008  0.203017   \n",
      "Patricia  0.232201  0.264726      0.222430  0.227975  0.333146  0.259720   \n",
      "Laura     0.088414  0.066548      0.081514  0.163502  0.370770  0.171935   \n",
      "Amanda    0.262363  0.138202      0.217309  0.263079  0.444109  0.288337   \n",
      "Victoria -0.007814 -0.100658      0.095528  0.094755  0.344669  0.096317   \n",
      "Julia     0.139800  0.121060      0.134506  0.186982  0.393683  0.228007   \n",
      "Gloria    0.257678  0.247074      0.261929  0.327174  0.517303  0.191477   \n",
      "Diana     0.107176  0.234992      0.160340  0.185863  0.394420  0.058999   \n",
      "Clara     0.180596  0.162744      0.165495  0.137695  0.300877  0.065982   \n",
      "Paula     0.190891  0.131198      0.262783  0.187911  0.379024  0.093813   \n",
      "Norma     0.282205  0.389738      0.379282  0.380887  0.508330  0.226895   \n",
      "\n",
      "           violent    bitter     harsh     angry  \n",
      "Paul      0.071145  0.108577  0.229642  0.094543  \n",
      "Vincent   0.046656  0.248593  0.137255  0.111998  \n",
      "Victor    0.226210  0.309030  0.259326  0.089568  \n",
      "Adrian    0.100869  0.189267  0.287642  0.148422  \n",
      "Marcus    0.112912  0.181055  0.217009  0.179165  \n",
      "Leo       0.230928  0.274450  0.360280  0.216291  \n",
      "Miles     0.152538  0.191773  0.326150  0.204782  \n",
      "Roman     0.094487  0.148998  0.184721  0.125650  \n",
      "Sergio    0.127045  0.177363  0.122853  0.141564  \n",
      "Felix     0.086857  0.218387  0.206739  0.154136  \n",
      "Patricia  0.085566  0.245421  0.273586  0.229582  \n",
      "Laura     0.101431  0.236678  0.201068  0.130618  \n",
      "Amanda    0.186287  0.319117  0.343517  0.291345  \n",
      "Victoria  0.190161  0.192831  0.177553  0.064318  \n",
      "Julia     0.059177  0.211511  0.225565  0.205225  \n",
      "Gloria    0.206890  0.259876  0.319135  0.256696  \n",
      "Diana     0.102851  0.124626  0.212911  0.109604  \n",
      "Clara     0.035327  0.090569  0.146442  0.072461  \n",
      "Paula     0.075734  0.100033  0.240405  0.102861  \n",
      "Norma     0.125826  0.223085  0.370489  0.220454  \n"
     ]
    }
   ],
   "source": [
    "# Latin American Names\n",
    "# Pleasant Words\n",
    "similarities_LXvP = cosine_similarity(LX_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_LXvU = cosine_similarity(LX_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_LXvP = pd.DataFrame(similarities_LXvP, index = LX_Names, columns = Pleasant_Words)\n",
    "similarities_LXvU = pd.DataFrame(similarities_LXvU, index = LX_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Latin American Names vs Pleasant Words\")\n",
    "print(similarities_LXvP)\n",
    "print(\"Cosine Similarity Matrix: Latin American Names vs Unpleasant Words\")\n",
    "print(similarities_LXvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b0bab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Chinese American Names vs Pleasant Words\n",
      "           happy  agreeable    polite     civil  charming  gracious    gentle  \\\n",
      "Lian    0.268269   0.337714  0.305467  0.475853  0.295326  0.395429  0.276247   \n",
      "Shan    0.262067   0.348784  0.318146  0.513194  0.296028  0.373603  0.246552   \n",
      "Lew     0.440470   0.476236  0.431198  0.607521  0.469924  0.519997  0.477630   \n",
      "Long    0.454544   0.477917  0.290655  0.383914  0.373819  0.459712  0.253284   \n",
      "Quan    0.244710   0.300724  0.233630  0.413162  0.229205  0.296320  0.177574   \n",
      "Jun     0.435784   0.538270  0.458759  0.623860  0.426609  0.545749  0.358897   \n",
      "Tou     0.390814   0.508937  0.394347  0.557033  0.409279  0.537184  0.332093   \n",
      "Jin     0.394709   0.432671  0.329592  0.520547  0.407863  0.433913  0.266804   \n",
      "Cai     0.481701   0.559708  0.463555  0.702203  0.504662  0.587055  0.450139   \n",
      "Chan    0.385768   0.391036  0.349902  0.488464  0.384412  0.393235  0.340575   \n",
      "Lue     0.292570   0.445376  0.417937  0.540484  0.314181  0.419456  0.395534   \n",
      "China   0.174312   0.196996  0.212314  0.280670  0.206070  0.199114  0.204173   \n",
      "Lu      0.400876   0.489738  0.362846  0.587764  0.459201  0.471723  0.435457   \n",
      "Maylee  0.270778   0.340231  0.363984  0.505753  0.353668  0.418484  0.406386   \n",
      "Tennie  0.272625   0.344636  0.330297  0.430035  0.291108  0.313256  0.293677   \n",
      "Maylin  0.361168   0.433307  0.391825  0.553282  0.402493  0.489610  0.429579   \n",
      "Chynna  0.503013   0.611318  0.526261  0.693792  0.581613  0.631636  0.527486   \n",
      "Jia     0.304796   0.379627  0.327885  0.510693  0.332024  0.430439  0.288882   \n",
      "Mei     0.415800   0.503292  0.468042  0.636345  0.433492  0.517841  0.425981   \n",
      "Tylee   0.281976   0.364173  0.301806  0.431039  0.287627  0.366650  0.290899   \n",
      "\n",
      "        approachable      love      cool  \n",
      "Lian        0.412870  0.345212  0.338308  \n",
      "Shan        0.419034  0.281446  0.298602  \n",
      "Lew         0.502787  0.480615  0.499812  \n",
      "Long        0.450556  0.454968  0.412080  \n",
      "Quan        0.395399  0.304576  0.285143  \n",
      "Jun         0.570448  0.477989  0.492867  \n",
      "Tou         0.520182  0.478385  0.433816  \n",
      "Jin         0.449024  0.359875  0.396804  \n",
      "Cai         0.649255  0.533749  0.531572  \n",
      "Chan        0.534645  0.402184  0.419245  \n",
      "Lue         0.498780  0.372994  0.408171  \n",
      "China       0.192323  0.191119  0.205755  \n",
      "Lu          0.541741  0.490446  0.474154  \n",
      "Maylee      0.459940  0.365540  0.320150  \n",
      "Tennie      0.452263  0.335658  0.333267  \n",
      "Maylin      0.503776  0.463544  0.415519  \n",
      "Chynna      0.665250  0.598458  0.606467  \n",
      "Jia         0.393675  0.370553  0.360702  \n",
      "Mei         0.543121  0.498539  0.485916  \n",
      "Tylee       0.397376  0.357157  0.330131  \n",
      "Cosine Similarity Matrix: Chinese American Names vs Unpleasant Words\n",
      "            rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Lian    0.173596  0.086090      0.224704  0.263759  0.439762  0.158457   \n",
      "Shan    0.243010  0.154564      0.270569  0.290258  0.489018  0.241034   \n",
      "Lew     0.347942  0.312053      0.331591  0.361783  0.548330  0.174442   \n",
      "Long    0.209637  0.141537      0.301665  0.457926  0.545883  0.148336   \n",
      "Quan    0.227216  0.111474      0.319786  0.265335  0.711632  0.171241   \n",
      "Jun     0.319097  0.219576      0.394879  0.392598  0.677841  0.239667   \n",
      "Tou     0.325777  0.201158      0.359851  0.465426  0.747944  0.272190   \n",
      "Jin     0.283757  0.142238      0.341026  0.326923  0.425687  0.172958   \n",
      "Cai     0.324233  0.252423      0.376600  0.434700  0.749752  0.267210   \n",
      "Chan    0.180066  0.113286      0.250875  0.288013  0.570469  0.107780   \n",
      "Lue     0.204437  0.200905      0.268473  0.301643  0.656382  0.269724   \n",
      "China  -0.001168  0.054343      0.015783  0.052308  0.124056  0.017453   \n",
      "Lu      0.264849  0.238619      0.357956  0.463285  0.739349  0.240524   \n",
      "Maylee  0.211773  0.182925      0.192031  0.209973  0.515136  0.138854   \n",
      "Tennie  0.097184  0.120697      0.198907  0.258673  0.482591  0.180714   \n",
      "Maylin  0.227776  0.197066      0.230197  0.291501  0.650230  0.166781   \n",
      "Chynna  0.372236  0.256536      0.431507  0.499079  0.724347  0.296366   \n",
      "Jia     0.233744  0.157698      0.246435  0.296264  0.461571  0.220930   \n",
      "Mei     0.318881  0.269145      0.357311  0.360630  0.585532  0.246619   \n",
      "Tylee   0.170232  0.125442      0.221846  0.315995  0.556134  0.177380   \n",
      "\n",
      "         violent    bitter     harsh     angry  \n",
      "Lian    0.145138  0.247838  0.250892  0.196297  \n",
      "Shan    0.237730  0.337075  0.374568  0.261922  \n",
      "Lew     0.177283  0.272913  0.355363  0.186563  \n",
      "Long    0.343859  0.348485  0.447292  0.326160  \n",
      "Quan    0.178063  0.209010  0.332010  0.258583  \n",
      "Jun     0.207613  0.332584  0.417809  0.291016  \n",
      "Tou     0.265969  0.404942  0.489893  0.350660  \n",
      "Jin     0.183292  0.299979  0.295213  0.189800  \n",
      "Cai     0.297138  0.370184  0.479630  0.333266  \n",
      "Chan    0.179819  0.174685  0.277120  0.154933  \n",
      "Lue     0.192630  0.306251  0.392794  0.328437  \n",
      "China   0.032662  0.053618 -0.030120 -0.036005  \n",
      "Lu      0.311094  0.357534  0.440822  0.273770  \n",
      "Maylee  0.094660  0.234371  0.258900  0.158564  \n",
      "Tennie  0.135944  0.195147  0.244692  0.187090  \n",
      "Maylin  0.135689  0.270555  0.335619  0.203237  \n",
      "Chynna  0.308955  0.461332  0.524727  0.344500  \n",
      "Jia     0.161134  0.310593  0.281040  0.223688  \n",
      "Mei     0.170976  0.325378  0.363465  0.255494  \n",
      "Tylee   0.172356  0.292561  0.287811  0.228192  \n"
     ]
    }
   ],
   "source": [
    "# Chinese American Names\n",
    "# Pleasant Words\n",
    "similarities_CHvP = cosine_similarity(CH_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_CHvU = cosine_similarity(CH_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_CHvP = pd.DataFrame(similarities_CHvP, index = CH_Names, columns = Pleasant_Words)\n",
    "similarities_CHvU = pd.DataFrame(similarities_CHvU, index = CH_Names, columns = Unpleasant_Words)\n",
    "print(\"Cosine Similarity Matrix: Chinese American Names vs Pleasant Words\")\n",
    "print(similarities_CHvP)\n",
    "print(\"Cosine Similarity Matrix: Chinese American Names vs Unpleasant Words\")\n",
    "print(similarities_CHvU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967ba9b",
   "metadata": {},
   "source": [
    "# TEST 2: Gender Biases for Favorability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984fa641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Male Names vs Pleasant Words\n",
      "                happy  agreeable    polite     civil  charming  gracious  \\\n",
      "James        0.264323   0.285021  0.238533  0.404505  0.249507  0.331670   \n",
      "John         0.263917   0.308286  0.218405  0.432454  0.219760  0.340813   \n",
      "Robert       0.159164   0.210734  0.215705  0.274650  0.127228  0.272302   \n",
      "Michael      0.336251   0.339140  0.316363  0.522873  0.347805  0.487477   \n",
      "William      0.188221   0.220080  0.115727  0.361746  0.207075  0.296012   \n",
      "David        0.238337   0.336345  0.309008  0.459027  0.248808  0.342114   \n",
      "Joseph       0.231378   0.288734  0.223294  0.325019  0.185305  0.334610   \n",
      "Richard      0.108802   0.170773  0.132427  0.247831  0.103367  0.247996   \n",
      "Charles      0.241694   0.307960  0.267634  0.391822  0.310617  0.403683   \n",
      "Thomas       0.194565   0.289645  0.272875  0.430608  0.179531  0.344031   \n",
      "Christopher  0.334908   0.357503  0.326462  0.530691  0.310868  0.413786   \n",
      "Daniel       0.233649   0.310641  0.257645  0.481313  0.228640  0.346990   \n",
      "Matthew      0.229618   0.376159  0.306568  0.439513  0.228408  0.363255   \n",
      "George       0.325866   0.385620  0.284006  0.434852  0.329881  0.489463   \n",
      "Anthony      0.267577   0.352793  0.353768  0.393387  0.322597  0.404675   \n",
      "Donald       0.268719   0.348285  0.300794  0.444513  0.252059  0.372480   \n",
      "Paul         0.203060   0.277410  0.284907  0.381434  0.294371  0.333334   \n",
      "Mark         0.291457   0.401347  0.343587  0.499188  0.298512  0.437021   \n",
      "Andrew       0.206922   0.282121  0.206402  0.340266  0.225168  0.322352   \n",
      "Edward       0.239389   0.347212  0.332690  0.441754  0.332039  0.415839   \n",
      "\n",
      "               gentle  approachable      love      cool  \n",
      "James        0.260473      0.328372  0.346978  0.269803  \n",
      "John         0.248217      0.329753  0.342643  0.360968  \n",
      "Robert       0.227116      0.285967  0.252335  0.202325  \n",
      "Michael      0.284588      0.440195  0.327771  0.352296  \n",
      "William      0.161824      0.268722  0.293122  0.238665  \n",
      "David        0.307513      0.346330  0.351192  0.309119  \n",
      "Joseph       0.154034      0.305739  0.250992  0.217384  \n",
      "Richard      0.097599      0.197527  0.212759  0.133443  \n",
      "Charles      0.287647      0.396299  0.348598  0.264970  \n",
      "Thomas       0.197521      0.371155  0.253560  0.265240  \n",
      "Christopher  0.318583      0.456126  0.307021  0.370731  \n",
      "Daniel       0.222068      0.345611  0.307220  0.312406  \n",
      "Matthew      0.314026      0.361639  0.369438  0.325976  \n",
      "George       0.294210      0.330745  0.481166  0.424958  \n",
      "Anthony      0.299135      0.474036  0.237593  0.308407  \n",
      "Donald       0.260119      0.358308  0.295233  0.345003  \n",
      "Paul         0.270955      0.319939  0.299477  0.322658  \n",
      "Mark         0.275667      0.454535  0.357676  0.368491  \n",
      "Andrew       0.199726      0.314084  0.281669  0.251924  \n",
      "Edward       0.253748      0.375335  0.247122  0.318860  \n",
      "Cosine Similarity Matrix: Male Names vs Unpleasant Words\n",
      "                 rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "James        0.154240  0.139182      0.194497  0.190973  0.534508  0.081550   \n",
      "John         0.254573  0.208656      0.298217  0.313978  0.467413  0.148536   \n",
      "Robert       0.114121  0.105991      0.102789  0.174731  0.358823  0.022597   \n",
      "Michael      0.237259  0.139858      0.262967  0.256301  0.393899  0.110104   \n",
      "William      0.243397  0.094860      0.225378  0.270836  0.465081  0.164201   \n",
      "David        0.194300  0.131624      0.193256  0.320163  0.538393  0.131398   \n",
      "Joseph       0.095039  0.066160      0.127523  0.168309  0.379585  0.109691   \n",
      "Richard      0.170977  0.068652      0.128163  0.227864  0.258728  0.062510   \n",
      "Charles      0.106306  0.050642      0.193223  0.213339  0.368055  0.089122   \n",
      "Thomas       0.260848  0.101349      0.292655  0.244624  0.433699  0.129225   \n",
      "Christopher  0.231803  0.141362      0.221705  0.257775  0.407091  0.013211   \n",
      "Daniel       0.145750  0.125569      0.189907  0.203578  0.431736  0.134327   \n",
      "Matthew      0.161759  0.129232      0.270112  0.293089  0.389533  0.095554   \n",
      "George       0.237199  0.158435      0.268552  0.340238  0.530232  0.175645   \n",
      "Anthony      0.267554  0.139868      0.244072  0.228356  0.386872  0.076945   \n",
      "Donald       0.188436  0.116065      0.228276  0.283817  0.349129  0.125031   \n",
      "Paul         0.213955  0.186296      0.184739  0.227751  0.376211  0.121249   \n",
      "Mark         0.245617  0.118587      0.261282  0.368644  0.563146  0.207605   \n",
      "Andrew       0.212327  0.158937      0.180060  0.193326  0.454219  0.160271   \n",
      "Edward       0.275233  0.131869      0.236592  0.270411  0.475225  0.101710   \n",
      "\n",
      "              violent    bitter     harsh     angry  \n",
      "James        0.143152  0.099260  0.203021  0.100106  \n",
      "John         0.180258  0.145437  0.284681  0.164928  \n",
      "Robert       0.116097  0.101235  0.169015  0.111701  \n",
      "Michael      0.120140  0.214238  0.300042  0.170971  \n",
      "William      0.261669  0.174365  0.325153  0.226022  \n",
      "David        0.141492  0.238353  0.283640  0.190714  \n",
      "Joseph       0.055649  0.104723  0.182014  0.107966  \n",
      "Richard      0.117397  0.137188  0.218662  0.108017  \n",
      "Charles      0.117206  0.154270  0.251083  0.112532  \n",
      "Thomas       0.117198  0.193824  0.276866  0.180691  \n",
      "Christopher  0.116264  0.081701  0.253798  0.100883  \n",
      "Daniel       0.038892  0.209183  0.212947  0.120118  \n",
      "Matthew      0.090478  0.227183  0.322567  0.107949  \n",
      "George       0.192705  0.244232  0.352671  0.201444  \n",
      "Anthony      0.159620  0.189552  0.304380  0.171059  \n",
      "Donald       0.134148  0.196875  0.221978  0.203071  \n",
      "Paul         0.071145  0.108577  0.229642  0.094543  \n",
      "Mark         0.185586  0.341183  0.451601  0.285383  \n",
      "Andrew       0.180264  0.202354  0.298062  0.212319  \n",
      "Edward       0.181575  0.179798  0.321265  0.158524  \n"
     ]
    }
   ],
   "source": [
    "# Male Names\n",
    "# Pleasant Words\n",
    "similarities_MvP = cosine_similarity(Male_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_MvU = cosine_similarity(Male_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_MvP = pd.DataFrame(similarities_MvP, index = Male_Names, columns = Pleasant_Words)\n",
    "similarities_MvU = pd.DataFrame(similarities_MvU, index = Male_Names, columns = Unpleasant_Words)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs Pleasant Words\")\n",
    "print(similarities_MvP)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs Unpleasant Words\")\n",
    "print(similarities_MvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fcfe221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Female Names vs Pleasant Words\n",
      "              happy  agreeable    polite     civil  charming  gracious  \\\n",
      "Mary       0.253565   0.311784  0.283632  0.440337  0.262250  0.444240   \n",
      "Elizabeth  0.066126   0.236392  0.268022  0.386091  0.158411  0.244093   \n",
      "Patricia   0.249780   0.354225  0.431576  0.575551  0.286422  0.390637   \n",
      "Jennifer   0.284704   0.350758  0.373091  0.557006  0.363007  0.396441   \n",
      "Linda      0.277525   0.413909  0.416520  0.552094  0.331191  0.421016   \n",
      "Barbara    0.232492   0.293390  0.309994  0.458465  0.247796  0.391909   \n",
      "Margaret   0.205589   0.381567  0.421427  0.527692  0.297811  0.415891   \n",
      "Susan      0.273926   0.390113  0.430124  0.501582  0.356873  0.388446   \n",
      "Dorothy    0.216249   0.277371  0.228731  0.326413  0.283816  0.283769   \n",
      "Sarah      0.299965   0.346045  0.343780  0.527762  0.352815  0.425353   \n",
      "Jessica    0.189922   0.306729  0.265833  0.426969  0.202560  0.324024   \n",
      "Helen      0.147473   0.251646  0.253600  0.290605  0.230004  0.258491   \n",
      "Nancy      0.213411   0.312957  0.347358  0.471168  0.339645  0.335685   \n",
      "Betty      0.263712   0.330806  0.273682  0.494477  0.300497  0.342529   \n",
      "Karen      0.329435   0.354858  0.376824  0.475802  0.319218  0.440189   \n",
      "Lisa       0.252695   0.258425  0.349619  0.367610  0.306011  0.340256   \n",
      "Anna       0.240550   0.371162  0.346573  0.489999  0.328926  0.410332   \n",
      "Sandra     0.280028   0.384402  0.401068  0.541986  0.304941  0.432276   \n",
      "Emily      0.114202   0.219189  0.264559  0.395765  0.261414  0.216145   \n",
      "Ashley     0.227184   0.402646  0.369266  0.487549  0.355246  0.385010   \n",
      "\n",
      "             gentle  approachable      love      cool  \n",
      "Mary       0.337240      0.357126  0.367520  0.261206  \n",
      "Elizabeth  0.301474      0.289477  0.257811  0.200230  \n",
      "Patricia   0.385007      0.383524  0.261107  0.366656  \n",
      "Jennifer   0.396407      0.327548  0.308419  0.362523  \n",
      "Linda      0.510286      0.399634  0.396038  0.488276  \n",
      "Barbara    0.371614      0.308863  0.349188  0.360444  \n",
      "Margaret   0.420342      0.389277  0.394712  0.313597  \n",
      "Susan      0.362311      0.392647  0.355874  0.356178  \n",
      "Dorothy    0.289516      0.287589  0.254918  0.269145  \n",
      "Sarah      0.325859      0.459589  0.331869  0.325689  \n",
      "Jessica    0.253869      0.275105  0.274772  0.306744  \n",
      "Helen      0.203577      0.262900  0.292232  0.237769  \n",
      "Nancy      0.351658      0.361465  0.370975  0.289197  \n",
      "Betty      0.273942      0.298919  0.311631  0.322029  \n",
      "Karen      0.324796      0.405775  0.335341  0.299173  \n",
      "Lisa       0.307056      0.302787  0.282244  0.295658  \n",
      "Anna       0.357603      0.402039  0.362778  0.396497  \n",
      "Sandra     0.369295      0.345507  0.258606  0.368930  \n",
      "Emily      0.264628      0.357760  0.200819  0.272641  \n",
      "Ashley     0.462433      0.395270  0.371782  0.412540  \n",
      "Cosine Similarity Matrix: Female Names vs Unpleasant Words\n",
      "               rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Mary       0.151794  0.134157      0.229747  0.345103  0.539705  0.223171   \n",
      "Elizabeth  0.081075  0.072516      0.142023  0.181180  0.390102  0.104354   \n",
      "Patricia   0.232201  0.264726      0.222430  0.227975  0.333146  0.259720   \n",
      "Jennifer   0.265566  0.318727      0.303981  0.307366  0.391505  0.252648   \n",
      "Linda      0.180105  0.279321      0.237766  0.296846  0.327389  0.145007   \n",
      "Barbara    0.224890  0.177227      0.226039  0.298381  0.343548  0.167036   \n",
      "Margaret   0.199349  0.179784      0.271071  0.286026  0.482134  0.263741   \n",
      "Susan      0.296002  0.209164      0.285018  0.278931  0.434420  0.220348   \n",
      "Dorothy    0.167432  0.144327      0.219677  0.234677  0.296810  0.044791   \n",
      "Sarah      0.218997  0.111856      0.271920  0.290603  0.508161  0.182492   \n",
      "Jessica    0.222629  0.235987      0.296210  0.249875  0.421599  0.238469   \n",
      "Helen      0.065408 -0.002207      0.104770  0.121778  0.399350  0.119756   \n",
      "Nancy      0.234573  0.118105      0.274570  0.250247  0.379898  0.270241   \n",
      "Betty      0.192407  0.185049      0.187166  0.304132  0.315401  0.250304   \n",
      "Karen      0.154070  0.160278      0.173061  0.207334  0.338377  0.110401   \n",
      "Lisa       0.181188  0.235037      0.097995  0.137081  0.313827  0.144241   \n",
      "Anna       0.307535  0.232344      0.297098  0.320331  0.555707  0.225328   \n",
      "Sandra     0.311397  0.376246      0.284227  0.313553  0.343760  0.203992   \n",
      "Emily      0.244077  0.142414      0.215055  0.198548  0.472323  0.242910   \n",
      "Ashley     0.303178  0.292099      0.330141  0.267415  0.336578  0.226503   \n",
      "\n",
      "            violent    bitter     harsh     angry  \n",
      "Mary       0.158879  0.219381  0.312540  0.228649  \n",
      "Elizabeth  0.051066  0.110688  0.178405  0.063700  \n",
      "Patricia   0.085566  0.245421  0.273586  0.229582  \n",
      "Jennifer   0.178102  0.282819  0.309998  0.277051  \n",
      "Linda      0.068561  0.238386  0.216590  0.143579  \n",
      "Barbara    0.101499  0.175475  0.264450  0.204738  \n",
      "Margaret   0.103347  0.293468  0.300715  0.197692  \n",
      "Susan      0.124662  0.292561  0.331097  0.202763  \n",
      "Dorothy    0.019812  0.155444  0.185960  0.032554  \n",
      "Sarah      0.120119  0.227403  0.330081  0.204316  \n",
      "Jessica    0.127782  0.249912  0.335235  0.244793  \n",
      "Helen      0.163003  0.113930  0.196332  0.142935  \n",
      "Nancy      0.230116  0.255045  0.339185  0.255025  \n",
      "Betty      0.070953  0.192544  0.207259  0.190355  \n",
      "Karen      0.067890  0.099126  0.208327  0.125021  \n",
      "Lisa      -0.000566  0.068159  0.196823  0.088782  \n",
      "Anna       0.183796  0.282734  0.367884  0.239299  \n",
      "Sandra     0.082943  0.173072  0.264638  0.187175  \n",
      "Emily      0.184649  0.234760  0.309608  0.241408  \n",
      "Ashley     0.130521  0.304985  0.351437  0.216874  \n"
     ]
    }
   ],
   "source": [
    "# Female Names\n",
    "# Pleasant Words\n",
    "similarities_FvP = cosine_similarity(Female_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_FvU = cosine_similarity(Female_Embeddings, Unpleasant_Embeddings)\n",
    "similarities_FvP = pd.DataFrame(similarities_FvP, index = Female_Names, columns = Pleasant_Words)\n",
    "similarities_FvU = pd.DataFrame(similarities_FvU, index = Female_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Female Names vs Pleasant Words\")\n",
    "print(similarities_FvP)\n",
    "print(\"Cosine Similarity Matrix: Female Names vs Unpleasant Words\")\n",
    "print(similarities_FvU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4844ca",
   "metadata": {},
   "source": [
    "# TEST 3: Gender Biases in Careers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4dc4744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Male Names vs STEM Careers\n",
      "             Software Developer  Nurse Practitioner  Health Services Manager  \\\n",
      "James                  0.063660            0.069200                 0.232475   \n",
      "John                   0.045015           -0.051360                 0.164809   \n",
      "Robert                 0.174297            0.039819                 0.178239   \n",
      "Michael                0.110490            0.136797                 0.184645   \n",
      "William                0.056919           -0.023466                 0.211037   \n",
      "David                  0.173491            0.109505                 0.328156   \n",
      "Joseph                 0.125445            0.003227                 0.187143   \n",
      "Richard                0.094749           -0.010311                 0.065831   \n",
      "Charles                0.144062            0.043981                 0.122281   \n",
      "Thomas                 0.079760            0.053890                 0.162753   \n",
      "Christopher            0.143744           -0.009341                 0.208933   \n",
      "Daniel                 0.036056            0.121244                 0.274453   \n",
      "Matthew                0.024261            0.007635                 0.194332   \n",
      "George                 0.082222            0.120756                 0.325556   \n",
      "Anthony                0.169935            0.105845                 0.179792   \n",
      "Donald                 0.110562            0.028042                 0.208976   \n",
      "Paul                   0.113173            0.190411                 0.434189   \n",
      "Mark                   0.173375            0.111179                 0.317622   \n",
      "Andrew                 0.118008            0.125621                 0.259868   \n",
      "Edward                 0.136947            0.051438                 0.209951   \n",
      "\n",
      "             Physicians Assistant  Security Analyst  IT Manager  \\\n",
      "James                    0.122923          0.210843    0.215092   \n",
      "John                     0.105720          0.163283    0.142037   \n",
      "Robert                   0.174625          0.233019    0.241720   \n",
      "Michael                  0.184518          0.289455    0.267887   \n",
      "William                  0.050709          0.231940    0.189000   \n",
      "David                    0.302195          0.184010    0.371275   \n",
      "Joseph                   0.145522          0.101791    0.233641   \n",
      "Richard                  0.085434          0.120877    0.144703   \n",
      "Charles                  0.144918          0.201961    0.160319   \n",
      "Thomas                   0.195456          0.219653    0.191132   \n",
      "Christopher              0.184364          0.205031    0.235556   \n",
      "Daniel                   0.258969          0.199806    0.185731   \n",
      "Matthew                  0.181045          0.122173    0.132056   \n",
      "George                   0.160198          0.157870    0.297301   \n",
      "Anthony                  0.168463          0.290306    0.254212   \n",
      "Donald                   0.240378          0.178935    0.249503   \n",
      "Paul                     0.261855          0.155100    0.249997   \n",
      "Mark                     0.228124          0.204896    0.290761   \n",
      "Andrew                   0.168812          0.234875    0.292291   \n",
      "Edward                   0.126921          0.260425    0.274026   \n",
      "\n",
      "             Web Developer   Dentist  Orthodontist  Computer Systems Analyst  \n",
      "James             0.191832  0.103562      0.059239                  0.048711  \n",
      "John              0.081107  0.120923      0.195609                  0.023461  \n",
      "Robert            0.172863  0.262430      0.314783                  0.137232  \n",
      "Michael           0.107689  0.308439      0.196036                  0.176564  \n",
      "William           0.134702  0.056292      0.118507                  0.032296  \n",
      "David             0.212030  0.409281      0.399548                  0.119285  \n",
      "Joseph            0.158267  0.202367      0.191607                  0.062525  \n",
      "Richard           0.028223  0.338498      0.393787                  0.081317  \n",
      "Charles           0.083867  0.340200      0.233970                  0.158074  \n",
      "Thomas            0.059032  0.248729      0.312239                  0.119511  \n",
      "Christopher       0.179050  0.202311      0.231947                  0.065355  \n",
      "Daniel            0.090648  0.263959      0.218003                  0.084677  \n",
      "Matthew           0.046821  0.309483      0.355036                 -0.014065  \n",
      "George            0.123093  0.218461      0.208545                  0.027562  \n",
      "Anthony           0.210025  0.409179      0.318923                  0.115391  \n",
      "Donald            0.027308  0.308549      0.315963                  0.192425  \n",
      "Paul              0.154719  0.292179      0.202717                  0.085144  \n",
      "Mark              0.173844  0.478498      0.471951                  0.117580  \n",
      "Andrew            0.260266  0.308328      0.238392                  0.120564  \n",
      "Edward            0.173236  0.300354      0.300410                  0.092449  \n",
      "Cosine Similarity Matrix: Male Names vs Non-STEM Careers\n",
      "               Artist  Marketing Manager  Social Worker  Attorney  Journalist  \\\n",
      "James        0.377548           0.182829       0.159806  0.268486    0.233371   \n",
      "John         0.387104          -0.011261       0.058279  0.216876    0.221518   \n",
      "Robert       0.284152           0.058633      -0.000117  0.308493    0.248903   \n",
      "Michael      0.425311           0.186383       0.200547  0.383781    0.212262   \n",
      "William      0.440505           0.102511       0.194712  0.176553    0.237633   \n",
      "David        0.312392           0.161461       0.036934  0.237486    0.261625   \n",
      "Joseph       0.275067           0.190201       0.135715  0.230425    0.161773   \n",
      "Richard      0.195262           0.026766       0.023935  0.417620    0.112713   \n",
      "Charles      0.266577           0.125571       0.066467  0.389655    0.137554   \n",
      "Thomas       0.333647           0.087211       0.063244  0.368781    0.150910   \n",
      "Christopher  0.419284           0.187206       0.209112  0.242390    0.232237   \n",
      "Daniel       0.325891           0.126236       0.124396  0.284907    0.176691   \n",
      "Matthew      0.275483           0.011455       0.084811  0.173501    0.290255   \n",
      "George       0.423002           0.190746       0.169829  0.235904    0.231381   \n",
      "Anthony      0.316517           0.171587       0.220588  0.374630    0.189942   \n",
      "Donald       0.177655           0.103938      -0.078158  0.212079    0.072380   \n",
      "Paul         0.485649           0.283546       0.264995  0.128105    0.124061   \n",
      "Mark         0.459901           0.154802       0.140957  0.253405    0.319173   \n",
      "Andrew       0.309385           0.179532       0.278581  0.230591    0.109880   \n",
      "Edward       0.273569           0.100114       0.145189  0.335330    0.187610   \n",
      "\n",
      "             Musician   Teacher  Media Manager  Graphic Designer     Judge  \n",
      "James        0.300919  0.092035       0.303064          0.230510  0.259905  \n",
      "John         0.347682  0.038557       0.160796          0.122407  0.275830  \n",
      "Robert       0.256050  0.098250       0.216664          0.126347  0.418414  \n",
      "Michael      0.334507  0.070293       0.293723          0.207275  0.280880  \n",
      "William      0.364211  0.024962       0.278656          0.221917  0.194714  \n",
      "David        0.255271  0.190795       0.316209          0.355679  0.332588  \n",
      "Joseph       0.178333  0.190684       0.212081          0.200812  0.265915  \n",
      "Richard      0.231293  0.025632       0.114885          0.138156  0.315084  \n",
      "Charles      0.269502  0.076919       0.165114          0.214289  0.373582  \n",
      "Thomas       0.294852  0.116376       0.138369          0.084249  0.310998  \n",
      "Christopher  0.370175  0.082813       0.247310          0.287285  0.226366  \n",
      "Daniel       0.273823  0.185462       0.156798          0.150635  0.267719  \n",
      "Matthew      0.223926  0.115227       0.168292          0.279508  0.266149  \n",
      "George       0.326730  0.134820       0.272624          0.206168  0.229675  \n",
      "Anthony      0.332963  0.128699       0.207942          0.285732  0.357645  \n",
      "Donald       0.160580  0.048709       0.100653          0.113834  0.230473  \n",
      "Paul         0.381170  0.208891       0.177769          0.339782  0.192939  \n",
      "Mark         0.326245  0.195480       0.226831          0.375062  0.378090  \n",
      "Andrew       0.252770  0.221091       0.273229          0.227189  0.259583  \n",
      "Edward       0.269633  0.159861       0.254685          0.218239  0.341078  \n"
     ]
    }
   ],
   "source": [
    "# Male Names\n",
    "# STEM Careers\n",
    "similarities_MvS = cosine_similarity(Male_Embeddings, STEM_Embeddings)\n",
    "# Non-STEM Careers\n",
    "similarities_MvN = cosine_similarity(Male_Embeddings, Non_STEM_Embeddings)\n",
    "similarities_MvS = pd.DataFrame(similarities_MvS, index = Male_Names, columns = STEM_Careers)\n",
    "similarities_MvN = pd.DataFrame(similarities_MvN, index = Male_Names, columns = Non_STEM_Careers)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs STEM Careers\")\n",
    "print(similarities_MvS)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs Non-STEM Careers\")\n",
    "print(similarities_MvN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b00b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Female Names vs STEM Careers\n",
      "           Software Developer  Nurse Practitioner  Health Services Manager  \\\n",
      "Mary                 0.151791            0.366161                 0.383118   \n",
      "Elizabeth            0.052311            0.318811                 0.256022   \n",
      "Patricia             0.146737            0.253841                 0.183873   \n",
      "Jennifer             0.195465            0.291292                 0.226042   \n",
      "Linda                0.064850            0.348450                 0.411815   \n",
      "Barbara              0.180591            0.334345                 0.298513   \n",
      "Margaret             0.113092            0.430163                 0.385509   \n",
      "Susan                0.209822            0.337954                 0.204680   \n",
      "Dorothy              0.077006            0.139731                 0.051418   \n",
      "Sarah                0.068396            0.288045                 0.347186   \n",
      "Jessica              0.066949            0.241722                 0.265120   \n",
      "Helen                0.068810            0.290246                 0.215319   \n",
      "Nancy                0.018112            0.401934                 0.222009   \n",
      "Betty                0.053302            0.159635                 0.298991   \n",
      "Karen                0.226867            0.425188                 0.336239   \n",
      "Lisa                 0.310480            0.338964                 0.349770   \n",
      "Anna                 0.091718            0.290103                 0.324051   \n",
      "Sandra               0.145239            0.322984                 0.384197   \n",
      "Emily                0.171394            0.280878                 0.240176   \n",
      "Ashley               0.032879            0.178097                 0.127531   \n",
      "\n",
      "           Physicians Assistant  Security Analyst  IT Manager  Web Developer  \\\n",
      "Mary                   0.253083          0.137972    0.321851       0.174282   \n",
      "Elizabeth              0.289633          0.158349    0.131272       0.048257   \n",
      "Patricia               0.163534          0.167839    0.219253       0.105974   \n",
      "Jennifer               0.140890          0.172963    0.280769       0.162006   \n",
      "Linda                  0.326645          0.140299    0.240959       0.004898   \n",
      "Barbara                0.263225          0.181582    0.281022       0.096893   \n",
      "Margaret               0.351333          0.193579    0.294380       0.107154   \n",
      "Susan                  0.268138          0.194831    0.243157       0.210161   \n",
      "Dorothy                0.078063          0.107069    0.173877       0.040384   \n",
      "Sarah                  0.244973          0.163614    0.236855       0.202401   \n",
      "Jessica                0.137335          0.112962    0.122044       0.089298   \n",
      "Helen                  0.240281          0.172300    0.183937       0.200855   \n",
      "Nancy                  0.297604          0.256408    0.177794       0.135852   \n",
      "Betty                  0.218094          0.107868    0.209262       0.153374   \n",
      "Karen                  0.356202          0.248754    0.344530       0.237052   \n",
      "Lisa                   0.240442          0.254199    0.329734       0.221827   \n",
      "Anna                   0.217454          0.222651    0.217065       0.060189   \n",
      "Sandra                 0.250993          0.211109    0.384747       0.159315   \n",
      "Emily                  0.216909          0.249718    0.221983       0.227880   \n",
      "Ashley                 0.079672          0.208629    0.103255       0.035616   \n",
      "\n",
      "            Dentist  Orthodontist  Computer Systems Analyst  \n",
      "Mary       0.200589      0.147854                  0.209548  \n",
      "Elizabeth  0.226197      0.258399                  0.161171  \n",
      "Patricia   0.301921      0.210973                  0.241186  \n",
      "Jennifer   0.230968      0.112842                  0.256541  \n",
      "Linda      0.256693      0.186635                  0.175165  \n",
      "Barbara    0.273236      0.225170                  0.215524  \n",
      "Margaret   0.371411      0.294102                  0.237376  \n",
      "Susan      0.360178      0.362044                  0.174930  \n",
      "Dorothy    0.168863      0.121298                  0.103852  \n",
      "Sarah      0.241231      0.210085                  0.094450  \n",
      "Jessica    0.279137      0.227302                  0.091374  \n",
      "Helen      0.185618      0.281076                  0.137864  \n",
      "Nancy      0.105683      0.115348                  0.173299  \n",
      "Betty      0.115108      0.100482                  0.141263  \n",
      "Karen      0.325733      0.256480                  0.271211  \n",
      "Lisa       0.332595      0.188362                  0.286789  \n",
      "Anna       0.275545      0.236220                  0.166502  \n",
      "Sandra     0.324703      0.289358                  0.219543  \n",
      "Emily      0.241841      0.155207                  0.263105  \n",
      "Ashley     0.160510      0.092252                  0.107512  \n",
      "Cosine Similarity Matrix: Female Names vs Non-STEM Careers\n",
      "             Artist  Marketing Manager  Social Worker  Attorney  Journalist  \\\n",
      "Mary       0.371285           0.271409       0.321409  0.217795    0.170201   \n",
      "Elizabeth  0.155442           0.044297       0.208001  0.178062    0.115589   \n",
      "Patricia   0.236580           0.106902       0.238766  0.254939    0.242154   \n",
      "Jennifer   0.372237           0.174070       0.310101  0.332881    0.182677   \n",
      "Linda      0.365702           0.140991       0.195557  0.210938    0.295973   \n",
      "Barbara    0.354968           0.173541       0.233655  0.297959    0.191992   \n",
      "Margaret   0.221383           0.178673       0.317309  0.226188    0.150976   \n",
      "Susan      0.274281           0.124388       0.208388  0.300223    0.216095   \n",
      "Dorothy    0.166527           0.082148       0.235522  0.241923    0.170816   \n",
      "Sarah      0.422690           0.231847       0.324690  0.304753    0.336197   \n",
      "Jessica    0.245314           0.069076       0.201328  0.201632    0.202302   \n",
      "Helen      0.275613           0.034230       0.221587  0.160654    0.167447   \n",
      "Nancy      0.290379           0.081888       0.251581  0.276916    0.215152   \n",
      "Betty      0.238036           0.128182       0.217411  0.112224    0.191762   \n",
      "Karen      0.314340           0.261235       0.401264  0.323485    0.266858   \n",
      "Lisa       0.299018           0.254889       0.188207  0.117578    0.192481   \n",
      "Anna       0.455663           0.141549       0.303158  0.267119    0.183339   \n",
      "Sandra     0.259269           0.236588       0.289470  0.147618    0.143845   \n",
      "Emily      0.332752           0.093602       0.235524  0.233158    0.226157   \n",
      "Ashley     0.285504           0.021766       0.232052  0.238861    0.161667   \n",
      "\n",
      "           Musician   Teacher  Media Manager  Graphic Designer     Judge  \n",
      "Mary       0.203883  0.241628       0.255127          0.294780  0.274673  \n",
      "Elizabeth  0.142638  0.282117       0.068941          0.279437  0.209573  \n",
      "Patricia   0.222200  0.225314       0.117191          0.245702  0.331942  \n",
      "Jennifer   0.317936  0.242057       0.226894          0.319064  0.317733  \n",
      "Linda      0.320790  0.212300       0.216459          0.274200  0.272750  \n",
      "Barbara    0.256491  0.188351       0.201569          0.274924  0.176570  \n",
      "Margaret   0.191629  0.358846       0.137689          0.276431  0.335890  \n",
      "Susan      0.274423  0.319060       0.091953          0.316081  0.221612  \n",
      "Dorothy    0.143133  0.129340       0.158353          0.274467  0.170084  \n",
      "Sarah      0.362195  0.176125       0.306211          0.349437  0.318951  \n",
      "Jessica    0.251881  0.222849       0.070299          0.213263  0.232677  \n",
      "Helen      0.215602  0.230912       0.103744          0.185778  0.193988  \n",
      "Nancy      0.252442  0.267174       0.221197          0.300462  0.134779  \n",
      "Betty      0.134173  0.127924       0.145223          0.208976  0.160914  \n",
      "Karen      0.283416  0.262764       0.289494          0.257969  0.419691  \n",
      "Lisa       0.182898  0.288269       0.152099          0.187700  0.240647  \n",
      "Anna       0.404483  0.254968       0.117445          0.226037  0.297970  \n",
      "Sandra     0.225757  0.254949       0.197615          0.235392  0.350238  \n",
      "Emily      0.311271  0.369047       0.175752          0.361281  0.311144  \n",
      "Ashley     0.239028  0.168131       0.027852          0.180914  0.208420  \n"
     ]
    }
   ],
   "source": [
    "# Female Names\n",
    "# STEM Careers\n",
    "similarities_FvS = cosine_similarity(Female_Embeddings, STEM_Embeddings)\n",
    "# Non-STEM Careers\n",
    "similarities_FvN = cosine_similarity(Female_Embeddings, Non_STEM_Embeddings)\n",
    "similarities_FvS = pd.DataFrame(similarities_FvS, index = Female_Names, columns = STEM_Careers)\n",
    "similarities_FvN = pd.DataFrame(similarities_FvN, index = Female_Names, columns = Non_STEM_Careers)\n",
    "print(\"Cosine Similarity Matrix: Female Names vs STEM Careers\")\n",
    "print(similarities_FvS)\n",
    "print(\"Cosine Similarity Matrix: Female Names vs Non-STEM Careers\")\n",
    "print(similarities_FvN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efdaa40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DataFrame  avgCS_stsb_xlm_r_multilingual\n",
      "0       AFvP                       0.379453\n",
      "1       AFvU                       0.278014\n",
      "2       EUvP                       0.313088\n",
      "3       EUvU                       0.216619\n",
      "4       LXvP                       0.338064\n",
      "5       LXvU                       0.199606\n",
      "6       CHvP                       0.410761\n",
      "7       CHvU                       0.285716\n",
      "8        MvP                       0.304959\n",
      "9        MvU                       0.207773\n",
      "10       FvP                       0.335541\n",
      "11       FvU                       0.226860\n",
      "12       MvS                       0.176004\n",
      "13       MvN                       0.219343\n",
      "14       FvS                       0.212310\n",
      "15       FvN                       0.230369\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Mean cosine similarity of each test\n",
    "\n",
    "dataframes_dict = {\n",
    "    'AFvP': similarities_AFvP,\n",
    "    'AFvU': similarities_AFvU,\n",
    "    'EUvP': similarities_EUvP,\n",
    "    'EUvU': similarities_EUvU,\n",
    "    'LXvP': similarities_LXvP,\n",
    "    'LXvU': similarities_LXvU,\n",
    "    'CHvP': similarities_CHvP,\n",
    "    'CHvU': similarities_CHvU,\n",
    "    'MvP': similarities_MvP,\n",
    "    'MvU': similarities_MvU,\n",
    "    'FvP': similarities_FvP,\n",
    "    'FvU': similarities_FvU,\n",
    "    'MvS': similarities_MvS,\n",
    "    'MvN': similarities_MvN,\n",
    "    'FvS': similarities_FvS,\n",
    "    'FvN': similarities_FvN\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the means\n",
    "mean_dict = {}\n",
    "\n",
    "# Calculate the mean for each DataFrame and store it in the mean_dict\n",
    "for df_name, df in dataframes_dict.items():\n",
    "    df = pd.DataFrame(df)\n",
    "    mean_value = df.values.mean()\n",
    "    mean_dict[df_name] = mean_value\n",
    "\n",
    "# Create a new DataFrame from the mean_dict\n",
    "mean_df = pd.DataFrame(list(mean_dict.items()), columns=['DataFrame', 'avgCS_stsb_xlm_r_multilingual'])\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(mean_df)\n",
    "\n",
    "#Save to .csv\n",
    "mean_df.to_csv('stsb_xlm_r_multilingual_meanCosSim.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4610f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFvP.csv was created\n",
      "AFvU.csv was created\n",
      "EUvP.csv was created\n",
      "EUvU.csv was created\n",
      "LXvP.csv was created\n",
      "LXvU.csv was created\n",
      "CHvP.csv was created\n",
      "CHvU.csv was created\n",
      "MvP.csv was created\n",
      "MvU.csv was created\n",
      "FvP.csv was created\n",
      "FvU.csv was created\n",
      "MvS.csv was created\n",
      "MvN.csv was created\n",
      "FvS.csv was created\n",
      "FvN.csv was created\n"
     ]
    }
   ],
   "source": [
    "for key, df in dataframes_dict.items():\n",
    "    # Construct the file path using the key\n",
    "    file_path = f\"{key}.csv\"\n",
    "    \n",
    "    # Write the DataFrame to the CSV file\n",
    "    df.to_csv(file_path, index=True)\n",
    "    print(f\"{key}.csv was created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
