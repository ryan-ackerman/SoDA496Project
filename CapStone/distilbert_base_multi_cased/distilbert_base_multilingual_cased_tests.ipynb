{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339e3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from transformers) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c953798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from torch) (3.12.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87367d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "178485cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ryan ackerman\\anaconda3\\envs\\venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4108488",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a12100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan Ackerman\\anaconda3\\envs\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading model.safetensors: 100%|████████████████████████████████████████████████| 542M/542M [03:29<00:00, 2.59MB/s]\n",
      "C:\\Users\\Ryan Ackerman\\anaconda3\\envs\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ryan Ackerman\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "# Tokenize words and get embeddings\n",
    "def get_word_embeddings(word_list):\n",
    "    tokens = tokenizer(word_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Average pooling over tokens\n",
    "    return embeddings\n",
    "\n",
    "# Word Sets and Embeddings\n",
    "AF_Names = [\"Reginald\", \"Kameron\", \"Kendrick\", \"Javon\", \"Tyrell\", \"Jamar\", \"Camron\", \"Tyree\", \"Jamari\", \"Reggie\", \"Jada\", \n",
    "            \"Latoya\", \"Jayla\", \"Tamika\", \"Latoyna\", \"Journey\", \"Tameka\", \"Journee\", \"Lawanda\", \"Janiya\"]\n",
    "AF_Embeddings = get_word_embeddings(AF_Names)\n",
    "\n",
    "EU_Names = [\"James\", \"John\", \"Robert\", \"Michael\", \"William\", \"David\", \"Joseph\", \"Richard\", \"Charles\", \"Thomas\", \"Mary\", \n",
    "            \"Elizabeth\", \"Patricia\", \"Jennifer\", \"Linda\", \"Barbara\", \"Margaret\", \"Susan\", \"Sarah\", \"Jessica\"]\n",
    "EU_Embeddings = get_word_embeddings(EU_Names)\n",
    "\n",
    "LX_Names = [\"Paul\", \"Vincent\", \"Victor\", \"Adrian\", \"Marcus\", \"Leo\", \"Miles\", \"Roman\", \"Sergio\", \"Felix\", \"Patricia\", \"Laura\", \n",
    "            \"Amanda\", \"Victoria\", \"Julia\", \"Gloria\", \"Diana\", \"Clara\", \"Paula\", \"Norma\"]\n",
    "LX_Embeddings = get_word_embeddings(LX_Names)\n",
    "\n",
    "CH_Names = [\"Lian\", \"Shan\", \"Lew\", \"Long\", \"Quan\", \"Jun\", \"Tou\", \"Jin\", \"Cai\", \"Chan\", \"Lue\", \"China\", \"Lu\", \"Maylee\", \n",
    "            \"Tennie\", \"Maylin\", \"Chynna\", \"Jia\", \"Mei\", \"Tylee\"]\n",
    "CH_Embeddings = get_word_embeddings(CH_Names)\n",
    "\n",
    "Male_Names = [\"James\", \"John\", \"Robert\", \"Michael\", \"William\", \"David\", \"Joseph\", \"Richard\", \"Charles\", \"Thomas\", \n",
    "              \"Christopher\", \"Daniel\", \"Matthew\",\"George\", \"Anthony\", \"Donald\", \"Paul\", \"Mark\", \"Andrew\", \"Edward\"]\n",
    "Male_Embeddings = get_word_embeddings(Male_Names)\n",
    "\n",
    "Female_Names = [\"Mary\", \"Elizabeth\", \"Patricia\", \"Jennifer\", \"Linda\", \"Barbara\", \"Margaret\", \"Susan\", \"Dorothy\", \"Sarah\", \n",
    "                \"Jessica\", \"Helen\", \"Nancy\", \"Betty\", \"Karen\", \"Lisa\", \"Anna\", \"Sandra\", \"Emily\", \"Ashley\"]\n",
    "Female_Embeddings = get_word_embeddings(Female_Names)\n",
    "\n",
    "Pleasant_Words = [\"happy\", \"agreeable\", \"polite\", \"civil\", \"charming\", \"gracious\", \"gentle\", \"approachable\", \"love\", \"cool\"]\n",
    "Pleasant_Embeddings = get_word_embeddings(Pleasant_Words)\n",
    "\n",
    "Unpleasant_Words = [\"rude\", \"lazy\", \"disagreeable\", \"lousy\", \"sad\", \"hate\", \"violent\", \"bitter\", \"harsh\", \"angry\"]\n",
    "Unpleasant_Embeddings = get_word_embeddings(Unpleasant_Words)\n",
    "\n",
    "STEM_Careers = [\"Software Developer\", \"Nurse Practitioner\", \"Health Services Manager\", \"Physicians Assistant\", \n",
    "                \"Security Analyst\", \"IT Manager\", \"Web Developer\", \"Dentist\", \"Orthodontist\", \"Computer Systems Analyst\"]\n",
    "STEM_Embeddings = get_word_embeddings(STEM_Careers)\n",
    "\n",
    "Non_STEM_Careers = [\"Artist\", \"Marketing Manager\", \"Social Worker\", \"Attorney\", \"Journalist\", \"Musician\", \"Teacher\", \n",
    "                    \"Media Manager\", \"Graphic Designer\", \"Judge\"]\n",
    "Non_STEM_Embeddings = get_word_embeddings(Non_STEM_Careers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0792c",
   "metadata": {},
   "source": [
    "# TEST 1: Racial Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50bd0cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: African American Names vs Pleasant Words\n",
      "             happy  agreeable    polite     civil  charming  gracious  \\\n",
      "Reginald  0.566712   0.526419  0.587341  0.583226  0.575985  0.474079   \n",
      "Kameron   0.459514   0.498966  0.621140  0.573623  0.563997  0.467893   \n",
      "Kendrick  0.590819   0.574628  0.624650  0.597998  0.573840  0.513798   \n",
      "Javon     0.475469   0.448161  0.606459  0.515011  0.547470  0.415408   \n",
      "Tyrell    0.441679   0.488627  0.608197  0.483342  0.586161  0.452509   \n",
      "Jamar     0.474144   0.455577  0.566285  0.509067  0.556861  0.359888   \n",
      "Camron    0.478365   0.494747  0.647060  0.593780  0.599473  0.468733   \n",
      "Tyree     0.473199   0.493463  0.609319  0.474316  0.592303  0.429475   \n",
      "Jamari    0.465766   0.411652  0.581802  0.498813  0.577082  0.336392   \n",
      "Reggie    0.616953   0.510686  0.565080  0.524070  0.577505  0.489746   \n",
      "Jada      0.553404   0.504154  0.645691  0.552507  0.564458  0.505430   \n",
      "Latoya    0.554431   0.521641  0.678377  0.560746  0.521845  0.489784   \n",
      "Jayla     0.549644   0.489601  0.596837  0.490471  0.537003  0.468708   \n",
      "Tamika    0.468403   0.458716  0.651273  0.490044  0.537159  0.409362   \n",
      "Latoyna   0.444972   0.438943  0.606255  0.533521  0.469886  0.428432   \n",
      "Journey   0.640656   0.536590  0.582941  0.504652  0.615335  0.522185   \n",
      "Tameka    0.434095   0.456343  0.631160  0.482811  0.525334  0.366848   \n",
      "Journee   0.477941   0.478198  0.546615  0.530693  0.483857  0.465428   \n",
      "Lawanda   0.499063   0.482260  0.578625  0.546938  0.524352  0.458445   \n",
      "Janiya    0.499269   0.466460  0.577746  0.534041  0.528841  0.396450   \n",
      "\n",
      "            gentle  approachable      love      cool  \n",
      "Reginald  0.583562      0.496538  0.539569  0.632427  \n",
      "Kameron   0.585629      0.471186  0.486454  0.548194  \n",
      "Kendrick  0.594486      0.554458  0.590124  0.696222  \n",
      "Javon     0.498518      0.439663  0.461152  0.565993  \n",
      "Tyrell    0.557412      0.452189  0.468354  0.555573  \n",
      "Jamar     0.502897      0.468147  0.464395  0.522343  \n",
      "Camron    0.548549      0.468110  0.498832  0.616454  \n",
      "Tyree     0.546230      0.469279  0.489789  0.570695  \n",
      "Jamari    0.490578      0.432372  0.453898  0.517562  \n",
      "Reggie    0.583699      0.495174  0.557791  0.663531  \n",
      "Jada      0.559165      0.497919  0.544938  0.611209  \n",
      "Latoya    0.564764      0.501813  0.567398  0.607358  \n",
      "Jayla     0.549374      0.485011  0.555732  0.598497  \n",
      "Tamika    0.538730      0.446701  0.492426  0.555089  \n",
      "Latoyna   0.495248      0.409305  0.472133  0.540142  \n",
      "Journey   0.561610      0.582723  0.651913  0.663879  \n",
      "Tameka    0.516251      0.450565  0.480022  0.538602  \n",
      "Journee   0.533185      0.462181  0.449401  0.525740  \n",
      "Lawanda   0.563429      0.469988  0.505606  0.559333  \n",
      "Janiya    0.488371      0.440153  0.471606  0.549114  \n",
      "Cosine Similarity Matrix: African American Names vs Unpleasant Words\n",
      "              rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Reginald  0.602565  0.563402      0.482587  0.576548  0.691129  0.523908   \n",
      "Kameron   0.580662  0.558078      0.461337  0.587480  0.567942  0.520933   \n",
      "Kendrick  0.585174  0.584942      0.509349  0.585339  0.689392  0.527057   \n",
      "Javon     0.585710  0.548841      0.449470  0.651940  0.545977  0.497339   \n",
      "Tyrell    0.579259  0.539307      0.450771  0.570690  0.520674  0.486287   \n",
      "Jamar     0.599047  0.488067      0.469370  0.608737  0.606412  0.516447   \n",
      "Camron    0.615891  0.601379      0.441452  0.645051  0.577545  0.491859   \n",
      "Tyree     0.602943  0.596869      0.471031  0.576546  0.509776  0.500216   \n",
      "Jamari    0.607034  0.480302      0.465265  0.629728  0.575101  0.498741   \n",
      "Reggie    0.580070  0.554546      0.464120  0.572815  0.633471  0.523936   \n",
      "Jada      0.623637  0.624197      0.492142  0.656180  0.650177  0.576918   \n",
      "Latoya    0.689093  0.667849      0.509726  0.720890  0.635903  0.564069   \n",
      "Jayla     0.589767  0.584393      0.478587  0.639648  0.605067  0.516471   \n",
      "Tamika    0.648779  0.543592      0.442970  0.615214  0.579680  0.525913   \n",
      "Latoyna   0.641981  0.683098      0.419180  0.654630  0.555503  0.479333   \n",
      "Journey   0.539432  0.532350      0.510616  0.524992  0.637503  0.476818   \n",
      "Tameka    0.644583  0.532331      0.442941  0.590795  0.553803  0.548628   \n",
      "Journee   0.524879  0.529352      0.474538  0.481769  0.485761  0.444545   \n",
      "Lawanda   0.590490  0.549465      0.472441  0.621771  0.567987  0.517182   \n",
      "Janiya    0.590424  0.595933      0.456125  0.619278  0.596610  0.470694   \n",
      "\n",
      "           violent    bitter     harsh     angry  \n",
      "Reginald  0.679168  0.645516  0.571797  0.570447  \n",
      "Kameron   0.551370  0.585642  0.530707  0.595286  \n",
      "Kendrick  0.701217  0.684180  0.586689  0.594231  \n",
      "Javon     0.541395  0.555155  0.570250  0.512823  \n",
      "Tyrell    0.533749  0.582990  0.529896  0.585934  \n",
      "Jamar     0.530246  0.546583  0.691824  0.523686  \n",
      "Camron    0.594723  0.600709  0.552170  0.621125  \n",
      "Tyree     0.547654  0.604605  0.523274  0.547034  \n",
      "Jamari    0.515209  0.526122  0.617355  0.540773  \n",
      "Reggie    0.666621  0.661672  0.545950  0.568823  \n",
      "Jada      0.588840  0.627435  0.701734  0.554435  \n",
      "Latoya    0.602962  0.629416  0.621680  0.591071  \n",
      "Jayla     0.555582  0.575797  0.600475  0.523197  \n",
      "Tamika    0.536146  0.567776  0.576355  0.530669  \n",
      "Latoyna   0.518112  0.570686  0.514702  0.512563  \n",
      "Journey   0.656361  0.629529  0.546756  0.564046  \n",
      "Tameka    0.509923  0.567815  0.554036  0.492185  \n",
      "Journee   0.601416  0.590259  0.472767  0.479657  \n",
      "Lawanda   0.543818  0.552872  0.611151  0.564581  \n",
      "Janiya    0.526118  0.559558  0.612222  0.580256  \n"
     ]
    }
   ],
   "source": [
    "# African American Names\n",
    "# Pleasant Words\n",
    "similarities_AFvP = cosine_similarity(AF_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_AFvU = cosine_similarity(AF_Embeddings, Unpleasant_Embeddings)\n",
    "\n",
    "similarities_AFvP = pd.DataFrame(similarities_AFvP, index = AF_Names, columns = Pleasant_Words)\n",
    "similarities_AFvU = pd.DataFrame(similarities_AFvU, index = AF_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: African American Names vs Pleasant Words\")\n",
    "print(similarities_AFvP)\n",
    "print(\"Cosine Similarity Matrix: African American Names vs Unpleasant Words\")\n",
    "print(similarities_AFvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7b5b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: European American Names vs Pleasant Words\n",
      "              happy  agreeable    polite     civil  charming  gracious  \\\n",
      "James      0.543416   0.509776  0.581580  0.551140  0.569809  0.482150   \n",
      "John       0.521828   0.506885  0.603690  0.560350  0.545691  0.511387   \n",
      "Robert     0.548064   0.563088  0.619817  0.561529  0.553753  0.485154   \n",
      "Michael    0.519469   0.465244  0.606560  0.539212  0.550376  0.474522   \n",
      "William    0.525600   0.542765  0.589079  0.538492  0.593231  0.460836   \n",
      "David      0.519735   0.501074  0.626363  0.547168  0.574771  0.472883   \n",
      "Joseph     0.518294   0.506203  0.588294  0.551050  0.569889  0.494914   \n",
      "Richard    0.545702   0.500254  0.604310  0.547291  0.594735  0.484986   \n",
      "Charles    0.500004   0.492459  0.575595  0.543024  0.536702  0.485205   \n",
      "Thomas     0.506336   0.519829  0.624939  0.568341  0.588635  0.490081   \n",
      "Mary       0.592158   0.519858  0.579484  0.514398  0.556302  0.544456   \n",
      "Elizabeth  0.500704   0.470875  0.512178  0.480943  0.486367  0.491594   \n",
      "Patricia   0.537397   0.495407  0.631213  0.549169  0.553075  0.468133   \n",
      "Jennifer   0.606165   0.434788  0.604126  0.538312  0.524223  0.518970   \n",
      "Linda      0.612696   0.434804  0.601407  0.540143  0.529557  0.488635   \n",
      "Barbara    0.563050   0.482297  0.601469  0.550955  0.548945  0.478270   \n",
      "Margaret   0.554797   0.521027  0.559766  0.515708  0.534594  0.493764   \n",
      "Susan      0.603058   0.535970  0.600753  0.541724  0.513949  0.521649   \n",
      "Sarah      0.574112   0.505097  0.589253  0.522312  0.543629  0.518689   \n",
      "Jessica    0.592346   0.450547  0.581345  0.521108  0.492331  0.491589   \n",
      "\n",
      "             gentle  approachable      love      cool  \n",
      "James      0.593084      0.512673  0.524948  0.647451  \n",
      "John       0.625600      0.502070  0.531957  0.616648  \n",
      "Robert     0.597432      0.529719  0.519423  0.642731  \n",
      "Michael    0.565232      0.485737  0.530353  0.638966  \n",
      "William    0.602801      0.513457  0.547300  0.604000  \n",
      "David      0.602195      0.484654  0.511042  0.648565  \n",
      "Joseph     0.542434      0.486225  0.526029  0.635803  \n",
      "Richard    0.569123      0.507636  0.553478  0.622761  \n",
      "Charles    0.637657      0.487575  0.521215  0.590471  \n",
      "Thomas     0.631866      0.525792  0.536782  0.607585  \n",
      "Mary       0.616023      0.515868  0.597432  0.632352  \n",
      "Elizabeth  0.548808      0.439956  0.508450  0.524493  \n",
      "Patricia   0.586730      0.519895  0.556755  0.604975  \n",
      "Jennifer   0.558900      0.422701  0.629200  0.659258  \n",
      "Linda      0.538642      0.441805  0.606409  0.644768  \n",
      "Barbara    0.553529      0.484446  0.524575  0.650370  \n",
      "Margaret   0.610554      0.516216  0.522836  0.566286  \n",
      "Susan      0.605511      0.519729  0.559725  0.625357  \n",
      "Sarah      0.578980      0.482398  0.573193  0.632080  \n",
      "Jessica    0.514033      0.446327  0.547064  0.653537  \n",
      "Cosine Similarity Matrix: European American Names vs Unpleasant Words\n",
      "               rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "James      0.541806  0.533028      0.505112  0.624330  0.580849  0.464368   \n",
      "John       0.594056  0.554435      0.438125  0.629386  0.601994  0.521619   \n",
      "Robert     0.558484  0.562066      0.484349  0.621150  0.585729  0.480191   \n",
      "Michael    0.543460  0.559666      0.444475  0.618556  0.569844  0.493233   \n",
      "William    0.553416  0.541669      0.516762  0.594166  0.579406  0.492367   \n",
      "David      0.540499  0.538653      0.445325  0.593050  0.570469  0.513760   \n",
      "Joseph     0.524382  0.530553      0.472451  0.604348  0.571510  0.472400   \n",
      "Richard    0.556361  0.560704      0.487406  0.583839  0.595152  0.502890   \n",
      "Charles    0.508335  0.537901      0.483137  0.576507  0.535327  0.473900   \n",
      "Thomas     0.576014  0.554440      0.487238  0.640500  0.593088  0.525819   \n",
      "Mary       0.506924  0.539236      0.513691  0.563613  0.545723  0.495143   \n",
      "Elizabeth  0.468674  0.483117      0.445474  0.457051  0.494051  0.472208   \n",
      "Patricia   0.544502  0.570610      0.497344  0.573950  0.564658  0.469807   \n",
      "Jennifer   0.531511  0.549530      0.394400  0.596065  0.572354  0.545974   \n",
      "Linda      0.529706  0.570134      0.390815  0.597049  0.565903  0.527540   \n",
      "Barbara    0.505554  0.573301      0.473798  0.572461  0.565490  0.487477   \n",
      "Margaret   0.503569  0.528367      0.524023  0.519226  0.539998  0.517063   \n",
      "Susan      0.528690  0.555422      0.471392  0.602034  0.583539  0.503095   \n",
      "Sarah      0.526039  0.557322      0.468560  0.583395  0.592164  0.498088   \n",
      "Jessica    0.500792  0.533670      0.400330  0.568917  0.577320  0.424166   \n",
      "\n",
      "            violent    bitter     harsh     angry  \n",
      "James      0.616682  0.606143  0.507186  0.580269  \n",
      "John       0.618589  0.577595  0.532743  0.583046  \n",
      "Robert     0.648758  0.616185  0.548271  0.585544  \n",
      "Michael    0.604750  0.571528  0.519294  0.577923  \n",
      "William    0.590007  0.590886  0.544532  0.625886  \n",
      "David      0.590515  0.582163  0.564684  0.580446  \n",
      "Joseph     0.639656  0.596094  0.516442  0.538629  \n",
      "Richard    0.619874  0.628681  0.546676  0.610136  \n",
      "Charles    0.627320  0.579576  0.494749  0.531953  \n",
      "Thomas     0.627710  0.604948  0.570837  0.620857  \n",
      "Mary       0.578106  0.636551  0.514732  0.580555  \n",
      "Elizabeth  0.502551  0.517262  0.438007  0.540367  \n",
      "Patricia   0.587284  0.581990  0.526607  0.569494  \n",
      "Jennifer   0.570700  0.584940  0.530965  0.564178  \n",
      "Linda      0.553208  0.592578  0.549063  0.522203  \n",
      "Barbara    0.559844  0.619759  0.536052  0.568091  \n",
      "Margaret   0.581048  0.576535  0.549789  0.535936  \n",
      "Susan      0.596373  0.622167  0.532560  0.586189  \n",
      "Sarah      0.565959  0.572351  0.553989  0.554465  \n",
      "Jessica    0.560891  0.545072  0.473721  0.529806  \n"
     ]
    }
   ],
   "source": [
    "# European American Names\n",
    "# Pleasant Words\n",
    "similarities_EUvP = cosine_similarity(EU_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_EUvU = cosine_similarity(EU_Embeddings, Unpleasant_Embeddings)\n",
    "\n",
    "similarities_EUvP = pd.DataFrame(similarities_EUvP, index = EU_Names, columns = Pleasant_Words)\n",
    "similarities_EUvU = pd.DataFrame(similarities_EUvU, index = EU_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: European American Names vs Pleasant Words\")\n",
    "print(similarities_EUvP)\n",
    "print(\"Cosine Similarity Matrix: European American Names vs Unpleasant Words\")\n",
    "print(similarities_EUvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c98f3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Latin American Names vs Pleasant Words\n",
      "             happy  agreeable    polite     civil  charming  gracious  \\\n",
      "Paul      0.533959   0.474876  0.646320  0.578168  0.520104  0.493193   \n",
      "Vincent   0.469814   0.426131  0.590920  0.566501  0.514194  0.466878   \n",
      "Victor    0.482301   0.429872  0.563138  0.562992  0.496960  0.451747   \n",
      "Adrian    0.546099   0.473693  0.597382  0.588334  0.557292  0.494811   \n",
      "Marcus    0.484134   0.502253  0.630629  0.533620  0.522302  0.481580   \n",
      "Leo       0.553104   0.466519  0.637988  0.543170  0.570141  0.467344   \n",
      "Miles     0.545628   0.502599  0.585340  0.550911  0.548275  0.517907   \n",
      "Roman     0.498830   0.451926  0.621183  0.566908  0.534944  0.475591   \n",
      "Sergio    0.509969   0.442918  0.618717  0.540100  0.527884  0.440288   \n",
      "Felix     0.540507   0.510688  0.611968  0.579109  0.561630  0.503952   \n",
      "Patricia  0.537397   0.495407  0.631213  0.549169  0.553075  0.468133   \n",
      "Laura     0.664022   0.442322  0.610638  0.505311  0.572668  0.502181   \n",
      "Amanda    0.601068   0.461734  0.585853  0.516541  0.486926  0.463867   \n",
      "Victoria  0.494347   0.448962  0.540121  0.557348  0.487158  0.503642   \n",
      "Julia     0.593162   0.484817  0.632564  0.573542  0.555205  0.540515   \n",
      "Gloria    0.609928   0.494587  0.550159  0.524928  0.484054  0.624415   \n",
      "Diana     0.589603   0.491433  0.589880  0.534357  0.546104  0.507451   \n",
      "Clara     0.573095   0.493906  0.590565  0.544171  0.512773  0.475564   \n",
      "Paula     0.583155   0.420809  0.607940  0.576449  0.514243  0.526284   \n",
      "Norma     0.528928   0.478687  0.615274  0.585234  0.509925  0.524380   \n",
      "\n",
      "            gentle  approachable      love      cool  \n",
      "Paul      0.587690      0.487924  0.509818  0.651608  \n",
      "Vincent   0.586292      0.423502  0.482819  0.580995  \n",
      "Victor    0.542635      0.443338  0.500249  0.584737  \n",
      "Adrian    0.541536      0.513551  0.527633  0.671134  \n",
      "Marcus    0.592578      0.480178  0.476544  0.605632  \n",
      "Leo       0.592927      0.457528  0.572548  0.664901  \n",
      "Miles     0.578957      0.496275  0.537343  0.628840  \n",
      "Roman     0.519628      0.459186  0.539736  0.606123  \n",
      "Sergio    0.535228      0.422815  0.489119  0.583836  \n",
      "Felix     0.582107      0.476491  0.531338  0.654607  \n",
      "Patricia  0.586730      0.519895  0.556755  0.604975  \n",
      "Laura     0.587062      0.451528  0.629818  0.654682  \n",
      "Amanda    0.584199      0.468899  0.580350  0.630667  \n",
      "Victoria  0.548204      0.435888  0.518026  0.549798  \n",
      "Julia     0.604620      0.490722  0.605827  0.677553  \n",
      "Gloria    0.578672      0.501116  0.641694  0.591376  \n",
      "Diana     0.603691      0.509026  0.618672  0.647716  \n",
      "Clara     0.577869      0.469920  0.573953  0.599304  \n",
      "Paula     0.535316      0.440298  0.585605  0.674000  \n",
      "Norma     0.624008      0.470757  0.557881  0.648976  \n",
      "Cosine Similarity Matrix: Latin American Names vs Unpleasant Words\n",
      "              rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Paul      0.556327  0.566154      0.421172  0.634106  0.580520  0.485059   \n",
      "Vincent   0.557312  0.535707      0.379918  0.582350  0.544798  0.462922   \n",
      "Victor    0.532889  0.519144      0.409375  0.554428  0.574933  0.405455   \n",
      "Adrian    0.543685  0.554569      0.478858  0.591376  0.586629  0.454618   \n",
      "Marcus    0.548783  0.554101      0.433733  0.558801  0.559515  0.492334   \n",
      "Leo       0.598169  0.590666      0.504141  0.629762  0.619386  0.487812   \n",
      "Miles     0.496488  0.544235      0.454782  0.563728  0.566852  0.489025   \n",
      "Roman     0.551752  0.574032      0.404958  0.602478  0.624749  0.443722   \n",
      "Sergio    0.534597  0.545633      0.406961  0.528299  0.547967  0.455398   \n",
      "Felix     0.553621  0.545615      0.464477  0.616022  0.580596  0.568477   \n",
      "Patricia  0.544502  0.570610      0.497344  0.573950  0.564658  0.469807   \n",
      "Laura     0.540215  0.548648      0.426311  0.583533  0.559827  0.456107   \n",
      "Amanda    0.524500  0.522904      0.422162  0.585849  0.600521  0.470037   \n",
      "Victoria  0.485439  0.546489      0.413830  0.505309  0.536462  0.471508   \n",
      "Julia     0.542336  0.629229      0.454094  0.601217  0.598157  0.530378   \n",
      "Gloria    0.494974  0.548468      0.460509  0.486493  0.500580  0.529924   \n",
      "Diana     0.521795  0.583185      0.476540  0.566050  0.553976  0.501438   \n",
      "Clara     0.544615  0.561958      0.446961  0.569341  0.545743  0.527775   \n",
      "Paula     0.534901  0.572748      0.382238  0.603138  0.579381  0.481139   \n",
      "Norma     0.582081  0.567076      0.419628  0.546579  0.601552  0.477911   \n",
      "\n",
      "           violent    bitter     harsh     angry  \n",
      "Paul      0.643894  0.584631  0.507127  0.554286  \n",
      "Vincent   0.618973  0.561376  0.454262  0.570321  \n",
      "Victor    0.590453  0.532004  0.458019  0.527234  \n",
      "Adrian    0.627413  0.590581  0.516710  0.576220  \n",
      "Marcus    0.588650  0.577720  0.543210  0.547857  \n",
      "Leo       0.602296  0.612095  0.537425  0.572549  \n",
      "Miles     0.554914  0.587340  0.565919  0.536714  \n",
      "Roman     0.610293  0.600978  0.508417  0.551657  \n",
      "Sergio    0.552532  0.544252  0.500218  0.555997  \n",
      "Felix     0.607479  0.590229  0.538811  0.586573  \n",
      "Patricia  0.587284  0.581990  0.526607  0.569494  \n",
      "Laura     0.582373  0.610067  0.536462  0.544575  \n",
      "Amanda    0.584940  0.588123  0.535647  0.522462  \n",
      "Victoria  0.520570  0.484870  0.477589  0.551233  \n",
      "Julia     0.607497  0.619950  0.574864  0.601249  \n",
      "Gloria    0.542074  0.595073  0.543074  0.548545  \n",
      "Diana     0.552590  0.587863  0.523774  0.577786  \n",
      "Clara     0.538459  0.587357  0.506258  0.571287  \n",
      "Paula     0.570094  0.579418  0.525203  0.530015  \n",
      "Norma     0.598815  0.593715  0.528479  0.552280  \n"
     ]
    }
   ],
   "source": [
    "# Latin American Names\n",
    "# Pleasant Words\n",
    "similarities_LXvP = cosine_similarity(LX_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_LXvU = cosine_similarity(LX_Embeddings, Unpleasant_Embeddings)\n",
    "\n",
    "similarities_LXvP = pd.DataFrame(similarities_LXvP, index = LX_Names, columns = Pleasant_Words)\n",
    "similarities_LXvU = pd.DataFrame(similarities_LXvU, index = LX_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Latin American Names vs Pleasant Words\")\n",
    "print(similarities_LXvP)\n",
    "print(\"Cosine Similarity Matrix: Latin American Names vs Unpleasant Words\")\n",
    "print(similarities_LXvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b0bab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Chinese American Names vs Pleasant Words\n",
      "           happy  agreeable    polite     civil  charming  gracious    gentle  \\\n",
      "Lian    0.424168   0.418780  0.539024  0.462996  0.503802  0.367526  0.452993   \n",
      "Shan    0.477224   0.479135  0.619274  0.502296  0.576228  0.405987  0.531663   \n",
      "Lew     0.518806   0.475788  0.620047  0.569935  0.526293  0.443812  0.496885   \n",
      "Long    0.675252   0.600934  0.597038  0.522114  0.555976  0.564773  0.620500   \n",
      "Quan    0.554439   0.493097  0.631707  0.558612  0.599176  0.444851  0.579445   \n",
      "Jun     0.623993   0.452226  0.597623  0.544619  0.569791  0.454120  0.528176   \n",
      "Tou     0.522799   0.461164  0.584964  0.439832  0.504451  0.429252  0.546270   \n",
      "Jin     0.520439   0.448166  0.566994  0.493429  0.547058  0.387329  0.500439   \n",
      "Cai     0.546343   0.475161  0.640174  0.588460  0.589269  0.458047  0.529951   \n",
      "Chan    0.549638   0.434457  0.570563  0.526540  0.569240  0.414669  0.521200   \n",
      "Lue     0.446052   0.429246  0.617879  0.486209  0.473093  0.417032  0.583602   \n",
      "China   0.506190   0.460218  0.507603  0.514071  0.543534  0.441945  0.474778   \n",
      "Lu      0.478966   0.437409  0.649678  0.536516  0.511054  0.421853  0.587239   \n",
      "Maylee  0.610745   0.497716  0.555162  0.468958  0.562856  0.471173  0.573321   \n",
      "Tennie  0.537536   0.513525  0.646816  0.514979  0.563963  0.512218  0.624166   \n",
      "Maylin  0.523334   0.467950  0.561441  0.494951  0.603584  0.396621  0.547826   \n",
      "Chynna  0.447627   0.438408  0.592011  0.519885  0.535652  0.406768  0.536405   \n",
      "Jia     0.439569   0.428471  0.544377  0.449970  0.527831  0.376320  0.468224   \n",
      "Mei     0.603565   0.430274  0.608680  0.532726  0.555593  0.419064  0.538400   \n",
      "Tylee   0.531357   0.483237  0.640920  0.497730  0.587035  0.444762  0.589874   \n",
      "\n",
      "        approachable      love      cool  \n",
      "Lian        0.387897  0.444893  0.547771  \n",
      "Shan        0.464289  0.497469  0.611537  \n",
      "Lew         0.448985  0.483956  0.602202  \n",
      "Long        0.571907  0.653305  0.673078  \n",
      "Quan        0.493950  0.570282  0.662380  \n",
      "Jun         0.447687  0.603109  0.718604  \n",
      "Tou         0.444894  0.520284  0.544157  \n",
      "Jin         0.447085  0.518199  0.640845  \n",
      "Cai         0.431040  0.546311  0.700212  \n",
      "Chan        0.440641  0.538762  0.616843  \n",
      "Lue         0.416921  0.515159  0.539588  \n",
      "China       0.461173  0.528892  0.597827  \n",
      "Lu          0.417250  0.541930  0.590307  \n",
      "Maylee      0.525093  0.619110  0.604990  \n",
      "Tennie      0.497604  0.503243  0.592659  \n",
      "Maylin      0.444630  0.527698  0.556990  \n",
      "Chynna      0.432561  0.488075  0.513624  \n",
      "Jia         0.420737  0.465772  0.541923  \n",
      "Mei         0.417682  0.574743  0.666418  \n",
      "Tylee       0.483481  0.524915  0.613527  \n",
      "Cosine Similarity Matrix: Chinese American Names vs Unpleasant Words\n",
      "            rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Lian    0.541127  0.504311      0.375522  0.582719  0.501994  0.489147   \n",
      "Shan    0.579634  0.544385      0.466212  0.610626  0.612545  0.507805   \n",
      "Lew     0.631294  0.703529      0.444533  0.621897  0.683327  0.505635   \n",
      "Long    0.589501  0.547331      0.525099  0.626152  0.624683  0.574779   \n",
      "Quan    0.609132  0.574708      0.441604  0.640191  0.659101  0.561472   \n",
      "Jun     0.593597  0.561798      0.416338  0.638183  0.677909  0.544333   \n",
      "Tou     0.601419  0.512894      0.450025  0.594858  0.542410  0.606973   \n",
      "Jin     0.554158  0.512902      0.427239  0.552618  0.602067  0.485864   \n",
      "Cai     0.638049  0.584096      0.466802  0.685046  0.689502  0.553989   \n",
      "Chan    0.562553  0.528617      0.405006  0.614658  0.611235  0.522577   \n",
      "Lue     0.648952  0.568590      0.415134  0.652012  0.529595  0.607841   \n",
      "China   0.466238  0.489929      0.445067  0.497063  0.563122  0.439455   \n",
      "Lu      0.637130  0.615232      0.414847  0.685121  0.602273  0.564697   \n",
      "Maylee  0.541866  0.524145      0.497328  0.587120  0.548548  0.506726   \n",
      "Tennie  0.668084  0.639465      0.476244  0.607821  0.556336  0.562466   \n",
      "Maylin  0.587911  0.518306      0.468297  0.640202  0.563497  0.505607   \n",
      "Chynna  0.608813  0.598055      0.403473  0.687295  0.549214  0.508559   \n",
      "Jia     0.563273  0.521896      0.424502  0.572203  0.543199  0.532819   \n",
      "Mei     0.629140  0.569131      0.416885  0.599095  0.664463  0.611552   \n",
      "Tylee   0.633311  0.598074      0.449290  0.657107  0.555139  0.537552   \n",
      "\n",
      "         violent    bitter     harsh     angry  \n",
      "Lian    0.479207  0.523624  0.553689  0.542825  \n",
      "Shan    0.598437  0.611834  0.613378  0.530433  \n",
      "Lew     0.637805  0.642933  0.559557  0.575730  \n",
      "Long    0.656390  0.711714  0.614509  0.567932  \n",
      "Quan    0.672201  0.642425  0.636208  0.586002  \n",
      "Jun     0.675833  0.675981  0.581774  0.549562  \n",
      "Tou     0.526196  0.573263  0.576124  0.517273  \n",
      "Jin     0.603204  0.613677  0.543517  0.543112  \n",
      "Cai     0.669633  0.685097  0.606995  0.589336  \n",
      "Chan    0.623896  0.614725  0.621048  0.540997  \n",
      "Lue     0.533458  0.562055  0.576296  0.541910  \n",
      "China   0.609985  0.589703  0.483337  0.497331  \n",
      "Lu      0.601154  0.593707  0.622221  0.563734  \n",
      "Maylee  0.565969  0.645075  0.544230  0.526515  \n",
      "Tennie  0.577030  0.642640  0.579914  0.566781  \n",
      "Maylin  0.557132  0.641790  0.557715  0.575082  \n",
      "Chynna  0.506515  0.569426  0.588977  0.553834  \n",
      "Jia     0.508371  0.529091  0.588279  0.501412  \n",
      "Mei     0.634194  0.666541  0.596532  0.548485  \n",
      "Tylee   0.580484  0.651229  0.563413  0.552619  \n"
     ]
    }
   ],
   "source": [
    "# Chinese American Names\n",
    "# Pleasant Words\n",
    "similarities_CHvP = cosine_similarity(CH_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_CHvU = cosine_similarity(CH_Embeddings, Unpleasant_Embeddings)\n",
    "\n",
    "similarities_CHvP = pd.DataFrame(similarities_CHvP, index = CH_Names, columns = Pleasant_Words)\n",
    "similarities_CHvU = pd.DataFrame(similarities_CHvU, index = CH_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Chinese American Names vs Pleasant Words\")\n",
    "print(similarities_CHvP)\n",
    "print(\"Cosine Similarity Matrix: Chinese American Names vs Unpleasant Words\")\n",
    "print(similarities_CHvU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6967ba9b",
   "metadata": {},
   "source": [
    "# TEST 2: Gender Biases for Favorability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984fa641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Male Names vs Pleasant Words\n",
      "                happy  agreeable    polite     civil  charming  gracious  \\\n",
      "James        0.543416   0.509776  0.581580  0.551140  0.569809  0.482150   \n",
      "John         0.521828   0.506885  0.603690  0.560350  0.545691  0.511387   \n",
      "Robert       0.548064   0.563088  0.619817  0.561529  0.553753  0.485154   \n",
      "Michael      0.519469   0.465244  0.606560  0.539212  0.550376  0.474522   \n",
      "William      0.525600   0.542765  0.589079  0.538492  0.593231  0.460836   \n",
      "David        0.519735   0.501074  0.626363  0.547168  0.574771  0.472883   \n",
      "Joseph       0.518294   0.506203  0.588294  0.551050  0.569889  0.494914   \n",
      "Richard      0.545702   0.500254  0.604310  0.547291  0.594735  0.484986   \n",
      "Charles      0.500004   0.492459  0.575595  0.543024  0.536702  0.485205   \n",
      "Thomas       0.506336   0.519829  0.624939  0.568341  0.588635  0.490081   \n",
      "Christopher  0.554989   0.514174  0.598004  0.567783  0.552253  0.513371   \n",
      "Daniel       0.507103   0.459853  0.592163  0.555944  0.557320  0.448084   \n",
      "Matthew      0.553856   0.510072  0.593603  0.543035  0.554493  0.496829   \n",
      "George       0.521027   0.498593  0.589227  0.572956  0.554752  0.499815   \n",
      "Anthony      0.521696   0.526585  0.599595  0.569476  0.555368  0.521199   \n",
      "Donald       0.508004   0.469813  0.576357  0.488801  0.550350  0.418428   \n",
      "Paul         0.533959   0.474876  0.646320  0.578168  0.520104  0.493193   \n",
      "Mark         0.545886   0.535915  0.619139  0.545094  0.530104  0.512368   \n",
      "Andrew       0.530783   0.502759  0.592051  0.562563  0.583747  0.508552   \n",
      "Edward       0.530454   0.503853  0.580930  0.569816  0.562471  0.493375   \n",
      "\n",
      "               gentle  approachable      love      cool  \n",
      "James        0.593084      0.512673  0.524948  0.647451  \n",
      "John         0.625600      0.502070  0.531957  0.616648  \n",
      "Robert       0.597432      0.529719  0.519423  0.642731  \n",
      "Michael      0.565232      0.485737  0.530353  0.638966  \n",
      "William      0.602801      0.513457  0.547300  0.604000  \n",
      "David        0.602195      0.484654  0.511042  0.648565  \n",
      "Joseph       0.542434      0.486225  0.526029  0.635803  \n",
      "Richard      0.569123      0.507636  0.553478  0.622761  \n",
      "Charles      0.637657      0.487575  0.521215  0.590471  \n",
      "Thomas       0.631866      0.525792  0.536782  0.607585  \n",
      "Christopher  0.620950      0.532219  0.561638  0.646211  \n",
      "Daniel       0.570265      0.466379  0.506546  0.613253  \n",
      "Matthew      0.582346      0.491666  0.532830  0.631341  \n",
      "George       0.591520      0.475680  0.535953  0.615748  \n",
      "Anthony      0.567600      0.528847  0.528265  0.651522  \n",
      "Donald       0.586023      0.475050  0.488856  0.619119  \n",
      "Paul         0.587690      0.487924  0.509818  0.651608  \n",
      "Mark         0.578943      0.532173  0.551745  0.644275  \n",
      "Andrew       0.597931      0.507765  0.523488  0.637753  \n",
      "Edward       0.628441      0.500023  0.539300  0.618132  \n",
      "Cosine Similarity Matrix: Male Names vs Unpleasant Words\n",
      "                 rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "James        0.541806  0.533028      0.505112  0.624330  0.580849  0.464368   \n",
      "John         0.594056  0.554435      0.438125  0.629386  0.601994  0.521619   \n",
      "Robert       0.558484  0.562066      0.484349  0.621150  0.585729  0.480191   \n",
      "Michael      0.543460  0.559666      0.444475  0.618556  0.569844  0.493233   \n",
      "William      0.553416  0.541669      0.516762  0.594166  0.579406  0.492367   \n",
      "David        0.540499  0.538653      0.445325  0.593050  0.570469  0.513760   \n",
      "Joseph       0.524382  0.530553      0.472451  0.604348  0.571510  0.472400   \n",
      "Richard      0.556361  0.560704      0.487406  0.583839  0.595152  0.502890   \n",
      "Charles      0.508335  0.537901      0.483137  0.576507  0.535327  0.473900   \n",
      "Thomas       0.576014  0.554440      0.487238  0.640500  0.593088  0.525819   \n",
      "Christopher  0.544490  0.556498      0.462659  0.624467  0.623570  0.518895   \n",
      "Daniel       0.553761  0.555271      0.431504  0.609904  0.578252  0.506275   \n",
      "Matthew      0.544601  0.512677      0.482184  0.610617  0.596557  0.463926   \n",
      "George       0.527052  0.549451      0.470893  0.570359  0.585086  0.517146   \n",
      "Anthony      0.500734  0.559647      0.470986  0.564226  0.569552  0.485112   \n",
      "Donald       0.535280  0.509080      0.446381  0.570780  0.532319  0.467694   \n",
      "Paul         0.556327  0.566154      0.421172  0.634106  0.580520  0.485059   \n",
      "Mark         0.532693  0.577151      0.474141  0.593276  0.593136  0.505245   \n",
      "Andrew       0.544487  0.544763      0.480116  0.620436  0.607539  0.480866   \n",
      "Edward       0.560491  0.603525      0.464002  0.584268  0.594885  0.528522   \n",
      "\n",
      "              violent    bitter     harsh     angry  \n",
      "James        0.616682  0.606143  0.507186  0.580269  \n",
      "John         0.618589  0.577595  0.532743  0.583046  \n",
      "Robert       0.648758  0.616185  0.548271  0.585544  \n",
      "Michael      0.604750  0.571528  0.519294  0.577923  \n",
      "William      0.590007  0.590886  0.544532  0.625886  \n",
      "David        0.590515  0.582163  0.564684  0.580446  \n",
      "Joseph       0.639656  0.596094  0.516442  0.538629  \n",
      "Richard      0.619874  0.628681  0.546676  0.610136  \n",
      "Charles      0.627320  0.579576  0.494749  0.531953  \n",
      "Thomas       0.627710  0.604948  0.570837  0.620857  \n",
      "Christopher  0.652184  0.629620  0.560209  0.587581  \n",
      "Daniel       0.575463  0.577681  0.522898  0.568534  \n",
      "Matthew      0.631229  0.581553  0.496038  0.582809  \n",
      "George       0.596439  0.628935  0.542477  0.613336  \n",
      "Anthony      0.600256  0.605330  0.527395  0.599886  \n",
      "Donald       0.525334  0.562895  0.496116  0.531936  \n",
      "Paul         0.643894  0.584631  0.507127  0.554286  \n",
      "Mark         0.598225  0.576649  0.533438  0.549788  \n",
      "Andrew       0.623379  0.587510  0.536059  0.617018  \n",
      "Edward       0.604261  0.581477  0.547000  0.587385  \n"
     ]
    }
   ],
   "source": [
    "# Male Names\n",
    "# Pleasant Words\n",
    "similarities_MvP = cosine_similarity(Male_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_MvU = cosine_similarity(Male_Embeddings, Unpleasant_Embeddings)\n",
    "\n",
    "similarities_MvP = pd.DataFrame(similarities_MvP, index = Male_Names, columns = Pleasant_Words)\n",
    "similarities_MvU = pd.DataFrame(similarities_MvU, index = Male_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Male Names vs Pleasant Words\")\n",
    "print(similarities_MvP)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs Unpleasant Words\")\n",
    "print(similarities_MvU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fcfe221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Female Names vs Pleasant Words\n",
      "              happy  agreeable    polite     civil  charming  gracious  \\\n",
      "Mary       0.592158   0.519858  0.579484  0.514398  0.556302  0.544456   \n",
      "Elizabeth  0.500704   0.470875  0.512178  0.480943  0.486367  0.491594   \n",
      "Patricia   0.537397   0.495407  0.631213  0.549169  0.553075  0.468133   \n",
      "Jennifer   0.606165   0.434788  0.604126  0.538312  0.524223  0.518970   \n",
      "Linda      0.612696   0.434804  0.601407  0.540143  0.529557  0.488635   \n",
      "Barbara    0.563050   0.482297  0.601469  0.550955  0.548945  0.478270   \n",
      "Margaret   0.554797   0.521027  0.559766  0.515708  0.534594  0.493764   \n",
      "Susan      0.603058   0.535970  0.600753  0.541724  0.513949  0.521649   \n",
      "Dorothy    0.572032   0.480671  0.547319  0.495347  0.525909  0.475775   \n",
      "Sarah      0.574112   0.505097  0.589253  0.522312  0.543629  0.518689   \n",
      "Jessica    0.592346   0.450547  0.581345  0.521108  0.492331  0.491589   \n",
      "Helen      0.619977   0.539226  0.589067  0.576628  0.552190  0.548324   \n",
      "Nancy      0.492981   0.488498  0.596853  0.564487  0.525553  0.468061   \n",
      "Betty      0.578116   0.446225  0.585589  0.511880  0.519904  0.476946   \n",
      "Karen      0.521254   0.435812  0.580117  0.489370  0.485834  0.441114   \n",
      "Lisa       0.635102   0.425474  0.570644  0.492874  0.536947  0.494255   \n",
      "Anna       0.558104   0.479560  0.616357  0.547603  0.510260  0.495100   \n",
      "Sandra     0.542399   0.457971  0.617738  0.555616  0.628571  0.478452   \n",
      "Emily      0.625847   0.521906  0.588965  0.539907  0.541172  0.533589   \n",
      "Ashley     0.597311   0.503114  0.550803  0.510573  0.522001  0.506684   \n",
      "\n",
      "             gentle  approachable      love      cool  \n",
      "Mary       0.616023      0.515868  0.597432  0.632352  \n",
      "Elizabeth  0.548808      0.439956  0.508450  0.524493  \n",
      "Patricia   0.586730      0.519895  0.556755  0.604975  \n",
      "Jennifer   0.558900      0.422701  0.629200  0.659258  \n",
      "Linda      0.538642      0.441805  0.606409  0.644768  \n",
      "Barbara    0.553529      0.484446  0.524575  0.650370  \n",
      "Margaret   0.610554      0.516216  0.522836  0.566286  \n",
      "Susan      0.605511      0.519729  0.559725  0.625357  \n",
      "Dorothy    0.549031      0.490722  0.534027  0.595139  \n",
      "Sarah      0.578980      0.482398  0.573193  0.632080  \n",
      "Jessica    0.514033      0.446327  0.547064  0.653537  \n",
      "Helen      0.607321      0.521191  0.605077  0.680222  \n",
      "Nancy      0.577209      0.480944  0.529683  0.590706  \n",
      "Betty      0.584815      0.441391  0.525776  0.644836  \n",
      "Karen      0.530425      0.437725  0.528262  0.610871  \n",
      "Lisa       0.539059      0.411312  0.590707  0.646419  \n",
      "Anna       0.557113      0.461231  0.532450  0.604149  \n",
      "Sandra     0.567561      0.465158  0.551250  0.625678  \n",
      "Emily      0.611286      0.549586  0.597411  0.675231  \n",
      "Ashley     0.581365      0.512388  0.574074  0.645963  \n",
      "Cosine Similarity Matrix: Female Names vs Unpleasant Words\n",
      "               rude      lazy  disagreeable     lousy       sad      hate  \\\n",
      "Mary       0.506924  0.539236      0.513691  0.563613  0.545723  0.495143   \n",
      "Elizabeth  0.468674  0.483117      0.445474  0.457051  0.494051  0.472208   \n",
      "Patricia   0.544502  0.570610      0.497344  0.573950  0.564658  0.469807   \n",
      "Jennifer   0.531511  0.549530      0.394400  0.596065  0.572354  0.545974   \n",
      "Linda      0.529706  0.570134      0.390815  0.597049  0.565903  0.527540   \n",
      "Barbara    0.505554  0.573301      0.473798  0.572461  0.565490  0.487477   \n",
      "Margaret   0.503569  0.528367      0.524023  0.519226  0.539998  0.517063   \n",
      "Susan      0.528690  0.555422      0.471392  0.602034  0.583539  0.503095   \n",
      "Dorothy    0.487112  0.547994      0.454291  0.551658  0.532336  0.493844   \n",
      "Sarah      0.526039  0.557322      0.468560  0.583395  0.592164  0.498088   \n",
      "Jessica    0.500792  0.533670      0.400330  0.568917  0.577320  0.424166   \n",
      "Helen      0.485201  0.558773      0.494380  0.594522  0.617233  0.506702   \n",
      "Nancy      0.516251  0.555728      0.453686  0.595725  0.568293  0.456957   \n",
      "Betty      0.516725  0.525983      0.438107  0.571499  0.550174  0.502917   \n",
      "Karen      0.503936  0.522170      0.390707  0.540359  0.549913  0.429302   \n",
      "Lisa       0.506257  0.550506      0.391212  0.581806  0.545785  0.485712   \n",
      "Anna       0.572904  0.574547      0.433309  0.555443  0.553331  0.496058   \n",
      "Sandra     0.604289  0.557270      0.471636  0.612049  0.613607  0.523585   \n",
      "Emily      0.522697  0.564677      0.514885  0.547157  0.595283  0.487779   \n",
      "Ashley     0.483841  0.511285      0.464628  0.531093  0.529249  0.455661   \n",
      "\n",
      "            violent    bitter     harsh     angry  \n",
      "Mary       0.578106  0.636551  0.514732  0.580555  \n",
      "Elizabeth  0.502551  0.517262  0.438007  0.540367  \n",
      "Patricia   0.587284  0.581990  0.526607  0.569494  \n",
      "Jennifer   0.570700  0.584940  0.530965  0.564178  \n",
      "Linda      0.553208  0.592578  0.549063  0.522203  \n",
      "Barbara    0.559844  0.619759  0.536052  0.568091  \n",
      "Margaret   0.581048  0.576535  0.549789  0.535936  \n",
      "Susan      0.596373  0.622167  0.532560  0.586189  \n",
      "Dorothy    0.576598  0.598240  0.535457  0.541201  \n",
      "Sarah      0.565959  0.572351  0.553989  0.554465  \n",
      "Jessica    0.560891  0.545072  0.473721  0.529806  \n",
      "Helen      0.669641  0.639174  0.562698  0.568744  \n",
      "Nancy      0.603401  0.581792  0.531675  0.523142  \n",
      "Betty      0.565995  0.607487  0.534085  0.537375  \n",
      "Karen      0.535338  0.580670  0.496450  0.568161  \n",
      "Lisa       0.547024  0.558254  0.518351  0.515718  \n",
      "Anna       0.555757  0.577443  0.509231  0.611673  \n",
      "Sandra     0.601976  0.600884  0.555063  0.572534  \n",
      "Emily      0.609052  0.633428  0.544287  0.568334  \n",
      "Ashley     0.554794  0.556563  0.508806  0.513940  \n"
     ]
    }
   ],
   "source": [
    "# Female Names\n",
    "# Pleasant Words\n",
    "similarities_FvP = cosine_similarity(Female_Embeddings, Pleasant_Embeddings)\n",
    "# Unpleasant Words\n",
    "similarities_FvU = cosine_similarity(Female_Embeddings, Unpleasant_Embeddings)\n",
    "\n",
    "similarities_FvP = pd.DataFrame(similarities_FvP, index = Female_Names, columns = Pleasant_Words)\n",
    "similarities_FvU = pd.DataFrame(similarities_FvU, index = Female_Names, columns = Unpleasant_Words)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Female Names vs Pleasant Words\")\n",
    "print(similarities_FvP)\n",
    "print(\"Cosine Similarity Matrix: Female Names vs Unpleasant Words\")\n",
    "print(similarities_FvU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4844ca",
   "metadata": {},
   "source": [
    "# TEST 3: Gender Biases in Careers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4dc4744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Male Names vs STEM Careers\n",
      "             Software Developer  Nurse Practitioner  Health Services Manager  \\\n",
      "James                  0.438088            0.468028                 0.480814   \n",
      "John                   0.431360            0.519418                 0.475162   \n",
      "Robert                 0.425374            0.515385                 0.476185   \n",
      "Michael                0.433512            0.554105                 0.467893   \n",
      "William                0.423699            0.523625                 0.455748   \n",
      "David                  0.465424            0.474373                 0.468724   \n",
      "Joseph                 0.448438            0.534212                 0.467920   \n",
      "Richard                0.434181            0.543579                 0.467037   \n",
      "Charles                0.430199            0.530084                 0.424068   \n",
      "Thomas                 0.433282            0.523795                 0.468355   \n",
      "Christopher            0.460736            0.537502                 0.486423   \n",
      "Daniel                 0.450495            0.480144                 0.471161   \n",
      "Matthew                0.460428            0.519335                 0.473280   \n",
      "George                 0.454877            0.515127                 0.496493   \n",
      "Anthony                0.421875            0.541401                 0.514857   \n",
      "Donald                 0.484474            0.456038                 0.448868   \n",
      "Paul                   0.423279            0.553927                 0.453323   \n",
      "Mark                   0.452919            0.543517                 0.475249   \n",
      "Andrew                 0.452093            0.524678                 0.454072   \n",
      "Edward                 0.455911            0.506491                 0.462746   \n",
      "\n",
      "             Physicians Assistant  Security Analyst  IT Manager  \\\n",
      "James                    0.490282          0.446906    0.544417   \n",
      "John                     0.493424          0.453628    0.545299   \n",
      "Robert                   0.488140          0.460280    0.531329   \n",
      "Michael                  0.480448          0.479383    0.551161   \n",
      "William                  0.478436          0.463994    0.506187   \n",
      "David                    0.469772          0.465005    0.531399   \n",
      "Joseph                   0.457819          0.428381    0.524703   \n",
      "Richard                  0.415159          0.445928    0.519126   \n",
      "Charles                  0.443870          0.454452    0.473953   \n",
      "Thomas                   0.472580          0.470119    0.546300   \n",
      "Christopher              0.490015          0.488000    0.549749   \n",
      "Daniel                   0.459408          0.474197    0.530822   \n",
      "Matthew                  0.463552          0.442761    0.552512   \n",
      "George                   0.498407          0.474905    0.521057   \n",
      "Anthony                  0.545137          0.508610    0.559386   \n",
      "Donald                   0.413487          0.450892    0.520620   \n",
      "Paul                     0.462116          0.433282    0.526583   \n",
      "Mark                     0.474643          0.488033    0.568396   \n",
      "Andrew                   0.477394          0.469117    0.522832   \n",
      "Edward                   0.466532          0.456695    0.516999   \n",
      "\n",
      "             Web Developer   Dentist  Orthodontist  Computer Systems Analyst  \n",
      "James             0.478533  0.563147      0.487039                  0.445870  \n",
      "John              0.454886  0.565639      0.548344                  0.464674  \n",
      "Robert            0.442648  0.573942      0.584679                  0.448363  \n",
      "Michael           0.462878  0.554380      0.541858                  0.509420  \n",
      "William           0.462489  0.513152      0.507766                  0.459837  \n",
      "David             0.487718  0.547131      0.527358                  0.462229  \n",
      "Joseph            0.463686  0.517895      0.521241                  0.433134  \n",
      "Richard           0.453728  0.536998      0.541955                  0.475858  \n",
      "Charles           0.428131  0.512402      0.524848                  0.469304  \n",
      "Thomas            0.461610  0.558939      0.528786                  0.479679  \n",
      "Christopher       0.477382  0.590851      0.559852                  0.506265  \n",
      "Daniel            0.479435  0.531196      0.524487                  0.481574  \n",
      "Matthew           0.456507  0.531907      0.499270                  0.437838  \n",
      "George            0.483545  0.538352      0.518072                  0.480693  \n",
      "Anthony           0.448734  0.590321      0.561705                  0.499452  \n",
      "Donald            0.459944  0.517354      0.488399                  0.472333  \n",
      "Paul              0.448945  0.547005      0.534694                  0.453621  \n",
      "Mark              0.475016  0.582148      0.539974                  0.488504  \n",
      "Andrew            0.489117  0.558346      0.532651                  0.467671  \n",
      "Edward            0.503244  0.532699      0.524654                  0.476417  \n",
      "Cosine Similarity Matrix: Male Names vs Non-STEM Careers\n",
      "               Artist  Marketing Manager  Social Worker  Attorney  Journalist  \\\n",
      "James        0.572012           0.546880       0.496684  0.580354    0.612646   \n",
      "John         0.549740           0.535621       0.502862  0.552267    0.630613   \n",
      "Robert       0.561545           0.532975       0.461793  0.578939    0.649145   \n",
      "Michael      0.574515           0.581222       0.465591  0.550710    0.631831   \n",
      "William      0.561001           0.503533       0.463363  0.557542    0.609131   \n",
      "David        0.581966           0.557958       0.524084  0.571137    0.641120   \n",
      "Joseph       0.580804           0.505549       0.474304  0.524009    0.622358   \n",
      "Richard      0.555930           0.536248       0.457920  0.529392    0.599319   \n",
      "Charles      0.573761           0.457322       0.428392  0.513503    0.615074   \n",
      "Thomas       0.577569           0.548099       0.502214  0.582258    0.636340   \n",
      "Christopher  0.602064           0.552603       0.487846  0.596087    0.669659   \n",
      "Daniel       0.539955           0.536527       0.493162  0.544425    0.617960   \n",
      "Matthew      0.554671           0.532806       0.517069  0.570552    0.608825   \n",
      "George       0.567930           0.558211       0.490847  0.616554    0.643494   \n",
      "Anthony      0.597678           0.601153       0.517455  0.602884    0.646445   \n",
      "Donald       0.482734           0.509380       0.442834  0.511888    0.551676   \n",
      "Paul         0.582926           0.536129       0.496574  0.534032    0.634929   \n",
      "Mark         0.600780           0.589105       0.544632  0.547274    0.629068   \n",
      "Andrew       0.567078           0.512194       0.518379  0.564790    0.644101   \n",
      "Edward       0.571536           0.512879       0.473455  0.549518    0.612699   \n",
      "\n",
      "             Musician   Teacher  Media Manager  Graphic Designer     Judge  \n",
      "James        0.646799  0.601259       0.572073          0.525430  0.584702  \n",
      "John         0.653655  0.641724       0.549012          0.494801  0.561842  \n",
      "Robert       0.638614  0.609934       0.574518          0.513121  0.592382  \n",
      "Michael      0.629286  0.636661       0.594427          0.524986  0.566118  \n",
      "William      0.640423  0.612428       0.541472          0.492989  0.575205  \n",
      "David        0.619998  0.595529       0.595256          0.536042  0.552569  \n",
      "Joseph       0.639580  0.605995       0.550680          0.489740  0.559424  \n",
      "Richard      0.603598  0.598647       0.550501          0.494046  0.550630  \n",
      "Charles      0.615976  0.594387       0.493402          0.466562  0.516481  \n",
      "Thomas       0.640263  0.637321       0.553023          0.531590  0.590369  \n",
      "Christopher  0.669987  0.664943       0.572681          0.535415  0.629974  \n",
      "Daniel       0.636600  0.580219       0.581381          0.479316  0.558992  \n",
      "Matthew      0.610926  0.636463       0.559349          0.499530  0.587174  \n",
      "George       0.665449  0.634389       0.575331          0.564700  0.598038  \n",
      "Anthony      0.678165  0.650467       0.607278          0.568108  0.606523  \n",
      "Donald       0.573449  0.568959       0.525121          0.473923  0.506292  \n",
      "Paul         0.634637  0.621248       0.550340          0.517562  0.548292  \n",
      "Mark         0.631198  0.644781       0.592145          0.597000  0.591929  \n",
      "Andrew       0.636895  0.628411       0.538887          0.516802  0.580168  \n",
      "Edward       0.649756  0.605330       0.545008          0.532350  0.545505  \n"
     ]
    }
   ],
   "source": [
    "# Male Names\n",
    "# STEM Careers\n",
    "similarities_MvS = cosine_similarity(Male_Embeddings, STEM_Embeddings)\n",
    "# Non-STEM Careers\n",
    "similarities_MvN = cosine_similarity(Male_Embeddings, Non_STEM_Embeddings)\n",
    "\n",
    "similarities_MvS = pd.DataFrame(similarities_MvS, index = Male_Names, columns = STEM_Careers)\n",
    "similarities_MvN = pd.DataFrame(similarities_MvN, index = Male_Names, columns = Non_STEM_Careers)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Male Names vs STEM Careers\")\n",
    "print(similarities_MvS)\n",
    "print(\"Cosine Similarity Matrix: Male Names vs Non-STEM Careers\")\n",
    "print(similarities_MvN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b00b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix: Female Names vs STEM Careers\n",
      "           Software Developer  Nurse Practitioner  Health Services Manager  \\\n",
      "Mary                 0.448504            0.582569                 0.548237   \n",
      "Elizabeth            0.415225            0.469874                 0.468053   \n",
      "Patricia             0.414746            0.545969                 0.522379   \n",
      "Jennifer             0.451255            0.494768                 0.464724   \n",
      "Linda                0.412345            0.464494                 0.469781   \n",
      "Barbara              0.433174            0.536368                 0.527314   \n",
      "Margaret             0.439379            0.525625                 0.525175   \n",
      "Susan                0.414533            0.538907                 0.511590   \n",
      "Dorothy              0.447841            0.558911                 0.516363   \n",
      "Sarah                0.435968            0.557240                 0.508177   \n",
      "Jessica              0.431127            0.510175                 0.436964   \n",
      "Helen                0.419789            0.551124                 0.498992   \n",
      "Nancy                0.427814            0.487697                 0.432388   \n",
      "Betty                0.406752            0.518980                 0.496378   \n",
      "Karen                0.379746            0.531877                 0.479577   \n",
      "Lisa                 0.467280            0.418026                 0.425731   \n",
      "Anna                 0.380298            0.476978                 0.434791   \n",
      "Sandra               0.435928            0.492107                 0.482081   \n",
      "Emily                0.455450            0.599189                 0.506661   \n",
      "Ashley               0.456371            0.512687                 0.480008   \n",
      "\n",
      "           Physicians Assistant  Security Analyst  IT Manager  Web Developer  \\\n",
      "Mary                   0.518716          0.519961    0.538058       0.481287   \n",
      "Elizabeth              0.446687          0.473946    0.477968       0.465593   \n",
      "Patricia               0.529006          0.528309    0.543058       0.441046   \n",
      "Jennifer               0.443631          0.445026    0.509380       0.508159   \n",
      "Linda                  0.412843          0.453066    0.508203       0.447186   \n",
      "Barbara                0.518845          0.526488    0.538486       0.446015   \n",
      "Margaret               0.514439          0.508853    0.520892       0.436976   \n",
      "Susan                  0.507944          0.484257    0.523221       0.453555   \n",
      "Dorothy                0.474550          0.473173    0.518813       0.488361   \n",
      "Sarah                  0.517086          0.491856    0.534604       0.491509   \n",
      "Jessica                0.431222          0.441189    0.506657       0.489135   \n",
      "Helen                  0.484686          0.454440    0.519714       0.452359   \n",
      "Nancy                  0.448087          0.442080    0.478914       0.438106   \n",
      "Betty                  0.477650          0.482779    0.518656       0.455113   \n",
      "Karen                  0.484052          0.491603    0.518148       0.432997   \n",
      "Lisa                   0.415027          0.454882    0.490709       0.495298   \n",
      "Anna                   0.472565          0.495123    0.490944       0.413045   \n",
      "Sandra                 0.469043          0.507329    0.521697       0.426046   \n",
      "Emily                  0.515401          0.504471    0.545918       0.522319   \n",
      "Ashley                 0.462207          0.488761    0.522328       0.485834   \n",
      "\n",
      "            Dentist  Orthodontist  Computer Systems Analyst  \n",
      "Mary       0.567680      0.527598                  0.519846  \n",
      "Elizabeth  0.509258      0.496319                  0.455598  \n",
      "Patricia   0.564874      0.540075                  0.512238  \n",
      "Jennifer   0.517717      0.435663                  0.442151  \n",
      "Linda      0.523382      0.466930                  0.442435  \n",
      "Barbara    0.544624      0.513110                  0.540902  \n",
      "Margaret   0.551883      0.525865                  0.505021  \n",
      "Susan      0.523082      0.514585                  0.452977  \n",
      "Dorothy    0.543283      0.519966                  0.478194  \n",
      "Sarah      0.556519      0.513927                  0.470824  \n",
      "Jessica    0.499159      0.451718                  0.407901  \n",
      "Helen      0.580671      0.518010                  0.421050  \n",
      "Nancy      0.519606      0.486346                  0.420357  \n",
      "Betty      0.513745      0.457031                  0.473502  \n",
      "Karen      0.540597      0.484803                  0.469152  \n",
      "Lisa       0.467941      0.462783                  0.476894  \n",
      "Anna       0.513404      0.514940                  0.496971  \n",
      "Sandra     0.503339      0.457386                  0.508807  \n",
      "Emily      0.572635      0.543255                  0.500889  \n",
      "Ashley     0.533686      0.491986                  0.481136  \n",
      "Cosine Similarity Matrix: Female Names vs Non-STEM Careers\n",
      "             Artist  Marketing Manager  Social Worker  Attorney  Journalist  \\\n",
      "Mary       0.572166           0.570783       0.525421  0.534611    0.619992   \n",
      "Elizabeth  0.528098           0.459238       0.451649  0.485666    0.557919   \n",
      "Patricia   0.594207           0.549267       0.489209  0.551053    0.624108   \n",
      "Jennifer   0.553485           0.545276       0.466818  0.527813    0.579999   \n",
      "Linda      0.519014           0.531402       0.492749  0.487158    0.550737   \n",
      "Barbara    0.545504           0.585515       0.493902  0.579944    0.623209   \n",
      "Margaret   0.560778           0.514960       0.501770  0.536669    0.629519   \n",
      "Susan      0.551464           0.554469       0.531970  0.538752    0.618811   \n",
      "Dorothy    0.548835           0.548083       0.504964  0.512072    0.567753   \n",
      "Sarah      0.579169           0.556290       0.554578  0.522071    0.627516   \n",
      "Jessica    0.552164           0.534056       0.489177  0.487774    0.593070   \n",
      "Helen      0.591003           0.524000       0.530223  0.576500    0.660257   \n",
      "Nancy      0.547424           0.525218       0.464268  0.542241    0.619976   \n",
      "Betty      0.581161           0.538685       0.475419  0.597018    0.619181   \n",
      "Karen      0.536059           0.540267       0.469883  0.507199    0.590067   \n",
      "Lisa       0.494744           0.498973       0.444975  0.455018    0.528399   \n",
      "Anna       0.526769           0.474671       0.447126  0.491088    0.597847   \n",
      "Sandra     0.519659           0.538915       0.470256  0.548448    0.604368   \n",
      "Emily      0.613514           0.561980       0.524275  0.564155    0.646219   \n",
      "Ashley     0.531383           0.563555       0.469807  0.503844    0.550138   \n",
      "\n",
      "           Musician   Teacher  Media Manager  Graphic Designer     Judge  \n",
      "Mary       0.626592  0.665234       0.571754          0.543160  0.521966  \n",
      "Elizabeth  0.551915  0.539546       0.516724          0.530765  0.442190  \n",
      "Patricia   0.644876  0.640617       0.562966          0.512607  0.533956  \n",
      "Jennifer   0.580719  0.571518       0.545827          0.526187  0.540829  \n",
      "Linda      0.561798  0.563049       0.525747          0.491031  0.491746  \n",
      "Barbara    0.630699  0.636103       0.584691          0.561586  0.583685  \n",
      "Margaret   0.606768  0.637152       0.548442          0.562952  0.563766  \n",
      "Susan      0.608742  0.614603       0.562951          0.509088  0.566174  \n",
      "Dorothy    0.594685  0.623319       0.559012          0.560486  0.582304  \n",
      "Sarah      0.610395  0.639233       0.586534          0.546618  0.536447  \n",
      "Jessica    0.551461  0.570132       0.546088          0.528126  0.526175  \n",
      "Helen      0.651960  0.659848       0.565476          0.556336  0.624419  \n",
      "Nancy      0.547623  0.587605       0.520571          0.534232  0.544019  \n",
      "Betty      0.592822  0.613649       0.548457          0.538098  0.571010  \n",
      "Karen      0.589168  0.580996       0.550197          0.471928  0.487524  \n",
      "Lisa       0.520917  0.548233       0.522736          0.530471  0.479949  \n",
      "Anna       0.616628  0.583476       0.505135          0.477768  0.476806  \n",
      "Sandra     0.617591  0.609860       0.543810          0.478034  0.559510  \n",
      "Emily      0.631217  0.678628       0.590674          0.558877  0.567766  \n",
      "Ashley     0.566008  0.604455       0.554884          0.513643  0.520585  \n"
     ]
    }
   ],
   "source": [
    "# Female Names\n",
    "# STEM Careers\n",
    "similarities_FvS = cosine_similarity(Female_Embeddings, STEM_Embeddings)\n",
    "# Non-STEM Careers\n",
    "similarities_FvN = cosine_similarity(Female_Embeddings, Non_STEM_Embeddings)\n",
    "\n",
    "similarities_FvS = pd.DataFrame(similarities_FvS, index = Female_Names, columns = STEM_Careers)\n",
    "similarities_FvN = pd.DataFrame(similarities_FvN, index = Female_Names, columns = Non_STEM_Careers)\n",
    "\n",
    "print(\"Cosine Similarity Matrix: Female Names vs STEM Careers\")\n",
    "print(similarities_FvS)\n",
    "print(\"Cosine Similarity Matrix: Female Names vs Non-STEM Careers\")\n",
    "print(similarities_FvN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e80805e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DataFrame  avgCS_distilbert_base_multilingual_cased\n",
      "0       AFvP                                  0.523826\n",
      "1       AFvU                                  0.564080\n",
      "2       EUvP                                  0.546529\n",
      "3       EUvU                                  0.547429\n",
      "4       LXvP                                  0.542147\n",
      "5       LXvU                                  0.540731\n",
      "6       CHvP                                  0.521961\n",
      "7       CHvU                                  0.568381\n",
      "8        MvP                                  0.548762\n",
      "9        MvU                                  0.556154\n",
      "10       FvP                                  0.543113\n",
      "11       FvU                                  0.537722\n",
      "12       MvS                                  0.491321\n",
      "13       MvN                                  0.568047\n",
      "14       FvS                                  0.487681\n",
      "15       FvN                                  0.552271\n"
     ]
    }
   ],
   "source": [
    "#Mean cosine similarity of each test\n",
    "\n",
    "dataframes_dict = {\n",
    "    'AFvP': similarities_AFvP,\n",
    "    'AFvU': similarities_AFvU,\n",
    "    'EUvP': similarities_EUvP,\n",
    "    'EUvU': similarities_EUvU,\n",
    "    'LXvP': similarities_LXvP,\n",
    "    'LXvU': similarities_LXvU,\n",
    "    'CHvP': similarities_CHvP,\n",
    "    'CHvU': similarities_CHvU,\n",
    "    'MvP': similarities_MvP,\n",
    "    'MvU': similarities_MvU,\n",
    "    'FvP': similarities_FvP,\n",
    "    'FvU': similarities_FvU,\n",
    "    'MvS': similarities_MvS,\n",
    "    'MvN': similarities_MvN,\n",
    "    'FvS': similarities_FvS,\n",
    "    'FvN': similarities_FvN\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the means\n",
    "mean_dict = {}\n",
    "\n",
    "# Calculate the mean for each DataFrame and store it in the mean_dict\n",
    "for df_name, df in dataframes_dict.items():\n",
    "    mean_value = df.values.mean()\n",
    "    mean_dict[df_name] = mean_value\n",
    "\n",
    "# Create a new DataFrame from the mean_dict\n",
    "mean_df = pd.DataFrame(list(mean_dict.items()), columns=['DataFrame', 'avgCS_distilbert_base_multilingual_cased'])\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(mean_df)\n",
    "\n",
    "#Save to .csv\n",
    "mean_df.to_csv('distilbert_base_multilingual_cased_meanCosSim.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
